<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Using R for Introduction to Econometrics</title>
  <meta name="description" content="Using <tt>R</tt> for Introduction to Econometrics">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Using R for Introduction to Econometrics" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="Emwikts1970/URFITE-Bookdown" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Using R for Introduction to Econometrics" />
  
  
  

<meta name="author" content="Christoph Hanck, Martin Arnold, Alexander Gerber and Martin Schmelzer">


<meta name="date" content="2018-07-17">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="probit-and-logit-regression.html">
<link rel="next" href="application-to-the-boston-hmda-data.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="js/hideOutput.js"></script>
<script type="text/javascript" src="MathJax-2.7.2/MathJax.js?config=default"></script>

 <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        extensions: ["tex2jax.js", "TeX/AMSmath.js"],
        tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
        jax: ["input/TeX","output/CommonHTML"]
      });
      MathJax.Hub.processSectionDelay = 0;
  </script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110299877-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110299877-1');
</script>

<!-- open review block -->

<script async defer src="https://hypothes.is/embed.js"></script>

<!-- datacamp-light-latest -->

<script src="https://cdn.datacamp.com/datacamp-light-latest.min.js"></script>


<!-- <script src="js/d3.v3.min.js"></script>
<script src="js/leastsquares.js"></script>
<script src="js/d3functions.js"></script>
<script src="d3.slider.js"></script>
<script src="slrm.js"></script> -->


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #f8f8f8; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
pre, code { background-color: #f8f8f8; }
code > span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code > span.dt { color: #204a87; } /* DataType */
code > span.dv { color: #0000cf; } /* DecVal */
code > span.bn { color: #0000cf; } /* BaseN */
code > span.fl { color: #0000cf; } /* Float */
code > span.ch { color: #4e9a06; } /* Char */
code > span.st { color: #4e9a06; } /* String */
code > span.co { color: #8f5902; font-style: italic; } /* Comment */
code > span.ot { color: #8f5902; } /* Other */
code > span.al { color: #ef2929; } /* Alert */
code > span.fu { color: #000000; } /* Function */
code > span.er { color: #a40000; font-weight: bold; } /* Error */
code > span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #000000; } /* Constant */
code > span.sc { color: #000000; } /* SpecialChar */
code > span.vs { color: #4e9a06; } /* VerbatimString */
code > span.ss { color: #4e9a06; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #000000; } /* Variable */
code > span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code > span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code > span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code > span.ex { } /* Extension */
code > span.at { color: #c4a000; } /* Attribute */
code > span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code > span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">URFITE</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="a-very-short-introduction-to-r-and-rstudio.html"><a href="a-very-short-introduction-to-r-and-rstudio.html"><i class="fa fa-check"></i><b>1.1</b> A Very Short Introduction to <tt>R</tt> and <em>RStudio</em></a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="rwabdv.html"><a href="rwabdv.html"><i class="fa fa-check"></i><b>2</b> Regression with a Binary Dependent Variable</a><ul>
<li class="chapter" data-level="2.1" data-path="binary-dependent-variables-and-the-linear-probability-model.html"><a href="binary-dependent-variables-and-the-linear-probability-model.html"><i class="fa fa-check"></i><b>2.1</b> Binary Dependent Variables and the Linear Probability Model</a></li>
<li class="chapter" data-level="2.2" data-path="probit-and-logit-regression.html"><a href="probit-and-logit-regression.html"><i class="fa fa-check"></i><b>2.2</b> Probit and Logit Regression</a><ul>
<li class="chapter" data-level="" data-path="probit-and-logit-regression.html"><a href="probit-and-logit-regression.html#probit-regression"><i class="fa fa-check"></i>Probit Regression</a></li>
<li class="chapter" data-level="" data-path="probit-and-logit-regression.html"><a href="probit-and-logit-regression.html#logit-regression"><i class="fa fa-check"></i>Logit Regression</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="estimation-and-inference-in-the-logit-and-probit-models.html"><a href="estimation-and-inference-in-the-logit-and-probit-models.html"><i class="fa fa-check"></i><b>2.3</b> Estimation and Inference in the Logit and Probit Models</a></li>
<li class="chapter" data-level="2.4" data-path="application-to-the-boston-hmda-data.html"><a href="application-to-the-boston-hmda-data.html"><i class="fa fa-check"></i><b>2.4</b> Application to the Boston HMDA Data</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Using <tt>R</tt> for Introduction to Econometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div class = rmdreview>
This book is in <b>Open Review</b>. We want your feedback to make the book better for you and other students. You may annotate some text by <span style="background-color: #3297FD; color: white">selecting it with the cursor</span> and then click the <i class="h-icon-annotate"></i> on the pop-up menu. You can also see the annotations of others: click the <i class="h-icon-chevron-left"></i> in the upper right hand corner of the page <i class="fa fa-arrow-circle-right  fa-rotate-315" aria-hidden="true"></i>
</div>
<div id="estimation-and-inference-in-the-logit-and-probit-models" class="section level2">
<h2><span class="header-section-number">2.3</span> Estimation and Inference in the Logit and Probit Models</h2>
<p>So far nothing has been said about <em>how</em> Logit and Probit models are estimated by statistical software. The reason why this is interesting is that both models are <em>nonlinear in the parameters</em> and thus cannot be estimated using OLS. Instead one relies on a method called <em>maximum likelihood estimation</em> (MLE). Another approach is estimation by <em>nonlinear least squares</em> (NLS).</p>
<div id="nonlinear-least-squares" class="section level4 unnumbered">
<h4>Nonlinear Least Squares</h4>
Consider the multiple regression Probit model
<span class="math display" id="eq:multprobit">\[\begin{align}
  E(Y_i\vert X_{1i}, \dots, X_{ki}) = P(Y_i=1\vert X_{1i}, \dots, X_{ki}) = \Phi(\beta_0 + \beta_1 X_{1i} + \dots + \beta_k X_{ki}). \tag{2.7}
\end{align}\]</span>
<p>Similarly to OLS, NLS estimates the parameters <span class="math inline">\(\beta_0,\beta_1,\dots,\beta_k\)</span> by minimizing the sum of squared mistakes <span class="math display">\[\sum_{i=1}^n\left[ Y_i - \Phi(b_0 + b_1 X_{1i} + \dots + b_k X_{ki}) \right]^2.\]</span> NLS estimation is a consistent approach that produces estimates which are normally distributed in large samples. In <tt>R</tt> there are functions like <tt>nls()</tt> from package <tt>stats</tt> which provide algorithms for solving nonlinear least squares problems. However, NLS is inefficient, meaning that there are estimation techniques that have a smaller variance which is why we will not dwell any further on this topic.</p>
</div>
<div id="maximum-likelihood-estimation" class="section level4 unnumbered">
<h4>Maximum Likelihood Estimation</h4>
<p>In MLE we seek to estimate the unknown parameters choosing them such that the likelihood of drawing the sample observed is maximized. This probability is measured by means the likelihood function, the joint probability distribution of the data treated as a function of the unknown parameters. Put differently, the maximum likelihood estimates of the unknown parameters are the values that result in a model which is most likely to produce the data observed. It turns out that MLE is more efficient than NLS.</p>
<p>As maximum likelihood estimates are normally distributed in large samples, statistical inference for coefficients in nonlinear models like Logit and Probit regression can be made using the same tools that are used for linear regression models: we can compute <span class="math inline">\(t\)</span>-statistics and confidence intervals.</p>
<p>Many software packages use an MLE algorithm for estimation of nonlinear models. The function <tt>glm()</tt> uses an algorithm named <em>iteratively reweighted least squares</em>.</p>
</div>
<div id="measures-of-fit" class="section level4 unnumbered">
<h4>Measures of Fit</h4>
<p>It is important to be aware that the usual <span class="math inline">\(R^2\)</span> and <span class="math inline">\(\overline{R^2}\)</span> are <em>invalid</em> for nonlinear regression models. The reason for this is simple: both measures are derived under the assumption that the relation between the dependent and the explanatory variable(s) is linear. This obviously does not hold for Probit and Logit models thus <span class="math inline">\(R^2\)</span> does not fall between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span> and there is no meaningful interpretation. However, statistical software sometimes reports these measures anyway.</p>
<p>There are many measures of fit for nonlinear regression models and there is no consensus which one should be reported. The situation is even more complicated because there is no measure of fit that is generally applicable. For models with a binary response variable like <span class="math inline">\(deny\)</span> one could use the following rule: If <span class="math inline">\(Y_i = 1\)</span> and <span class="math inline">\(\widehat{P(Y_i|X_{i1}, \dots, X_{ik})} &gt; 0.5\)</span> or if <span class="math inline">\(Y_i = 0\)</span> and <span class="math inline">\(\widehat{P(Y_i|X_{i1}, \dots, X_{ik})} &lt; 0.5\)</span>, consider the <span class="math inline">\(Y_i\)</span> as correctly predicted. Otherwise <span class="math inline">\(Y_i\)</span> is said to be incorrectly predicted. The measure of fit is the share of correctly predicted observations. The downside of such an approach is that it does not yield information on the quality of the prediction.<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a></p>
<p>An alternative to the latter are so called pseudo-<span class="math inline">\(R^2\)</span> measures. In order to measure the quality of the fit, these measures compare the value of the maximized (log-)likelihood of the model with all regressors (the <em>full model</em>) to the likelihood of a model with no regressors (<em>null model</em>, regression on a constant).</p>
<p>For example, consider a Probit regression. The <span class="math inline">\(\text{pseudo-}R^2\)</span> is given by <span class="math display">\[\text{pseudo-}R^2 = 1 - \frac{\ln(f^{max}_{full})}{\ln(f^{max}_{null})}\]</span> where <span class="math inline">\(f^{max}_j \in [0,1]\)</span> denotes the maximized likelihood for model <span class="math inline">\(j\)</span>.</p>
<p>The reasoning behind this is that the maximized likelihood increases as additional regressors are added to the model, similarly to the decrease in <span class="math inline">\(SSR\)</span> when regressors are added in a linear regression model. If the full model has a similar maximized likelihood than the null model, the full model does not really improve upon a model that uses only the information in the dependent variable, so <span class="math inline">\(\text{pseudo-}R^2 \approx 0\)</span>. If the full model fits the data very good, the maximized likelihood should be close to <span class="math inline">\(1\)</span> such that <span class="math inline">\(\ln(f^{max}_{full}) \approx 0\)</span> and <span class="math inline">\(\text{pseudo-}R^2 \approx 1\)</span>. See Appendix 11.2 of the book for more on MLE and pseudo-<span class="math inline">\(R^2\)</span> measures.</p>
<p><tt>summary()</tt> does not report <span class="math inline">\(\text{pseudo-}R^2\)</span> for models estimated by <tt>glm()</tt> but we can use the entries <em>residual deviance</em> (<tt>deviance</tt>) and <em>null deviance</em> (<tt>null.deviance</tt>) instead. These are computed as <span class="math display">\[\text{deviance} = -2 \times \left[\ln(f^{max}_{saturated}) - \ln(f^{max}_{full}) \right]\]</span> and</p>
<p><span class="math display">\[\text{null deviance} = -2 \times \left[\ln(f^{max}_{saturated}) - \ln(f^{max}_{null}) \right]\]</span> where <span class="math inline">\(f^{max}_{saturated}\)</span> is the maximized likelihood for a model which assumes that each observation has its own parameter (there are <span class="math inline">\(n+1\)</span> parameters to be estimated which leads to a perfect fit). For models wit ah binary dependent variable, it holds that <span class="math display">\[\text{pseudo-}R^2 = 1 - \frac{\text{deviance}}{\text{null deviance}} = 1- \frac{\ln(f^{max}_{full})}{\ln(f^{max}_{null})}.\]</span></p>
<p>We now compute the <span class="math inline">\(\text{pseudo-}R^2\)</span> for the augmented Probit model of mortgage denial.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute pseudo-R2 for the probit model of mortgage denial</span>
pseudoR2 &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span>(denyprobit2<span class="op">$</span>deviance) <span class="op">/</span><span class="st"> </span>(denyprobit2<span class="op">$</span>null.deviance)
pseudoR2</code></pre></div>
<pre><code>## [1] 0.08594259</code></pre>
<p>Another way to obtain the <span class="math inline">\(\text{pseudo-}R^2\)</span> is to estimate the null model using <tt>glm()</tt> and extract the maximized log-likelihoods for both the null and the full model using the function <tt>logLik()</tt>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute null model</span>
denyprobit_null &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="dt">formula =</span> deny <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, 
                       <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;probit&quot;</span>), 
                       <span class="dt">data =</span> HMDA)

<span class="co"># compute the pseudo-R2 using `logLik`</span>
<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">logLik</span>(denyprobit2)[<span class="dv">1</span>]<span class="op">/</span><span class="kw">logLik</span>(denyprobit_null)[<span class="dv">1</span>]</code></pre></div>
<pre><code>## [1] 0.08594259</code></pre>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="3">
<li id="fn3"><p>Note that this is in contrast to the case of a numeric dependent variable where we use the squared errors for assessment of the quality of the prediction.<a href="estimation-and-inference-in-the-logit-and-probit-models.html#fnref3">â†©</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="probit-and-logit-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="application-to-the-boston-hmda-data.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 1
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/11-ch11.Rmd",
"text": "Edit"
},
"download": ["URFITE.pdf"],
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
