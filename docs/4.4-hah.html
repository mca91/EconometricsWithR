<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4.4 Heteroskedasticity and Homoskedasticity | Introduction to Econometrics with R</title>
  <meta name="description" content="Beginners with little background in statistics and econometrics often have a hard time understanding the benefits of having programming skills for learning and applying Econometrics. ‘Introduction to Econometrics with R’ is an interactive companion to the well-received textbook ‘Introduction to Econometrics’ by James H. Stock and Mark W. Watson (2015). It gives a gentle introduction to the essentials of R programming and guides students in implementing the empirical applications presented throughout the textbook using the newly aquired skills. This is supported by interactive programming exercises generated with DataCamp Light and integration of interactive visualizations of central concepts which are based on the flexible JavaScript library D3.js." />
  <meta name="generator" content="bookdown 0.33 and GitBook 2.6.7" />

  <meta property="og:title" content="4.4 Heteroskedasticity and Homoskedasticity | Introduction to Econometrics with R" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://www.econometrics-with-r.org//images/cover.png" />
  <meta property="og:description" content="Beginners with little background in statistics and econometrics often have a hard time understanding the benefits of having programming skills for learning and applying Econometrics. ‘Introduction to Econometrics with R’ is an interactive companion to the well-received textbook ‘Introduction to Econometrics’ by James H. Stock and Mark W. Watson (2015). It gives a gentle introduction to the essentials of R programming and guides students in implementing the empirical applications presented throughout the textbook using the newly aquired skills. This is supported by interactive programming exercises generated with DataCamp Light and integration of interactive visualizations of central concepts which are based on the flexible JavaScript library D3.js." />
  <meta name="github-repo" content="mca91/EconometricsWithR" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4.4 Heteroskedasticity and Homoskedasticity | Introduction to Econometrics with R" />
  
  <meta name="twitter:description" content="Beginners with little background in statistics and econometrics often have a hard time understanding the benefits of having programming skills for learning and applying Econometrics. ‘Introduction to Econometrics with R’ is an interactive companion to the well-received textbook ‘Introduction to Econometrics’ by James H. Stock and Mark W. Watson (2015). It gives a gentle introduction to the essentials of R programming and guides students in implementing the empirical applications presented throughout the textbook using the newly aquired skills. This is supported by interactive programming exercises generated with DataCamp Light and integration of interactive visualizations of central concepts which are based on the flexible JavaScript library D3.js." />
  <meta name="twitter:image" content="https://www.econometrics-with-r.org//images/cover.png" />

<meta name="author" content="Christoph Hanck, Martin Arnold, Alexander Gerber, and Martin Schmelzer" />


<meta name="date" content="2023-07-12" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="4.3-rwxiabv.html"/>
<link rel="next" href="4.5-the-gauss-markov-theorem.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<!-- font families -->

<link href="https://fonts.googleapis.com/css?family=PT+Sans|Pacifico|Source+Sans+Pro" rel="stylesheet">

<script src="js/hideOutput.js"></script>

<!-- Mathjax -->
<script type="text/javascript" id="MathJax-script" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/mml-chtml.min.js"></script>

 <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        extensions: ["tex2jax.js", "TeX/AMSmath.js"],
        tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
        jax: ["input/TeX","output/CommonHTML"]
      });
      MathJax.Hub.processSectionDelay = 0;
  </script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110299877-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110299877-1');
</script>

<!-- open review block -->

<script type="application/json" class="js-hypothesis-config">
{
"showHighlights": false
}
</script>
<script async defer src="https://hypothes.is/embed.js"></script>



<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><center><img src="images/logo.png" alt="logo" width="50%" height="50%"style="margin: 15px 0 0 0"></center></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="1-introduction.html"><a href="1-introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="1.1-colophon.html"><a href="1.1-colophon.html"><i class="fa fa-check"></i><b>1.1</b> Colophon</a></li>
<li class="chapter" data-level="1.2" data-path="1.2-a-very-short-introduction-to-r-and-rstudio.html"><a href="1.2-a-very-short-introduction-to-r-and-rstudio.html"><i class="fa fa-check"></i><b>1.2</b> A Very Short Introduction to <tt>R</tt> and <em>RStudio</em></a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-arosur.html"><a href="2-arosur.html"><i class="fa fa-check"></i><b>2</b> A Review of Statistics using R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="2.1-estimation-of-the-population-mean.html"><a href="2.1-estimation-of-the-population-mean.html"><i class="fa fa-check"></i><b>2.1</b> Estimation of the Population Mean</a></li>
<li class="chapter" data-level="2.2" data-path="2.2-potsm.html"><a href="2.2-potsm.html"><i class="fa fa-check"></i><b>2.2</b> Properties of the Sample Mean</a></li>
<li class="chapter" data-level="2.3" data-path="2.3-hypothesis-tests-concerning-the-population-mean.html"><a href="2.3-hypothesis-tests-concerning-the-population-mean.html"><i class="fa fa-check"></i><b>2.3</b> Hypothesis Tests Concerning the Population Mean</a>
<ul>
<li class="chapter" data-level="" data-path="2.3-hypothesis-tests-concerning-the-population-mean.html"><a href="2.3-hypothesis-tests-concerning-the-population-mean.html#the-p-value"><i class="fa fa-check"></i>The p-Value</a></li>
<li class="chapter" data-level="" data-path="2.3-hypothesis-tests-concerning-the-population-mean.html"><a href="2.3-hypothesis-tests-concerning-the-population-mean.html#calculating-the-p-value-when-the-standard-deviation-is-known"><i class="fa fa-check"></i>Calculating the p-Value when the Standard Deviation is Known</a></li>
<li class="chapter" data-level="" data-path="2.3-hypothesis-tests-concerning-the-population-mean.html"><a href="2.3-hypothesis-tests-concerning-the-population-mean.html#SVSSDASE"><i class="fa fa-check"></i>Sample Variance, Sample Standard Deviation and Standard Error</a></li>
<li class="chapter" data-level="" data-path="2.3-hypothesis-tests-concerning-the-population-mean.html"><a href="2.3-hypothesis-tests-concerning-the-population-mean.html#calculating-the-p-value-when-the-standard-deviation-is-unknown"><i class="fa fa-check"></i>Calculating the p-value When the Standard Deviation is Unknown</a></li>
<li class="chapter" data-level="" data-path="2.3-hypothesis-tests-concerning-the-population-mean.html"><a href="2.3-hypothesis-tests-concerning-the-population-mean.html#the-t-statistic"><i class="fa fa-check"></i>The t-statistic</a></li>
<li class="chapter" data-level="" data-path="2.3-hypothesis-tests-concerning-the-population-mean.html"><a href="2.3-hypothesis-tests-concerning-the-population-mean.html#hypothesis-testing-with-a-prespecified-significance-level"><i class="fa fa-check"></i>Hypothesis Testing with a Prespecified Significance Level</a></li>
<li class="chapter" data-level="" data-path="2.3-hypothesis-tests-concerning-the-population-mean.html"><a href="2.3-hypothesis-tests-concerning-the-population-mean.html#one-sided-alternatives"><i class="fa fa-check"></i>One-sided Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="2.4-confidence-intervals-for-the-population-mean.html"><a href="2.4-confidence-intervals-for-the-population-mean.html"><i class="fa fa-check"></i><b>2.4</b> Confidence Intervals for the Population Mean</a></li>
<li class="chapter" data-level="2.5" data-path="2.5-cmfdp.html"><a href="2.5-cmfdp.html"><i class="fa fa-check"></i><b>2.5</b> Comparing Means from Different Populations</a></li>
<li class="chapter" data-level="2.6" data-path="2.6-aattggoe.html"><a href="2.6-aattggoe.html"><i class="fa fa-check"></i><b>2.6</b> An Application to the Gender Gap of Earnings</a></li>
<li class="chapter" data-level="2.7" data-path="2.7-scatterplots-sample-covariance-and-sample-correlation.html"><a href="2.7-scatterplots-sample-covariance-and-sample-correlation.html"><i class="fa fa-check"></i><b>2.7</b> Scatterplots, Sample Covariance and Sample Correlation</a></li>
<li class="chapter" data-level="2.8" data-path="2.8-exercises-3.html"><a href="2.8-exercises-3.html"><i class="fa fa-check"></i><b>2.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-lrwor.html"><a href="3-lrwor.html"><i class="fa fa-check"></i><b>3</b> Linear Regression with One Regressor</a>
<ul>
<li class="chapter" data-level="3.1" data-path="3.1-simple-linear-regression.html"><a href="3.1-simple-linear-regression.html"><i class="fa fa-check"></i><b>3.1</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="3.2" data-path="3.2-estimating-the-coefficients-of-the-linear-regression-model.html"><a href="3.2-estimating-the-coefficients-of-the-linear-regression-model.html"><i class="fa fa-check"></i><b>3.2</b> Estimating the Coefficients of the Linear Regression Model</a>
<ul>
<li class="chapter" data-level="" data-path="3.2-estimating-the-coefficients-of-the-linear-regression-model.html"><a href="3.2-estimating-the-coefficients-of-the-linear-regression-model.html#the-ordinary-least-squares-estimator"><i class="fa fa-check"></i>The Ordinary Least Squares Estimator</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="3.3-measures-of-fit.html"><a href="3.3-measures-of-fit.html"><i class="fa fa-check"></i><b>3.3</b> Measures of Fit</a>
<ul>
<li class="chapter" data-level="" data-path="3.3-measures-of-fit.html"><a href="3.3-measures-of-fit.html#the-coefficient-of-determination"><i class="fa fa-check"></i>The Coefficient of Determination</a></li>
<li class="chapter" data-level="" data-path="3.3-measures-of-fit.html"><a href="3.3-measures-of-fit.html#the-standard-error-of-the-regression"><i class="fa fa-check"></i>The Standard Error of the Regression</a></li>
<li class="chapter" data-level="" data-path="3.3-measures-of-fit.html"><a href="3.3-measures-of-fit.html#application-to-the-test-score-data"><i class="fa fa-check"></i>Application to the Test Score Data</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="3.4-tlsa.html"><a href="3.4-tlsa.html"><i class="fa fa-check"></i><b>3.4</b> The Least Squares Assumptions</a>
<ul>
<li class="chapter" data-level="" data-path="3.4-tlsa.html"><a href="3.4-tlsa.html#assumption-1-the-error-term-has-conditional-mean-of-zero"><i class="fa fa-check"></i>Assumption 1: The Error Term has Conditional Mean of Zero</a></li>
<li class="chapter" data-level="" data-path="3.4-tlsa.html"><a href="3.4-tlsa.html#assumption-2-independently-and-identically-distributed-data"><i class="fa fa-check"></i>Assumption 2: Independently and Identically Distributed Data</a></li>
<li class="chapter" data-level="" data-path="3.4-tlsa.html"><a href="3.4-tlsa.html#assumption-3-large-outliers-are-unlikely"><i class="fa fa-check"></i>Assumption 3: Large Outliers are Unlikely</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="3.5-tsdotoe.html"><a href="3.5-tsdotoe.html"><i class="fa fa-check"></i><b>3.5</b> The Sampling Distribution of the OLS Estimator</a>
<ul>
<li class="chapter" data-level="" data-path="3.5-tsdotoe.html"><a href="3.5-tsdotoe.html#simulation-study-1"><i class="fa fa-check"></i>Simulation Study 1</a></li>
<li class="chapter" data-level="" data-path="3.5-tsdotoe.html"><a href="3.5-tsdotoe.html#simulation-study-2"><i class="fa fa-check"></i>Simulation Study 2</a></li>
<li class="chapter" data-level="" data-path="3.5-tsdotoe.html"><a href="3.5-tsdotoe.html#simulation-study-3"><i class="fa fa-check"></i>Simulation Study 3</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="3.6-exercises-4.html"><a href="3.6-exercises-4.html"><i class="fa fa-check"></i><b>3.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-htaciitslrm.html"><a href="4-htaciitslrm.html"><i class="fa fa-check"></i><b>4</b> Hypothesis Tests and Confidence Intervals in the Simple Linear Regression Model</a>
<ul>
<li class="chapter" data-level="4.1" data-path="4.1-testing-two-sided-hypotheses-concerning-the-slope-coefficient.html"><a href="4.1-testing-two-sided-hypotheses-concerning-the-slope-coefficient.html"><i class="fa fa-check"></i><b>4.1</b> Testing Two-Sided Hypotheses Concerning the Slope Coefficient</a></li>
<li class="chapter" data-level="4.2" data-path="4.2-cifrc.html"><a href="4.2-cifrc.html"><i class="fa fa-check"></i><b>4.2</b> Confidence Intervals for Regression Coefficients</a>
<ul>
<li class="chapter" data-level="" data-path="4.2-cifrc.html"><a href="4.2-cifrc.html#simulation-study-confidence-intervals"><i class="fa fa-check"></i>Simulation Study: Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="4.3-rwxiabv.html"><a href="4.3-rwxiabv.html"><i class="fa fa-check"></i><b>4.3</b> Regression when X is a Binary Variable</a></li>
<li class="chapter" data-level="4.4" data-path="4.4-hah.html"><a href="4.4-hah.html"><i class="fa fa-check"></i><b>4.4</b> Heteroskedasticity and Homoskedasticity</a>
<ul>
<li class="chapter" data-level="" data-path="4.4-hah.html"><a href="4.4-hah.html#a-real-world-example-for-heteroskedasticity"><i class="fa fa-check"></i>A Real-World Example for Heteroskedasticity</a></li>
<li class="chapter" data-level="" data-path="4.4-hah.html"><a href="4.4-hah.html#should-we-care-about-heteroskedasticity"><i class="fa fa-check"></i>Should We Care About Heteroskedasticity?</a></li>
<li class="chapter" data-level="" data-path="4.4-hah.html"><a href="4.4-hah.html#computation-of-heteroskedasticity-robust-standard-errors"><i class="fa fa-check"></i>Computation of Heteroskedasticity-Robust Standard Errors</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="4.5-the-gauss-markov-theorem.html"><a href="4.5-the-gauss-markov-theorem.html"><i class="fa fa-check"></i><b>4.5</b> The Gauss-Markov Theorem</a>
<ul>
<li class="chapter" data-level="" data-path="4.5-the-gauss-markov-theorem.html"><a href="4.5-the-gauss-markov-theorem.html#simulation-study-blue-estimator"><i class="fa fa-check"></i>Simulation Study: BLUE Estimator</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="4.6-using-the-t-statistic-in-regression-when-the-sample-size-is-small.html"><a href="4.6-using-the-t-statistic-in-regression-when-the-sample-size-is-small.html"><i class="fa fa-check"></i><b>4.6</b> Using the t-Statistic in Regression When the Sample Size Is Small</a></li>
<li class="chapter" data-level="4.7" data-path="4.7-exercises-5.html"><a href="4.7-exercises-5.html"><i class="fa fa-check"></i><b>4.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Econometrics with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div class = rmdreview>
This book is in <b>Open Review</b>. We want your feedback to make the book better for you and other students. You may annotate some text by <span style="background-color: #3297FD; color: white">selecting it with the cursor</span> and then click "Annotate" in the pop-up menu. You can also see the annotations of others: click the arrow in the upper right hand corner of the page <i class="fa fa-arrow-circle-right  fa-rotate-315" aria-hidden="true"></i>
</div>
<div id="hah" class="section level2 hasAnchor" number="4.4">
<h2><span class="header-section-number">4.4</span> Heteroskedasticity and Homoskedasticity<a href="4.4-hah.html#hah" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>All inference made in the previous chapters relies on the assumption that the error variance does not vary as regressor values change. But this will often not be the case in empirical applications.</p>
<div id="KC5.4" class="keyconcept">
<h3 class="right">
Key Concept 5.4
</h3>
<h3 class="left">
Heteroskedasticity and Homoskedasticity
</h3>
<ul>
<li><p>The error term of our regression model is homoskedastic if the variance of the conditional distribution of <span class="math inline">\(u_i\)</span> given <span class="math inline">\(X_i\)</span>, <span class="math inline">\(Var(u_i|X_i=x)\)</span>, is constant <em>for all</em> observations in our sample:
<span class="math display">\[ \text{Var}(u_i|X_i=x) = \sigma^2 \ \forall \ i=1,\dots,n. \]</span></p></li>
<li><p>If instead there is dependence of the conditional variance of <span class="math inline">\(u_i\)</span> on <span class="math inline">\(X_i\)</span>, the error term is said to be heteroskedastic. We then write
<span class="math display">\[ \text{Var}(u_i|X_i=x) = \sigma_i^2 \ \forall \ i=1,\dots,n. \]</span></p></li>
<li><p>Homoskedasticity is a <em>special case</em> of heteroskedasticity.</p></li>
</ul>
</div>
<p>For a better understanding of heteroskedasticity, we generate some bivariate heteroskedastic data, estimate a linear regression model and then use box plots to depict the conditional distributions of the residuals.</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="4.4-hah.html#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load scales package for adjusting color opacities</span></span>
<span id="cb85-2"><a href="4.4-hah.html#cb85-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(scales)</span>
<span id="cb85-3"><a href="4.4-hah.html#cb85-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-4"><a href="4.4-hah.html#cb85-4" aria-hidden="true" tabindex="-1"></a><span class="co"># generate some heteroskedastic data:</span></span>
<span id="cb85-5"><a href="4.4-hah.html#cb85-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-6"><a href="4.4-hah.html#cb85-6" aria-hidden="true" tabindex="-1"></a><span class="co"># set seed for reproducibility</span></span>
<span id="cb85-7"><a href="4.4-hah.html#cb85-7" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>) </span>
<span id="cb85-8"><a href="4.4-hah.html#cb85-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-9"><a href="4.4-hah.html#cb85-9" aria-hidden="true" tabindex="-1"></a><span class="co"># set up vector of x coordinates</span></span>
<span id="cb85-10"><a href="4.4-hah.html#cb85-10" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">15</span>, <span class="dv">20</span>, <span class="dv">25</span>), <span class="at">each =</span> <span class="dv">25</span>)</span>
<span id="cb85-11"><a href="4.4-hah.html#cb85-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-12"><a href="4.4-hah.html#cb85-12" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize vector of errors</span></span>
<span id="cb85-13"><a href="4.4-hah.html#cb85-13" aria-hidden="true" tabindex="-1"></a>e <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb85-14"><a href="4.4-hah.html#cb85-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-15"><a href="4.4-hah.html#cb85-15" aria-hidden="true" tabindex="-1"></a><span class="co"># sample 100 errors such that the variance increases with x</span></span>
<span id="cb85-16"><a href="4.4-hah.html#cb85-16" aria-hidden="true" tabindex="-1"></a>e[<span class="dv">1</span><span class="sc">:</span><span class="dv">25</span>] <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">25</span>, <span class="at">sd =</span> <span class="dv">10</span>)</span>
<span id="cb85-17"><a href="4.4-hah.html#cb85-17" aria-hidden="true" tabindex="-1"></a>e[<span class="dv">26</span><span class="sc">:</span><span class="dv">50</span>] <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">25</span>, <span class="at">sd =</span> <span class="dv">15</span>)</span>
<span id="cb85-18"><a href="4.4-hah.html#cb85-18" aria-hidden="true" tabindex="-1"></a>e[<span class="dv">51</span><span class="sc">:</span><span class="dv">75</span>] <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">25</span>, <span class="at">sd =</span> <span class="dv">20</span>)</span>
<span id="cb85-19"><a href="4.4-hah.html#cb85-19" aria-hidden="true" tabindex="-1"></a>e[<span class="dv">76</span><span class="sc">:</span><span class="dv">100</span>] <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">25</span>, <span class="at">sd =</span> <span class="dv">25</span>)</span>
<span id="cb85-20"><a href="4.4-hah.html#cb85-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-21"><a href="4.4-hah.html#cb85-21" aria-hidden="true" tabindex="-1"></a><span class="co"># set up y</span></span>
<span id="cb85-22"><a href="4.4-hah.html#cb85-22" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">720</span> <span class="sc">-</span> <span class="fl">3.3</span> <span class="sc">*</span> x <span class="sc">+</span> e</span>
<span id="cb85-23"><a href="4.4-hah.html#cb85-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-24"><a href="4.4-hah.html#cb85-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate the model </span></span>
<span id="cb85-25"><a href="4.4-hah.html#cb85-25" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x)</span>
<span id="cb85-26"><a href="4.4-hah.html#cb85-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-27"><a href="4.4-hah.html#cb85-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the data</span></span>
<span id="cb85-28"><a href="4.4-hah.html#cb85-28" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> x, </span>
<span id="cb85-29"><a href="4.4-hah.html#cb85-29" aria-hidden="true" tabindex="-1"></a>     <span class="at">y =</span> y, </span>
<span id="cb85-30"><a href="4.4-hah.html#cb85-30" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;An Example of Heteroskedasticity&quot;</span>,</span>
<span id="cb85-31"><a href="4.4-hah.html#cb85-31" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Student-Teacher Ratio&quot;</span>,</span>
<span id="cb85-32"><a href="4.4-hah.html#cb85-32" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;Test Score&quot;</span>,</span>
<span id="cb85-33"><a href="4.4-hah.html#cb85-33" aria-hidden="true" tabindex="-1"></a>     <span class="at">cex =</span> <span class="fl">0.5</span>, </span>
<span id="cb85-34"><a href="4.4-hah.html#cb85-34" aria-hidden="true" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">19</span>, </span>
<span id="cb85-35"><a href="4.4-hah.html#cb85-35" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">8</span>, <span class="dv">27</span>), </span>
<span id="cb85-36"><a href="4.4-hah.html#cb85-36" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">600</span>, <span class="dv">710</span>))</span>
<span id="cb85-37"><a href="4.4-hah.html#cb85-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-38"><a href="4.4-hah.html#cb85-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Add the regression line to the plot</span></span>
<span id="cb85-39"><a href="4.4-hah.html#cb85-39" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(mod, <span class="at">col =</span> <span class="st">&quot;darkred&quot;</span>)</span>
<span id="cb85-40"><a href="4.4-hah.html#cb85-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-41"><a href="4.4-hah.html#cb85-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Add boxplots to the plot</span></span>
<span id="cb85-42"><a href="4.4-hah.html#cb85-42" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span>(<span class="at">formula =</span> y <span class="sc">~</span> x, </span>
<span id="cb85-43"><a href="4.4-hah.html#cb85-43" aria-hidden="true" tabindex="-1"></a>        <span class="at">add =</span> <span class="cn">TRUE</span>, </span>
<span id="cb85-44"><a href="4.4-hah.html#cb85-44" aria-hidden="true" tabindex="-1"></a>        <span class="at">at =</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">15</span>, <span class="dv">20</span>, <span class="dv">25</span>), </span>
<span id="cb85-45"><a href="4.4-hah.html#cb85-45" aria-hidden="true" tabindex="-1"></a>        <span class="at">col =</span> <span class="fu">alpha</span>(<span class="st">&quot;gray&quot;</span>, <span class="fl">0.4</span>), </span>
<span id="cb85-46"><a href="4.4-hah.html#cb85-46" aria-hidden="true" tabindex="-1"></a>        <span class="at">border =</span> <span class="st">&quot;black&quot;</span>)</span></code></pre></div>
<p><img src="ITER_files/figure-html/unnamed-chunk-146-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>We have used the <tt>formula</tt> argument <tt>y ~ x</tt> in <tt>boxplot()</tt> to specify that we want to split up the vector <tt>y</tt> into groups according to <tt>x</tt>. <tt>boxplot(y ~ x)</tt> generates a boxplot for each of the groups in <tt>y</tt> defined by <tt>x</tt>.</p>
<p>For this artificial data it is clear that the conditional error variances differ. Specifically, we observe that the variance in test scores (and therefore the variance of the errors committed) <em>increases</em> with the student teacher ratio.</p>
<div id="a-real-world-example-for-heteroskedasticity" class="section level3 unnumbered hasAnchor">
<h3>A Real-World Example for Heteroskedasticity<a href="4.4-hah.html#a-real-world-example-for-heteroskedasticity" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Think about the economic value of education: if there were no expected economic value-added to receiving university education, you probably would not be reading this script right now. A starting point to empirically verify such a relation is to have data on working individuals. More precisely, we need data on wages and education of workers in order to estimate a model like</p>
<p><span class="math display">\[ wage_i = \beta_0 + \beta_1 \cdot education_i + u_i. \]</span></p>
<p>What can be presumed about this relation? It is likely that, on average, higher educated workers earn more than workers with less education, so we expect to estimate an upward sloping regression line. Also, it seems plausible that earnings of better educated workers have a higher dispersion than those of low-skilled workers: solid education is not a guarantee for a high salary so even highly qualified workers take on low-income jobs. However, they are more likely to meet the requirements for the well-paid jobs than workers with less education for whom opportunities in the labor market are much more limited.</p>
<p>To verify this empirically we may use real data on hourly earnings and the number of years of education of employees. Such data can be found in <tt>CPSSWEducation</tt>. This data set is part of the package <tt>AER</tt> and comes from the Current Population Survey (CPS) which is conducted periodically by the <a href="http://www.bls.gov/">Bureau of Labor Statistics</a> in the United States.</p>
<p>The subsequent code chunks demonstrate how to import the data into <tt>R</tt> and how to produce a plot in the fashion of Figure 5.3 in the book.</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="4.4-hah.html#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load package and attach data</span></span>
<span id="cb86-2"><a href="4.4-hah.html#cb86-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(AER)</span>
<span id="cb86-3"><a href="4.4-hah.html#cb86-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;CPSSWEducation&quot;</span>)</span>
<span id="cb86-4"><a href="4.4-hah.html#cb86-4" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(CPSSWEducation)</span>
<span id="cb86-5"><a href="4.4-hah.html#cb86-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-6"><a href="4.4-hah.html#cb86-6" aria-hidden="true" tabindex="-1"></a><span class="co"># get an overview</span></span>
<span id="cb86-7"><a href="4.4-hah.html#cb86-7" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(CPSSWEducation)</span>
<span id="cb86-8"><a href="4.4-hah.html#cb86-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       age          gender        earnings        education    </span></span>
<span id="cb86-9"><a href="4.4-hah.html#cb86-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Min.   :29.0   female:1202   Min.   : 2.137   Min.   : 6.00  </span></span>
<span id="cb86-10"><a href="4.4-hah.html#cb86-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  1st Qu.:29.0   male  :1748   1st Qu.:10.577   1st Qu.:12.00  </span></span>
<span id="cb86-11"><a href="4.4-hah.html#cb86-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Median :29.0                 Median :14.615   Median :13.00  </span></span>
<span id="cb86-12"><a href="4.4-hah.html#cb86-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Mean   :29.5                 Mean   :16.743   Mean   :13.55  </span></span>
<span id="cb86-13"><a href="4.4-hah.html#cb86-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  3rd Qu.:30.0                 3rd Qu.:20.192   3rd Qu.:16.00  </span></span>
<span id="cb86-14"><a href="4.4-hah.html#cb86-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Max.   :30.0                 Max.   :97.500   Max.   :18.00</span></span>
<span id="cb86-15"><a href="4.4-hah.html#cb86-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-16"><a href="4.4-hah.html#cb86-16" aria-hidden="true" tabindex="-1"></a><span class="co"># estimate a simple regression model</span></span>
<span id="cb86-17"><a href="4.4-hah.html#cb86-17" aria-hidden="true" tabindex="-1"></a>labor_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(earnings <span class="sc">~</span> education)</span>
<span id="cb86-18"><a href="4.4-hah.html#cb86-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-19"><a href="4.4-hah.html#cb86-19" aria-hidden="true" tabindex="-1"></a><span class="co"># plot observations and add the regression line</span></span>
<span id="cb86-20"><a href="4.4-hah.html#cb86-20" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(education, </span>
<span id="cb86-21"><a href="4.4-hah.html#cb86-21" aria-hidden="true" tabindex="-1"></a>     earnings, </span>
<span id="cb86-22"><a href="4.4-hah.html#cb86-22" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">150</span>))</span>
<span id="cb86-23"><a href="4.4-hah.html#cb86-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-24"><a href="4.4-hah.html#cb86-24" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(labor_model, </span>
<span id="cb86-25"><a href="4.4-hah.html#cb86-25" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">&quot;steelblue&quot;</span>, </span>
<span id="cb86-26"><a href="4.4-hah.html#cb86-26" aria-hidden="true" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="ITER_files/figure-html/unnamed-chunk-147-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>The plot reveals that the mean of the distribution of earnings increases with the level of education. This is also supported by a formal analysis: the estimated regression model stored in <tt>labor_model</tt> shows that there is a positive relation between years of education and earnings.</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="4.4-hah.html#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="co"># print the contents of labor_model to the console</span></span>
<span id="cb87-2"><a href="4.4-hah.html#cb87-2" aria-hidden="true" tabindex="-1"></a>labor_model</span>
<span id="cb87-3"><a href="4.4-hah.html#cb87-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb87-4"><a href="4.4-hah.html#cb87-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb87-5"><a href="4.4-hah.html#cb87-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; lm(formula = earnings ~ education)</span></span>
<span id="cb87-6"><a href="4.4-hah.html#cb87-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb87-7"><a href="4.4-hah.html#cb87-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb87-8"><a href="4.4-hah.html#cb87-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; (Intercept)    education  </span></span>
<span id="cb87-9"><a href="4.4-hah.html#cb87-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      -3.134        1.467</span></span></code></pre></div>
<p>The estimated regression equation states that, on average, an additional year of education increases a worker’s hourly earnings by about <span class="math inline">\(\$ 1.47\)</span>. Once more we use <tt>confint()</tt> to obtain a <span class="math inline">\(95\%\)</span> confidence interval for both regression coefficients.</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="4.4-hah.html#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="co"># compute a 95% confidence interval for the coefficients in the model</span></span>
<span id="cb88-2"><a href="4.4-hah.html#cb88-2" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(labor_model)</span>
<span id="cb88-3"><a href="4.4-hah.html#cb88-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                 2.5 %    97.5 %</span></span>
<span id="cb88-4"><a href="4.4-hah.html#cb88-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; (Intercept) -5.015248 -1.253495</span></span>
<span id="cb88-5"><a href="4.4-hah.html#cb88-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; education    1.330098  1.603753</span></span></code></pre></div>
<p>Since the interval is <span class="math inline">\([1.33, 1.60]\)</span> we can reject the hypothesis that the coefficient on <tt>education</tt> is zero at the <span class="math inline">\(5\%\)</span> level.</p>
<p>Furthermore, the plot indicates that there is heteroskedasticity: if we assume the regression line to be a reasonably good representation of the conditional mean function <span class="math inline">\(E(earnings_i\vert education_i)\)</span>, the dispersion of hourly earnings around that function clearly increases with the level of education, i.e., the variance of the distribution of earnings increases. In other words: the variance of the errors (the errors made in explaining earnings by education) increases with education so that the regression errors are heteroskedastic.</p>
<p>This example makes a case that the assumption of homoskedasticity is doubtful in economic applications. Should we care about heteroskedasticity? Yes, we should. As explained in the next section, heteroskedasticity can have serious negative consequences in hypothesis testing, if we ignore it.</p>
</div>
<div id="should-we-care-about-heteroskedasticity" class="section level3 unnumbered hasAnchor">
<h3>Should We Care About Heteroskedasticity?<a href="4.4-hah.html#should-we-care-about-heteroskedasticity" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To answer the question whether we should worry about heteroskedasticity being present, consider the variance of <span class="math inline">\(\hat\beta_1\)</span> under the assumption of homoskedasticity. In this case we have</p>
<p><span class="math display">\[ \sigma^2_{\hat\beta_1} = \frac{\sigma^2_u}{n \cdot \sigma^2_X} \tag{5.5} \]</span></p>
<p>which is a simplified version of the general equation (<a href="#mjx-eqn-4.1">4.1</a>) presented in Key Concept 4.4. See Appendix 5.1 of the book for details on the derivation. <tt>summary()</tt> estimates (<a href="#mjx-eqn-5.5">5.5</a>) by</p>
<p><span class="math display">\[ \overset{\sim}{\sigma}^2_{\hat\beta_1} = \frac{SER^2}{\sum_{i=1}^n (X_i - \overline{X})^2} \ \ \text{where} \ \ SER=\frac{1}{n-2} \sum_{i=1}^n \hat u_i^2. \]</span></p>
<p>Thus <tt>summary()</tt> estimates the <em>homoskedasticity-only</em> standard error</p>
<p><span class="math display">\[ \sqrt{ \overset{\sim}{\sigma}^2_{\hat\beta_1} } = \sqrt{ \frac{SER^2}{\sum_{i=1}^n(X_i - \overline{X})^2} }. \]</span></p>
<p>This is in fact an estimator for the standard deviation of the estimator <span class="math inline">\(\hat{\beta}_1\)</span> that is <em>inconsistent</em> for the true value <span class="math inline">\(\sigma^2_{\hat\beta_1}\)</span> when there is heteroskedasticity. The implication is that <span class="math inline">\(t\)</span>-statistics computed in the manner of Key Concept 5.1 do not follow a standard normal distribution, even in large samples. This issue may invalidate inference when using the previously treated tools for hypothesis testing: we should be cautious when making statements about the significance of regression coefficients on the basis of <span class="math inline">\(t\)</span>-statistics as computed by <tt>summary()</tt> or confidence intervals produced by <tt>confint()</tt> if it is doubtful for the assumption of homoskedasticity to hold!</p>
<p>We will now use <tt>R</tt> to compute the homoskedasticity-only standard error for <span class="math inline">\(\hat{\beta}_1\)</span> in the regression model <tt>labor_model</tt> by hand and see that it matches the value produced by <tt>summary()</tt>.</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="4.4-hah.html#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Store model summary in &#39;model&#39;</span></span>
<span id="cb89-2"><a href="4.4-hah.html#cb89-2" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">summary</span>(labor_model)</span>
<span id="cb89-3"><a href="4.4-hah.html#cb89-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-4"><a href="4.4-hah.html#cb89-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the standard error of the regression from model summary</span></span>
<span id="cb89-5"><a href="4.4-hah.html#cb89-5" aria-hidden="true" tabindex="-1"></a>SER <span class="ot">&lt;-</span> model<span class="sc">$</span>sigma</span>
<span id="cb89-6"><a href="4.4-hah.html#cb89-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-7"><a href="4.4-hah.html#cb89-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the variation in &#39;education&#39;</span></span>
<span id="cb89-8"><a href="4.4-hah.html#cb89-8" aria-hidden="true" tabindex="-1"></a>V <span class="ot">&lt;-</span> (<span class="fu">nrow</span>(CPSSWEducation)<span class="sc">-</span><span class="dv">1</span>) <span class="sc">*</span> <span class="fu">var</span>(education)</span>
<span id="cb89-9"><a href="4.4-hah.html#cb89-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-10"><a href="4.4-hah.html#cb89-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the standard error of the slope parameter&#39;s estimator and print it</span></span>
<span id="cb89-11"><a href="4.4-hah.html#cb89-11" aria-hidden="true" tabindex="-1"></a>SE.beta_1.hat <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(SER<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>V)</span>
<span id="cb89-12"><a href="4.4-hah.html#cb89-12" aria-hidden="true" tabindex="-1"></a>SE.beta_1.hat</span>
<span id="cb89-13"><a href="4.4-hah.html#cb89-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.06978281</span></span>
<span id="cb89-14"><a href="4.4-hah.html#cb89-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-15"><a href="4.4-hah.html#cb89-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Use logical operators to see if the value computed by hand matches the one provided </span></span>
<span id="cb89-16"><a href="4.4-hah.html#cb89-16" aria-hidden="true" tabindex="-1"></a><span class="co"># in mod$coefficients. Round estimates to four decimal places</span></span>
<span id="cb89-17"><a href="4.4-hah.html#cb89-17" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(model<span class="sc">$</span>coefficients[<span class="dv">2</span>, <span class="dv">2</span>], <span class="dv">4</span>) <span class="sc">==</span> <span class="fu">round</span>(SE.beta_1.hat, <span class="dv">4</span>)</span>
<span id="cb89-18"><a href="4.4-hah.html#cb89-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] TRUE</span></span></code></pre></div>
<p>Indeed, the estimated values are equal.</p>
</div>
<div id="computation-of-heteroskedasticity-robust-standard-errors" class="section level3 unnumbered hasAnchor">
<h3>Computation of Heteroskedasticity-Robust Standard Errors<a href="4.4-hah.html#computation-of-heteroskedasticity-robust-standard-errors" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consistent estimation of <span class="math inline">\(\sigma_{\hat{\beta}_1}\)</span> under heteroskedasticity is granted when the following <em>robust</em> estimator is used.</p>
<p><span class="math display">\[ SE(\hat{\beta}_1) = \sqrt{ \frac{1}{n} \cdot \frac{ \frac{1}{n} \sum_{i=1}^n (X_i - \overline{X})^2 \hat{u}_i^2 }{ \left[ \frac{1}{n} \sum_{i=1}^n (X_i - \overline{X})^2  \right]^2} } \tag{5.6} \]</span></p>
<p>Standard error estimates computed this way are also referred to as <a href="https://en.wikipedia.org/wiki/Heteroscedasticity-consistent_standard_errors">Eicker-Huber-White standard errors</a>, the most frequently cited paper on this is <span class="citation">White (<a href="#ref-white1980" role="doc-biblioref">1980</a>)</span>.</p>
<p>It can be quite cumbersome to do this calculation by hand. Luckily certain R functions exist, serving that purpose. A convenient one named <tt>vcovHC()</tt> is part of the package <tt>sandwich</tt>.<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> This function can compute a variety of standard errors. The one brought forward in (<a href="#mjx-eqn-5.6">5.6</a>) is computed when the argument <tt>type</tt> is set to <tt>“HC0”</tt>. Most of the examples presented in the book rely on a slightly different formula which is the default in the statistics package <em>STATA</em>:</p>
<p><span class="math display" id="eq:hc1">\[\begin{align}
SE(\hat{\beta}_1)_{HC1} = \sqrt{ \frac{1}{n} \cdot \frac{ \frac{1}{n-2} \sum_{i=1}^n (X_i - \overline{X})^2 \hat{u}_i^2 }{ \left[ \frac{1}{n} \sum_{i=1}^n (X_i - \overline{X})^2  \right]^2}} \tag{4.2}
\end{align}\]</span></p>
<p>The difference is that we multiply by <span class="math inline">\(\frac{1}{n-2}\)</span> in the numerator of <a href="4.4-hah.html#eq:hc1">(4.2)</a>. This is a degrees of freedom correction and was considered by <span class="citation">MacKinnon and White (<a href="#ref-mackinnon1985" role="doc-biblioref">1985</a>)</span>. To get <tt>vcovHC()</tt> to use <a href="4.4-hah.html#eq:hc1">(4.2)</a>, we have to set <tt>type = “HC1”</tt>.</p>
<p>Let us now compute robust standard error estimates for the coefficients in <tt>linear_model</tt>.</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="4.4-hah.html#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="co"># compute heteroskedasticity-robust standard errors</span></span>
<span id="cb90-2"><a href="4.4-hah.html#cb90-2" aria-hidden="true" tabindex="-1"></a>vcov <span class="ot">&lt;-</span> <span class="fu">vcovHC</span>(linear_model, <span class="at">type =</span> <span class="st">&quot;HC1&quot;</span>)</span>
<span id="cb90-3"><a href="4.4-hah.html#cb90-3" aria-hidden="true" tabindex="-1"></a>vcov</span>
<span id="cb90-4"><a href="4.4-hah.html#cb90-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;             (Intercept)        STR</span></span>
<span id="cb90-5"><a href="4.4-hah.html#cb90-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; (Intercept)  107.419993 -5.3639114</span></span>
<span id="cb90-6"><a href="4.4-hah.html#cb90-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; STR           -5.363911  0.2698692</span></span></code></pre></div>
<p>The output of <tt>vcovHC()</tt> is the variance-covariance matrix of coefficient estimates. We are interested in the square root of the diagonal elements of this matrix, i.e., the standard error estimates.</p>

<div class="rmdknit">
<p>When we have k &gt; 1 regressors, writing down the equations for a regression model becomes very messy. A more convenient way to denote and estimate so-called multiple regression models (see Chapter 6) is by using matrix algebra. This is why functions like <tt>vcovHC()</tt> produce matrices. In the simple linear regression model, the variances and covariances of the estimators can be gathered in the symmetric variance-covariance matrix</p>
<p><span class="math display">\[\begin{equation}
\text{Var}
  \begin{pmatrix}
    \hat\beta_0 \\
    \hat\beta_1
  \end{pmatrix} =
\begin{pmatrix}
  \text{Var}(\hat\beta_0) &amp; \text{Cov}(\hat\beta_0,\hat\beta_1) \\
\text{Cov}(\hat\beta_0,\hat\beta_1) &amp; \text{Var}(\hat\beta_1)
\end{pmatrix},
\end{equation}\]</span></p>
<p>so <tt>vcovHC()</tt> gives us <span class="math inline">\(\widehat{\text{Var}}(\hat\beta_0)\)</span>, <span class="math inline">\(\widehat{\text{Var}}(\hat\beta_1)\)</span> and <span class="math inline">\(\widehat{\text{Cov}}(\hat\beta_0,\hat\beta_1)\)</span>, but most of the time we are interested in the diagonal elements of the estimated matrix.</p>
</div>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="4.4-hah.html#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="co"># compute the square root of the diagonal elements in vcov</span></span>
<span id="cb91-2"><a href="4.4-hah.html#cb91-2" aria-hidden="true" tabindex="-1"></a>robust_se <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">diag</span>(vcov))</span>
<span id="cb91-3"><a href="4.4-hah.html#cb91-3" aria-hidden="true" tabindex="-1"></a>robust_se</span>
<span id="cb91-4"><a href="4.4-hah.html#cb91-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; (Intercept)         STR </span></span>
<span id="cb91-5"><a href="4.4-hah.html#cb91-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  10.3643617   0.5194893</span></span></code></pre></div>
<p>Now assume we want to generate a coefficient summary as provided by <tt>summary()</tt> but with <em>robust</em> standard errors of the coefficient estimators, robust <span class="math inline">\(t\)</span>-statistics and corresponding <span class="math inline">\(p\)</span>-values for the regression model <tt>linear_model</tt>. This can be done using <tt>coeftest()</tt> from the package <tt>lmtest</tt>, see <code>?coeftest</code>. Further we specify in the argument <tt>vcov.</tt> that <tt>vcov</tt>, the Eicker-Huber-White estimate of the variance matrix we have computed before, should be used.</p>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="4.4-hah.html#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="co"># we invoke the function `coeftest()` on our model</span></span>
<span id="cb92-2"><a href="4.4-hah.html#cb92-2" aria-hidden="true" tabindex="-1"></a><span class="fu">coeftest</span>(linear_model, <span class="at">vcov. =</span> vcov)</span>
<span id="cb92-3"><a href="4.4-hah.html#cb92-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb92-4"><a href="4.4-hah.html#cb92-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; t test of coefficients:</span></span>
<span id="cb92-5"><a href="4.4-hah.html#cb92-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb92-6"><a href="4.4-hah.html#cb92-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;              Estimate Std. Error t value  Pr(&gt;|t|)    </span></span>
<span id="cb92-7"><a href="4.4-hah.html#cb92-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; (Intercept) 698.93295   10.36436 67.4362 &lt; 2.2e-16 ***</span></span>
<span id="cb92-8"><a href="4.4-hah.html#cb92-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; STR          -2.27981    0.51949 -4.3886 1.447e-05 ***</span></span>
<span id="cb92-9"><a href="4.4-hah.html#cb92-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb92-10"><a href="4.4-hah.html#cb92-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span></code></pre></div>
<p>We see that the values reported in the column <tt>Std.Error</tt> are equal those from <tt>sqrt(diag(vcov))</tt>.</p>
<p>How severe are the implications of using homoskedasticity-only standard errors in the presence of heteroskedasticity? The answer is: it depends. As mentioned above we face the risk of drawing wrong conclusions when conducting significance tests. <br> Let us illustrate this by generating another example of a heteroskedastic data set and using it to estimate a simple regression model. We take</p>
<p><span class="math display">\[ Y_i = \beta_1 \cdot X_i + u_i \ \ , \ \ u_i \overset{i.i.d.}{\sim} \mathcal{N}(0,0.36 \cdot X_i^2)  \]</span></p>
<p>with <span class="math inline">\(\beta_1=1\)</span> as the data generating process. Clearly, the assumption of homoskedasticity is violated here since the variance of the errors is a nonlinear, increasing function of <span class="math inline">\(X_i\)</span> but the errors have zero mean and are i.i.d. such that the assumptions made in Key Concept 4.3 are not violated. As before, we are interested in estimating <span class="math inline">\(\beta_1\)</span>.</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="4.4-hah.html#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">905</span>)</span>
<span id="cb93-2"><a href="4.4-hah.html#cb93-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-3"><a href="4.4-hah.html#cb93-3" aria-hidden="true" tabindex="-1"></a><span class="co"># generate heteroskedastic data </span></span>
<span id="cb93-4"><a href="4.4-hah.html#cb93-4" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">500</span></span>
<span id="cb93-5"><a href="4.4-hah.html#cb93-5" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> <span class="dv">500</span>, <span class="at">mean =</span> X, <span class="at">sd =</span> <span class="fl">0.6</span> <span class="sc">*</span> X)</span>
<span id="cb93-6"><a href="4.4-hah.html#cb93-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-7"><a href="4.4-hah.html#cb93-7" aria-hidden="true" tabindex="-1"></a><span class="co"># estimate a simple regression model</span></span>
<span id="cb93-8"><a href="4.4-hah.html#cb93-8" aria-hidden="true" tabindex="-1"></a>reg <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y <span class="sc">~</span> X)</span></code></pre></div>
<p>We plot the data and add the regression line.</p>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="4.4-hah.html#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the data</span></span>
<span id="cb94-2"><a href="4.4-hah.html#cb94-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y, </span>
<span id="cb94-3"><a href="4.4-hah.html#cb94-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">19</span>, </span>
<span id="cb94-4"><a href="4.4-hah.html#cb94-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span> <span class="st">&quot;steelblue&quot;</span>, </span>
<span id="cb94-5"><a href="4.4-hah.html#cb94-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">cex =</span> <span class="fl">0.8</span>)</span>
<span id="cb94-6"><a href="4.4-hah.html#cb94-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-7"><a href="4.4-hah.html#cb94-7" aria-hidden="true" tabindex="-1"></a><span class="co"># add the regression line to the plot</span></span>
<span id="cb94-8"><a href="4.4-hah.html#cb94-8" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(reg, </span>
<span id="cb94-9"><a href="4.4-hah.html#cb94-9" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">&quot;darkred&quot;</span>, </span>
<span id="cb94-10"><a href="4.4-hah.html#cb94-10" aria-hidden="true" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="fl">1.5</span>)</span></code></pre></div>
<p><img src="ITER_files/figure-html/unnamed-chunk-155-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>The plot shows that the data are heteroskedastic as the variance of <span class="math inline">\(Y\)</span> grows with <span class="math inline">\(X\)</span>. We next conduct a significance test of the (true) null hypothesis <span class="math inline">\(H_0: \beta_1 = 1\)</span> twice, once using the homoskedasticity-only standard error formula and once with the robust version (<a href="#mjx-eqn-5.6">5.6</a>). An easy way to do this in <tt>R</tt> is the function <tt>linearHypothesis()</tt> from the package <tt>car</tt>, see <code>?linearHypothesis</code>. It allows to test linear hypotheses about parameters in linear models in a similar way as done with a <span class="math inline">\(t\)</span>-statistic and offers various robust covariance matrix estimators. We test by comparing the tests’ <span class="math inline">\(p\)</span>-values to the significance level of <span class="math inline">\(5\%\)</span>.</p>

<div class="rmdknit">
<p><tt>linearHypothesis()</tt> computes a test statistic that follows an <span class="math inline">\(F\)</span>-distribution under the null hypothesis. We will not focus on the details of the underlying theory. In general, the idea of the <span class="math inline">\(F\)</span>-test is to compare the fit of different models. When testing a hypothesis about a <em>single</em> coefficient using an <span class="math inline">\(F\)</span>-test, one can show that the test statistic is simply the square of the corresponding <span class="math inline">\(t\)</span>-statistic:</p>
<p><span class="math display">\[F = t^2 = \left(\frac{\hat\beta_i - \beta_{i,0}}{SE(\hat\beta_i)}\right)^2 \sim F_{1,n-k-1}\]</span></p>
In <tt>linearHypothesis()</tt>, there are different ways to specify the hypothesis to be tested, e.g., using a vector of the type <tt>character</tt> (as done in the next code chunk), see <tt>?linearHypothesis</tt> for alternatives. The function returns an object of class <tt>anova</tt> which contains further information on the test that can be accessed using the <tt>$</tt> operator.
</div>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="4.4-hah.html#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="co"># test hypthesis using the default standard error formula</span></span>
<span id="cb95-2"><a href="4.4-hah.html#cb95-2" aria-hidden="true" tabindex="-1"></a><span class="fu">linearHypothesis</span>(reg, <span class="at">hypothesis.matrix =</span> <span class="st">&quot;X = 1&quot;</span>)<span class="sc">$</span><span class="st">&#39;Pr(&gt;F)&#39;</span>[<span class="dv">2</span>] <span class="sc">&lt;</span> <span class="fl">0.05</span></span>
<span id="cb95-3"><a href="4.4-hah.html#cb95-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] TRUE</span></span>
<span id="cb95-4"><a href="4.4-hah.html#cb95-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-5"><a href="4.4-hah.html#cb95-5" aria-hidden="true" tabindex="-1"></a><span class="co"># test hypothesis using the robust standard error formula</span></span>
<span id="cb95-6"><a href="4.4-hah.html#cb95-6" aria-hidden="true" tabindex="-1"></a><span class="fu">linearHypothesis</span>(reg, <span class="at">hypothesis.matrix =</span> <span class="st">&quot;X = 1&quot;</span>,</span>
<span id="cb95-7"><a href="4.4-hah.html#cb95-7" aria-hidden="true" tabindex="-1"></a>                      <span class="at">white.adjust =</span> <span class="st">&quot;hc1&quot;</span>)<span class="sc">$</span><span class="st">&#39;Pr(&gt;F)&#39;</span>[<span class="dv">2</span>] <span class="sc">&lt;</span> <span class="fl">0.05</span></span>
<span id="cb95-8"><a href="4.4-hah.html#cb95-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] FALSE</span></span></code></pre></div>
<p>This is a good example of what can go wrong if we ignore heteroskedasticity: for the data set at hand the default method rejects the null hypothesis <span class="math inline">\(\beta_1 = 1\)</span> although it is true. When using the robust standard error formula the test does not reject the null. Of course, we could think this might just be a coincidence and both tests do equally well in maintaining the type I error rate of <span class="math inline">\(5\%\)</span>. This can be further investigated by computing <em>Monte Carlo</em> estimates of the rejection frequencies of both tests on the basis of a large number of random samples. We proceed as follows:</p>
<ul>
<li>initialize vectors <tt>t</tt> and <tt>t.rob</tt>.</li>
<li>Using a <tt>for()</tt> loop, we generate <span class="math inline">\(10000\)</span> heteroskedastic random samples of size <span class="math inline">\(1000\)</span>, estimate the regression model and check whether the tests falsely reject the null at the level of <span class="math inline">\(5\%\)</span> using comparison operators. The results are stored in the respective vectors <tt>t</tt> and <tt>t.rob</tt>.</li>
<li>After the simulation, we compute the fraction of false rejections for both tests.</li>
</ul>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="4.4-hah.html#cb96-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-2"><a href="4.4-hah.html#cb96-2" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize vectors t and t.rob</span></span>
<span id="cb96-3"><a href="4.4-hah.html#cb96-3" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb96-4"><a href="4.4-hah.html#cb96-4" aria-hidden="true" tabindex="-1"></a>t.rob <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb96-5"><a href="4.4-hah.html#cb96-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-6"><a href="4.4-hah.html#cb96-6" aria-hidden="true" tabindex="-1"></a><span class="co"># loop sampling and estimation</span></span>
<span id="cb96-7"><a href="4.4-hah.html#cb96-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10000</span>) {</span>
<span id="cb96-8"><a href="4.4-hah.html#cb96-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb96-9"><a href="4.4-hah.html#cb96-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># sample data</span></span>
<span id="cb96-10"><a href="4.4-hah.html#cb96-10" aria-hidden="true" tabindex="-1"></a>  X <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">1000</span></span>
<span id="cb96-11"><a href="4.4-hah.html#cb96-11" aria-hidden="true" tabindex="-1"></a>  Y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> <span class="dv">1000</span>, <span class="at">mean =</span> X, <span class="at">sd =</span> <span class="fl">0.6</span> <span class="sc">*</span> X)</span>
<span id="cb96-12"><a href="4.4-hah.html#cb96-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-13"><a href="4.4-hah.html#cb96-13" aria-hidden="true" tabindex="-1"></a>  <span class="co"># estimate regression model</span></span>
<span id="cb96-14"><a href="4.4-hah.html#cb96-14" aria-hidden="true" tabindex="-1"></a>  reg <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y <span class="sc">~</span> X)</span>
<span id="cb96-15"><a href="4.4-hah.html#cb96-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-16"><a href="4.4-hah.html#cb96-16" aria-hidden="true" tabindex="-1"></a>  <span class="co"># homoskedasdicity-only significance test</span></span>
<span id="cb96-17"><a href="4.4-hah.html#cb96-17" aria-hidden="true" tabindex="-1"></a>  t[i] <span class="ot">&lt;-</span> <span class="fu">linearHypothesis</span>(reg, <span class="st">&quot;X = 1&quot;</span>)<span class="sc">$</span><span class="st">&#39;Pr(&gt;F)&#39;</span>[<span class="dv">2</span>] <span class="sc">&lt;</span> <span class="fl">0.05</span></span>
<span id="cb96-18"><a href="4.4-hah.html#cb96-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-19"><a href="4.4-hah.html#cb96-19" aria-hidden="true" tabindex="-1"></a>  <span class="co"># robust significance test</span></span>
<span id="cb96-20"><a href="4.4-hah.html#cb96-20" aria-hidden="true" tabindex="-1"></a>  t.rob[i] <span class="ot">&lt;-</span> <span class="fu">linearHypothesis</span>(reg, <span class="st">&quot;X = 1&quot;</span>, <span class="at">white.adjust =</span> <span class="st">&quot;hc1&quot;</span>)<span class="sc">$</span><span class="st">&#39;Pr(&gt;F)&#39;</span>[<span class="dv">2</span>] <span class="sc">&lt;</span> <span class="fl">0.05</span></span>
<span id="cb96-21"><a href="4.4-hah.html#cb96-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-22"><a href="4.4-hah.html#cb96-22" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb96-23"><a href="4.4-hah.html#cb96-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-24"><a href="4.4-hah.html#cb96-24" aria-hidden="true" tabindex="-1"></a><span class="co"># compute the fraction of false rejections</span></span>
<span id="cb96-25"><a href="4.4-hah.html#cb96-25" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">cbind</span>(<span class="at">t =</span> <span class="fu">mean</span>(t), <span class="at">t.rob =</span> <span class="fu">mean</span>(t.rob)), <span class="dv">3</span>)</span>
<span id="cb96-26"><a href="4.4-hah.html#cb96-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;          t t.rob</span></span>
<span id="cb96-27"><a href="4.4-hah.html#cb96-27" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1,] 0.073  0.05</span></span></code></pre></div>
<p>These results reveal the increased risk of falsely rejecting the null using the homoskedasticity-only standard error for the testing problem at hand: with the common standard error, <span class="math inline">\(7.28\%\)</span> of all tests falsely reject the null hypothesis. In contrast, with the robust test statistic we are closer to the nominal level of <span class="math inline">\(5\%\)</span>.</p>
</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-mackinnon1985" class="csl-entry">
MacKinnon, James G, and Halbert White. 1985. <span>“<span class="nocase">Some heteroskedasticity-consistent covariance matrix estimators with improved finite sample properties</span>.”</span> <em>Journal of Econometrics</em> 29 (3): 305–25.
</div>
<div id="ref-white1980" class="csl-entry">
White, Halbert. 1980. <span>“<span>A</span> <span>H</span>eteroskedasticity-<span>C</span>onsistent <span>C</span>ovariance <span>M</span>atrix <span>E</span>stimator and a <span>D</span>irect <span>T</span>est for <span>H</span>eteroskedasticity.”</span> <em><span>E</span>conometrica</em> 48 (4): pp. 817–838.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="5">
<li id="fn5"><p>The package <tt>sandwich</tt> is a dependency of the package <tt>AER</tt>, meaning that it is attached automatically if you load <tt>AER</tt>.<a href="4.4-hah.html#fnref5" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="4.3-rwxiabv.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="4.5-the-gauss-markov-theorem.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": true,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": {
"link": "https://github.com/mca91/EconometricsWithR/edit/master/05-ch5.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ITER.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
