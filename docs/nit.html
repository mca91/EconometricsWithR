<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Using R for Introduction to Econometrics</title>
  <meta name="description" content="Using <tt>R</tt> for Introduction to Econometrics">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Using R for Introduction to Econometrics" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="Emwikts1970/URFITE-Bookdown" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Using R for Introduction to Econometrics" />
  
  
  

<meta name="author" content="Christoph Hanck, Martin Arnold, Alexander Gerber and Martin Schmelzer">


<meta name="date" content="2018-07-20">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="llsuic.html">
<link rel="next" href="niib.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.2/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.7.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotlyjs-1.29.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotlyjs-1.29.2/plotly-latest.min.js"></script>
<script src="js/hideOutput.js"></script>
<script type="text/javascript" src="MathJax-2.7.2/MathJax.js?config=default"></script>

 <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        extensions: ["tex2jax.js", "TeX/AMSmath.js"],
        tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
        jax: ["input/TeX","output/CommonHTML"]
      });
      MathJax.Hub.processSectionDelay = 0;
  </script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110299877-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110299877-1');
</script>

<!-- open review block -->

<script async defer src="https://hypothes.is/embed.js"></script>

<!-- datacamp-light-latest -->

<script src="https://cdn.datacamp.com/datacamp-light-latest.min.js"></script>


<!-- <script src="js/d3.v3.min.js"></script>
<script src="js/leastsquares.js"></script>
<script src="js/d3functions.js"></script>
<script src="d3.slider.js"></script>
<script src="slrm.js"></script> -->


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #f8f8f8; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
pre, code { background-color: #f8f8f8; }
code > span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code > span.dt { color: #204a87; } /* DataType */
code > span.dv { color: #0000cf; } /* DecVal */
code > span.bn { color: #0000cf; } /* BaseN */
code > span.fl { color: #0000cf; } /* Float */
code > span.ch { color: #4e9a06; } /* Char */
code > span.st { color: #4e9a06; } /* String */
code > span.co { color: #8f5902; font-style: italic; } /* Comment */
code > span.ot { color: #8f5902; } /* Other */
code > span.al { color: #ef2929; } /* Alert */
code > span.fu { color: #000000; } /* Function */
code > span.er { color: #a40000; font-weight: bold; } /* Error */
code > span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #000000; } /* Constant */
code > span.sc { color: #000000; } /* SpecialChar */
code > span.vs { color: #4e9a06; } /* VerbatimString */
code > span.ss { color: #4e9a06; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #000000; } /* Variable */
code > span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code > span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code > span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code > span.ex { } /* Extension */
code > span.at { color: #c4a000; } /* Attribute */
code > span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code > span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">URFITE</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="a-very-short-introduction-to-r-and-rstudio.html"><a href="a-very-short-introduction-to-r-and-rstudio.html"><i class="fa fa-check"></i><b>1.1</b> A Very Short Introduction to <tt>R</tt> and <em>RStudio</em></a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="pt.html"><a href="pt.html"><i class="fa fa-check"></i><b>2</b> Probability Theory</a><ul>
<li class="chapter" data-level="2.1" data-path="random-variables-and-probability-distributions.html"><a href="random-variables-and-probability-distributions.html"><i class="fa fa-check"></i><b>2.1</b> Random Variables and Probability Distributions</a><ul>
<li class="chapter" data-level="" data-path="random-variables-and-probability-distributions.html"><a href="random-variables-and-probability-distributions.html#probability-distributions-of-discrete-random-variables"><i class="fa fa-check"></i>Probability Distributions of Discrete Random Variables</a></li>
<li class="chapter" data-level="" data-path="random-variables-and-probability-distributions.html"><a href="random-variables-and-probability-distributions.html#bernoulli-trials"><i class="fa fa-check"></i>Bernoulli Trials</a></li>
<li class="chapter" data-level="" data-path="random-variables-and-probability-distributions.html"><a href="random-variables-and-probability-distributions.html#expected-value-mean-and-variance"><i class="fa fa-check"></i>Expected Value, Mean and Variance</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="probability-distributions-of-continuous-random-variables.html"><a href="probability-distributions-of-continuous-random-variables.html"><i class="fa fa-check"></i><b>2.2</b> Probability Distributions of Continuous Random Variables</a><ul>
<li class="chapter" data-level="" data-path="probability-distributions-of-continuous-random-variables.html"><a href="probability-distributions-of-continuous-random-variables.html#the-normal-distribution"><i class="fa fa-check"></i>The Normal Distribution</a></li>
<li class="chapter" data-level="" data-path="probability-distributions-of-continuous-random-variables.html"><a href="probability-distributions-of-continuous-random-variables.html#the-chi-squared-distribution"><i class="fa fa-check"></i>The Chi-Squared Distribution</a></li>
<li class="chapter" data-level="" data-path="probability-distributions-of-continuous-random-variables.html"><a href="probability-distributions-of-continuous-random-variables.html#thetdist"><i class="fa fa-check"></i>The Student t Distribution</a></li>
<li class="chapter" data-level="" data-path="probability-distributions-of-continuous-random-variables.html"><a href="probability-distributions-of-continuous-random-variables.html#the-f-distribution"><i class="fa fa-check"></i>The F Distribution</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="RSATDOSA.html"><a href="RSATDOSA.html"><i class="fa fa-check"></i><b>2.3</b> Random Sampling and the Distribution of Sample Averages</a><ul>
<li class="chapter" data-level="" data-path="RSATDOSA.html"><a href="RSATDOSA.html#mean-and-variance-of-the-sample-mean"><i class="fa fa-check"></i>Mean and Variance of the Sample Mean</a></li>
<li class="chapter" data-level="" data-path="RSATDOSA.html"><a href="RSATDOSA.html#large-sample-approximations-to-sampling-distributions"><i class="fa fa-check"></i>Large Sample Approximations to Sampling Distributions</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>2.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="arosur.html"><a href="arosur.html"><i class="fa fa-check"></i><b>3</b> A Review of Statistics using R</a><ul>
<li class="chapter" data-level="3.1" data-path="estimation-of-the-population-mean.html"><a href="estimation-of-the-population-mean.html"><i class="fa fa-check"></i><b>3.1</b> Estimation of the Population Mean</a></li>
<li class="chapter" data-level="3.2" data-path="potsm.html"><a href="potsm.html"><i class="fa fa-check"></i><b>3.2</b> Properties of the Sample Mean</a></li>
<li class="chapter" data-level="3.3" data-path="hypothesis-tests-concerning-the-population-mean.html"><a href="hypothesis-tests-concerning-the-population-mean.html"><i class="fa fa-check"></i><b>3.3</b> Hypothesis Tests Concerning the Population Mean</a><ul>
<li class="chapter" data-level="" data-path="hypothesis-tests-concerning-the-population-mean.html"><a href="hypothesis-tests-concerning-the-population-mean.html#the-p-value"><i class="fa fa-check"></i>The p-Value</a></li>
<li class="chapter" data-level="" data-path="hypothesis-tests-concerning-the-population-mean.html"><a href="hypothesis-tests-concerning-the-population-mean.html#calculating-the-p-value-when-the-standard-deviation-is-known"><i class="fa fa-check"></i>Calculating the p-Value When the Standard Deviation Is Known</a></li>
<li class="chapter" data-level="" data-path="hypothesis-tests-concerning-the-population-mean.html"><a href="hypothesis-tests-concerning-the-population-mean.html#SVSSDASE"><i class="fa fa-check"></i>Sample Variance, Sample Standard Deviation and Standard Error</a></li>
<li class="chapter" data-level="" data-path="hypothesis-tests-concerning-the-population-mean.html"><a href="hypothesis-tests-concerning-the-population-mean.html#calculating-the-p-value-when-the-standard-deviation-is-unknown"><i class="fa fa-check"></i>Calculating the p-value When the Standard Deviation is Unknown</a></li>
<li class="chapter" data-level="" data-path="hypothesis-tests-concerning-the-population-mean.html"><a href="hypothesis-tests-concerning-the-population-mean.html#the-t-statistic"><i class="fa fa-check"></i>The t-statistic</a></li>
<li class="chapter" data-level="" data-path="hypothesis-tests-concerning-the-population-mean.html"><a href="hypothesis-tests-concerning-the-population-mean.html#hypothesis-testing-with-a-prespecified-significance-level"><i class="fa fa-check"></i>Hypothesis Testing with a Prespecified Significance Level</a></li>
<li class="chapter" data-level="" data-path="hypothesis-tests-concerning-the-population-mean.html"><a href="hypothesis-tests-concerning-the-population-mean.html#one-sided-alternatives"><i class="fa fa-check"></i>One-sided Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="confidence-intervals-for-the-population-mean.html"><a href="confidence-intervals-for-the-population-mean.html"><i class="fa fa-check"></i><b>3.4</b> Confidence Intervals for the Population Mean</a></li>
<li class="chapter" data-level="3.5" data-path="comparing-means-from-different-populations.html"><a href="comparing-means-from-different-populations.html"><i class="fa fa-check"></i><b>3.5</b> Comparing Means from Different Populations</a></li>
<li class="chapter" data-level="3.6" data-path="aattggoe.html"><a href="aattggoe.html"><i class="fa fa-check"></i><b>3.6</b> An Application to the Gender Gap of Earnings</a></li>
<li class="chapter" data-level="3.7" data-path="scatterplots-sample-covariance-and-sample-correlation.html"><a href="scatterplots-sample-covariance-and-sample-correlation.html"><i class="fa fa-check"></i><b>3.7</b> Scatterplots, Sample Covariance and Sample Correlation</a></li>
<li class="chapter" data-level="3.8" data-path="exercises-1.html"><a href="exercises-1.html"><i class="fa fa-check"></i><b>3.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="lrwor.html"><a href="lrwor.html"><i class="fa fa-check"></i><b>4</b> Linear Regression with One Regressor</a><ul>
<li class="chapter" data-level="4.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>4.1</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="4.2" data-path="estimating-the-coefficients-of-the-linear-regression-model.html"><a href="estimating-the-coefficients-of-the-linear-regression-model.html"><i class="fa fa-check"></i><b>4.2</b> Estimating the Coefficients of the Linear Regression Model</a><ul>
<li class="chapter" data-level="" data-path="estimating-the-coefficients-of-the-linear-regression-model.html"><a href="estimating-the-coefficients-of-the-linear-regression-model.html#the-ordinary-least-squares-estimator"><i class="fa fa-check"></i>The Ordinary Least Squares Estimator</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="measures-of-fit.html"><a href="measures-of-fit.html"><i class="fa fa-check"></i><b>4.3</b> Measures of Fit</a><ul>
<li class="chapter" data-level="" data-path="measures-of-fit.html"><a href="measures-of-fit.html#the-coefficient-of-determination"><i class="fa fa-check"></i>The Coefficient of Determination</a></li>
<li class="chapter" data-level="" data-path="measures-of-fit.html"><a href="measures-of-fit.html#the-standard-error-of-the-regression"><i class="fa fa-check"></i>The Standard Error of the Regression</a></li>
<li class="chapter" data-level="" data-path="measures-of-fit.html"><a href="measures-of-fit.html#application-to-the-test-score-data"><i class="fa fa-check"></i>Application to the Test Score Data</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="tlsa.html"><a href="tlsa.html"><i class="fa fa-check"></i><b>4.4</b> The Least Squares Assumptions</a><ul>
<li class="chapter" data-level="" data-path="tlsa.html"><a href="tlsa.html#assumption-1-the-error-term-has-conditional-mean-of-zero"><i class="fa fa-check"></i>Assumption 1: The Error Term has Conditional Mean of Zero</a></li>
<li class="chapter" data-level="" data-path="tlsa.html"><a href="tlsa.html#assumption-2-independently-and-identically-distributed-data"><i class="fa fa-check"></i>Assumption 2: Independently and Identically Distributed Data</a></li>
<li class="chapter" data-level="" data-path="tlsa.html"><a href="tlsa.html#assumption-3-large-outliers-are-unlikely"><i class="fa fa-check"></i>Assumption 3: Large Outliers are Unlikely</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="tsdotoe.html"><a href="tsdotoe.html"><i class="fa fa-check"></i><b>4.5</b> The Sampling Distribution of the OLS Estimator</a><ul>
<li class="chapter" data-level="" data-path="tsdotoe.html"><a href="tsdotoe.html#simulation-study-1"><i class="fa fa-check"></i>Simulation Study 1</a></li>
<li class="chapter" data-level="" data-path="tsdotoe.html"><a href="tsdotoe.html#simulation-study-2"><i class="fa fa-check"></i>Simulation Study 2</a></li>
<li class="chapter" data-level="" data-path="tsdotoe.html"><a href="tsdotoe.html#simulation-study-3"><i class="fa fa-check"></i>Simulation Study 3</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="exercises-2.html"><a href="exercises-2.html"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="htaciitslrm.html"><a href="htaciitslrm.html"><i class="fa fa-check"></i><b>5</b> Hypothesis Tests and Confidence Intervals in the Simple Linear Regression Model</a><ul>
<li class="chapter" data-level="5.1" data-path="testing-two-sided-hypotheses-concerning-the-slope-coefficient.html"><a href="testing-two-sided-hypotheses-concerning-the-slope-coefficient.html"><i class="fa fa-check"></i><b>5.1</b> Testing Two-Sided Hypotheses Concerning the Slope Coefficient</a></li>
<li class="chapter" data-level="5.2" data-path="cifrc.html"><a href="cifrc.html"><i class="fa fa-check"></i><b>5.2</b> Confidence Intervals for Regression Coefficients</a><ul>
<li class="chapter" data-level="" data-path="cifrc.html"><a href="cifrc.html#simulation-study-confidence-intervals"><i class="fa fa-check"></i>Simulation Study: Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="rwxiabv.html"><a href="rwxiabv.html"><i class="fa fa-check"></i><b>5.3</b> Regression when X is a Binary Variable</a></li>
<li class="chapter" data-level="5.4" data-path="heteroskedasticity-and-homoskedasticity.html"><a href="heteroskedasticity-and-homoskedasticity.html"><i class="fa fa-check"></i><b>5.4</b> Heteroskedasticity and Homoskedasticity</a><ul>
<li class="chapter" data-level="" data-path="heteroskedasticity-and-homoskedasticity.html"><a href="heteroskedasticity-and-homoskedasticity.html#a-real-world-example-for-heteroskedasticity"><i class="fa fa-check"></i>A Real-World Example for Heteroskedasticity</a></li>
<li class="chapter" data-level="" data-path="heteroskedasticity-and-homoskedasticity.html"><a href="heteroskedasticity-and-homoskedasticity.html#should-we-care-about-heteroskedasticity"><i class="fa fa-check"></i>Should We Care About Heteroskedasticity?</a></li>
<li class="chapter" data-level="" data-path="heteroskedasticity-and-homoskedasticity.html"><a href="heteroskedasticity-and-homoskedasticity.html#computation-of-heteroskedasticity-robust-standard-errors"><i class="fa fa-check"></i>Computation of Heteroskedasticity-Robust Standard Errors</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="the-gauss-markov-theorem.html"><a href="the-gauss-markov-theorem.html"><i class="fa fa-check"></i><b>5.5</b> The Gauss-Markov Theorem</a><ul>
<li class="chapter" data-level="" data-path="the-gauss-markov-theorem.html"><a href="the-gauss-markov-theorem.html#simulation-study-blue-estimator"><i class="fa fa-check"></i>Simulation Study: BLUE Estimator</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="using-the-t-statistic-in-regression-when-the-sample-size-is-small.html"><a href="using-the-t-statistic-in-regression-when-the-sample-size-is-small.html"><i class="fa fa-check"></i><b>5.6</b> Using the t-Statistic in Regression When the Sample Size Is Small</a></li>
<li class="chapter" data-level="5.7" data-path="exercises-3.html"><a href="exercises-3.html"><i class="fa fa-check"></i><b>5.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="rmwmr.html"><a href="rmwmr.html"><i class="fa fa-check"></i><b>6</b> Regression Models with Multiple Regressors</a><ul>
<li class="chapter" data-level="6.1" data-path="omitted-variable-bias.html"><a href="omitted-variable-bias.html"><i class="fa fa-check"></i><b>6.1</b> Omitted Variable Bias</a></li>
<li class="chapter" data-level="6.2" data-path="the-multiple-regression-model.html"><a href="the-multiple-regression-model.html"><i class="fa fa-check"></i><b>6.2</b> The Multiple Regression Model</a></li>
<li class="chapter" data-level="6.3" data-path="mofimr.html"><a href="mofimr.html"><i class="fa fa-check"></i><b>6.3</b> Measures of Fit in Multiple Regression</a></li>
<li class="chapter" data-level="6.4" data-path="ols-assumptions-in-multiple-regression.html"><a href="ols-assumptions-in-multiple-regression.html"><i class="fa fa-check"></i><b>6.4</b> OLS Assumptions in Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="ols-assumptions-in-multiple-regression.html"><a href="ols-assumptions-in-multiple-regression.html#multicollinearity"><i class="fa fa-check"></i>Multicollinearity</a></li>
<li class="chapter" data-level="" data-path="ols-assumptions-in-multiple-regression.html"><a href="ols-assumptions-in-multiple-regression.html#simulation-study-imperfect-multicollinearity"><i class="fa fa-check"></i>Simulation Study: Imperfect Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="the-distribution-of-the-ols-estimators-in-multiple-regression.html"><a href="the-distribution-of-the-ols-estimators-in-multiple-regression.html"><i class="fa fa-check"></i><b>6.5</b> The Distribution of the OLS Estimators in Multiple Regression</a></li>
<li class="chapter" data-level="6.6" data-path="exercises-4.html"><a href="exercises-4.html"><i class="fa fa-check"></i><b>6.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="htaciimr.html"><a href="htaciimr.html"><i class="fa fa-check"></i><b>7</b> Hypothesis Tests and Confidence Intervals in Multiple Regression</a><ul>
<li class="chapter" data-level="7.1" data-path="hypothesis-tests-and-confidence-intervals-for-a-single-coefficient.html"><a href="hypothesis-tests-and-confidence-intervals-for-a-single-coefficient.html"><i class="fa fa-check"></i><b>7.1</b> Hypothesis Tests and Confidence Intervals for a Single Coefficient</a></li>
<li class="chapter" data-level="7.2" data-path="an-application-to-test-scores-and-the-student-teacher-ratio.html"><a href="an-application-to-test-scores-and-the-student-teacher-ratio.html"><i class="fa fa-check"></i><b>7.2</b> An Application to Test Scores and the Student-Teacher Ratio</a><ul>
<li class="chapter" data-level="" data-path="an-application-to-test-scores-and-the-student-teacher-ratio.html"><a href="an-application-to-test-scores-and-the-student-teacher-ratio.html#another-augmentation-of-the-model"><i class="fa fa-check"></i>Another Augmentation of the Model</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="joint-hypothesis-testing-using-the-f-statistic.html"><a href="joint-hypothesis-testing-using-the-f-statistic.html"><i class="fa fa-check"></i><b>7.3</b> Joint Hypothesis Testing Using the F-Statistic</a></li>
<li class="chapter" data-level="7.4" data-path="confidence-sets-for-multiple-coefficients.html"><a href="confidence-sets-for-multiple-coefficients.html"><i class="fa fa-check"></i><b>7.4</b> Confidence Sets for Multiple Coefficients</a></li>
<li class="chapter" data-level="7.5" data-path="model-specification-for-multiple-regression.html"><a href="model-specification-for-multiple-regression.html"><i class="fa fa-check"></i><b>7.5</b> Model Specification for Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="model-specification-for-multiple-regression.html"><a href="model-specification-for-multiple-regression.html#model-specification-in-theory-and-in-practice"><i class="fa fa-check"></i>Model Specification in Theory and in Practice</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="analysis-of-the-test-score-data-set.html"><a href="analysis-of-the-test-score-data-set.html"><i class="fa fa-check"></i><b>7.6</b> Analysis of the Test Score Data Set</a></li>
<li class="chapter" data-level="7.7" data-path="exercises-5.html"><a href="exercises-5.html"><i class="fa fa-check"></i><b>7.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="nrf.html"><a href="nrf.html"><i class="fa fa-check"></i><b>8</b> Nonlinear Regression Functions</a><ul>
<li class="chapter" data-level="8.1" data-path="a-general-strategy-for-modelling-nonlinear-regression-functions.html"><a href="a-general-strategy-for-modelling-nonlinear-regression-functions.html"><i class="fa fa-check"></i><b>8.1</b> A General Strategy for Modelling Nonlinear Regression Functions</a></li>
<li class="chapter" data-level="8.2" data-path="nfoasiv.html"><a href="nfoasiv.html"><i class="fa fa-check"></i><b>8.2</b> Nonlinear Functions of a Single Independent Variable</a><ul>
<li class="chapter" data-level="" data-path="nfoasiv.html"><a href="nfoasiv.html#polynomials"><i class="fa fa-check"></i>Polynomials</a></li>
<li class="chapter" data-level="" data-path="nfoasiv.html"><a href="nfoasiv.html#logarithms"><i class="fa fa-check"></i>Logarithms</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="interactions-between-independent-variables.html"><a href="interactions-between-independent-variables.html"><i class="fa fa-check"></i><b>8.3</b> Interactions Between Independent Variables</a></li>
<li class="chapter" data-level="8.4" data-path="nonlinear-effects-on-test-scores-of-the-student-teacher-ratio.html"><a href="nonlinear-effects-on-test-scores-of-the-student-teacher-ratio.html"><i class="fa fa-check"></i><b>8.4</b> Nonlinear Effects on Test Scores of the Student-Teacher Ratio</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="asbomr.html"><a href="asbomr.html"><i class="fa fa-check"></i><b>9</b> Assessing Studies Based on Multiple Regression</a><ul>
<li class="chapter" data-level="9.1" data-path="internal-and-external-validity.html"><a href="internal-and-external-validity.html"><i class="fa fa-check"></i><b>9.1</b> Internal and External Validity</a></li>
<li class="chapter" data-level="9.2" data-path="threats-to-internal-validity-of-multiple-regression-analysis.html"><a href="threats-to-internal-validity-of-multiple-regression-analysis.html"><i class="fa fa-check"></i><b>9.2</b> Threats to Internal Validity of Multiple Regression Analysis</a></li>
<li class="chapter" data-level="9.3" data-path="internal-and-external-validity-when-the-regression-is-used-for-forecasting.html"><a href="internal-and-external-validity-when-the-regression-is-used-for-forecasting.html"><i class="fa fa-check"></i><b>9.3</b> Internal and External Validity When the Regression is Used for Forecasting</a></li>
<li class="chapter" data-level="9.4" data-path="etsacs.html"><a href="etsacs.html"><i class="fa fa-check"></i><b>9.4</b> Example: Test Scores and Class Size</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="rwpd.html"><a href="rwpd.html"><i class="fa fa-check"></i><b>10</b> Regression with Panel Data</a><ul>
<li class="chapter" data-level="10.1" data-path="panel-data.html"><a href="panel-data.html"><i class="fa fa-check"></i><b>10.1</b> Panel Data</a></li>
<li class="chapter" data-level="10.2" data-path="PDWTTP.html"><a href="PDWTTP.html"><i class="fa fa-check"></i><b>10.2</b> Panel Data with Two Time Periods: “Before and After” Comparisons</a></li>
<li class="chapter" data-level="10.3" data-path="fixed-effects-regression.html"><a href="fixed-effects-regression.html"><i class="fa fa-check"></i><b>10.3</b> Fixed Effects Regression</a><ul>
<li class="chapter" data-level="" data-path="fixed-effects-regression.html"><a href="fixed-effects-regression.html#estimation-and-inference"><i class="fa fa-check"></i>Estimation and Inference</a></li>
<li class="chapter" data-level="" data-path="fixed-effects-regression.html"><a href="fixed-effects-regression.html#application-to-traffic-deaths"><i class="fa fa-check"></i>Application to Traffic Deaths</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="regression-with-time-fixed-effects.html"><a href="regression-with-time-fixed-effects.html"><i class="fa fa-check"></i><b>10.4</b> Regression with Time Fixed Effects</a></li>
<li class="chapter" data-level="10.5" data-path="tferaaseffer.html"><a href="tferaaseffer.html"><i class="fa fa-check"></i><b>10.5</b> The Fixed Effects Regression Assumptions and Standard Errors for Fixed Effects Regression</a></li>
<li class="chapter" data-level="10.6" data-path="drunk-driving-laws-and-traffic-deaths.html"><a href="drunk-driving-laws-and-traffic-deaths.html"><i class="fa fa-check"></i><b>10.6</b> Drunk Driving Laws and Traffic Deaths</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="rwabdv.html"><a href="rwabdv.html"><i class="fa fa-check"></i><b>11</b> Regression with a Binary Dependent Variable</a><ul>
<li class="chapter" data-level="11.1" data-path="binary-dependent-variables-and-the-linear-probability-model.html"><a href="binary-dependent-variables-and-the-linear-probability-model.html"><i class="fa fa-check"></i><b>11.1</b> Binary Dependent Variables and the Linear Probability Model</a></li>
<li class="chapter" data-level="11.2" data-path="probit-and-logit-regression.html"><a href="probit-and-logit-regression.html"><i class="fa fa-check"></i><b>11.2</b> Probit and Logit Regression</a><ul>
<li class="chapter" data-level="" data-path="probit-and-logit-regression.html"><a href="probit-and-logit-regression.html#probit-regression"><i class="fa fa-check"></i>Probit Regression</a></li>
<li class="chapter" data-level="" data-path="probit-and-logit-regression.html"><a href="probit-and-logit-regression.html#logit-regression"><i class="fa fa-check"></i>Logit Regression</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="estimation-and-inference-in-the-logit-and-probit-models.html"><a href="estimation-and-inference-in-the-logit-and-probit-models.html"><i class="fa fa-check"></i><b>11.3</b> Estimation and Inference in the Logit and Probit Models</a></li>
<li class="chapter" data-level="11.4" data-path="application-to-the-boston-hmda-data.html"><a href="application-to-the-boston-hmda-data.html"><i class="fa fa-check"></i><b>11.4</b> Application to the Boston HMDA Data</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="ivr.html"><a href="ivr.html"><i class="fa fa-check"></i><b>12</b> Instrumental Variables Regression</a><ul>
<li class="chapter" data-level="12.1" data-path="TIVEWASRAASI.html"><a href="TIVEWASRAASI.html"><i class="fa fa-check"></i><b>12.1</b> The IV Estimator with a Single Regressor and a Single Instrument</a></li>
<li class="chapter" data-level="12.2" data-path="TGIVRM.html"><a href="TGIVRM.html"><i class="fa fa-check"></i><b>12.2</b> The General IV Regression Model</a></li>
<li class="chapter" data-level="12.3" data-path="civ.html"><a href="civ.html"><i class="fa fa-check"></i><b>12.3</b> Checking Instrument Validity</a></li>
<li class="chapter" data-level="12.4" data-path="attdfc.html"><a href="attdfc.html"><i class="fa fa-check"></i><b>12.4</b> Application to the Demand for Cigarettes</a></li>
<li class="chapter" data-level="12.5" data-path="where-do-valid-instruments-come-from.html"><a href="where-do-valid-instruments-come-from.html"><i class="fa fa-check"></i><b>12.5</b> Where Do Valid Instruments Come From?</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="eaqe.html"><a href="eaqe.html"><i class="fa fa-check"></i><b>13</b> Experiments and Quasi-Experiments</a><ul>
<li class="chapter" data-level="13.1" data-path="potential-outcomes-causal-effects-and-idealized-experiments.html"><a href="potential-outcomes-causal-effects-and-idealized-experiments.html"><i class="fa fa-check"></i><b>13.1</b> Potential Outcomes, Causal Effects and Idealized Experiments</a></li>
<li class="chapter" data-level="13.2" data-path="threats-to-validity-of-experiments.html"><a href="threats-to-validity-of-experiments.html"><i class="fa fa-check"></i><b>13.2</b> Threats to Validity of Experiments</a></li>
<li class="chapter" data-level="13.3" data-path="experimental-estimates-of-the-effect-of-class-size-reductions.html"><a href="experimental-estimates-of-the-effect-of-class-size-reductions.html"><i class="fa fa-check"></i><b>13.3</b> Experimental Estimates of the Effect of Class Size Reductions</a><ul>
<li class="chapter" data-level="" data-path="experimental-estimates-of-the-effect-of-class-size-reductions.html"><a href="experimental-estimates-of-the-effect-of-class-size-reductions.html#experimental-design-and-the-data-set"><i class="fa fa-check"></i>Experimental Design and the Data Set</a></li>
<li class="chapter" data-level="" data-path="experimental-estimates-of-the-effect-of-class-size-reductions.html"><a href="experimental-estimates-of-the-effect-of-class-size-reductions.html#analysis-of-the-star-data"><i class="fa fa-check"></i>Analysis of the STAR Data</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="quasi-experiments.html"><a href="quasi-experiments.html"><i class="fa fa-check"></i><b>13.4</b> Quasi Experiments</a><ul>
<li class="chapter" data-level="" data-path="quasi-experiments.html"><a href="quasi-experiments.html#the-differences-in-differences-estimator"><i class="fa fa-check"></i>The Differences-in-Differences Estimator</a></li>
<li class="chapter" data-level="" data-path="quasi-experiments.html"><a href="quasi-experiments.html#regression-discontinuity-estimators"><i class="fa fa-check"></i>Regression Discontinuity Estimators</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="ittsraf.html"><a href="ittsraf.html"><i class="fa fa-check"></i><b>14</b> Introduction to Time Series Regression and Forecasting</a><ul>
<li class="chapter" data-level="14.1" data-path="using-regression-models-for-forecasting.html"><a href="using-regression-models-for-forecasting.html"><i class="fa fa-check"></i><b>14.1</b> Using Regression Models for Forecasting</a></li>
<li class="chapter" data-level="14.2" data-path="tsdasc.html"><a href="tsdasc.html"><i class="fa fa-check"></i><b>14.2</b> Time Series Data and Serial Correlation</a><ul>
<li class="chapter" data-level="" data-path="tsdasc.html"><a href="tsdasc.html#notation-lags-differences-logarithms-and-growth-rates"><i class="fa fa-check"></i>Notation, Lags, Differences, Logarithms and Growth Rates</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="autoregressions.html"><a href="autoregressions.html"><i class="fa fa-check"></i><b>14.3</b> Autoregressions</a><ul>
<li class="chapter" data-level="" data-path="autoregressions.html"><a href="autoregressions.html#autoregressive-models-of-order-p"><i class="fa fa-check"></i>Autoregressive Models of Order p</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="cybtmpi.html"><a href="cybtmpi.html"><i class="fa fa-check"></i><b>14.4</b> Can You Beat the Market? (Part I)</a></li>
<li class="chapter" data-level="14.5" data-path="apatadlm.html"><a href="apatadlm.html"><i class="fa fa-check"></i><b>14.5</b> Additional Predictors and The ADL Model</a><ul>
<li class="chapter" data-level="" data-path="apatadlm.html"><a href="apatadlm.html#forecast-uncertainty-and-forecast-intervals"><i class="fa fa-check"></i>Forecast Uncertainty and Forecast Intervals</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="llsuic.html"><a href="llsuic.html"><i class="fa fa-check"></i><b>14.6</b> Lag Length Selection Using Information Criteria</a></li>
<li class="chapter" data-level="14.7" data-path="nit.html"><a href="nit.html"><i class="fa fa-check"></i><b>14.7</b> Nonstationarity I: Trends</a></li>
<li class="chapter" data-level="14.8" data-path="niib.html"><a href="niib.html"><i class="fa fa-check"></i><b>14.8</b> Nonstationarity II: Breaks</a></li>
<li class="chapter" data-level="14.9" data-path="can-you-beat-the-market-part-ii.html"><a href="can-you-beat-the-market-part-ii.html"><i class="fa fa-check"></i><b>14.9</b> Can You Beat the Market? (Part II)</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="eodce.html"><a href="eodce.html"><i class="fa fa-check"></i><b>15</b> Estimation of Dynamic Causal Effects</a><ul>
<li class="chapter" data-level="15.1" data-path="the-orange-juice-data.html"><a href="the-orange-juice-data.html"><i class="fa fa-check"></i><b>15.1</b> The Orange Juice Data</a></li>
<li class="chapter" data-level="15.2" data-path="dynamic-causal-effects.html"><a href="dynamic-causal-effects.html"><i class="fa fa-check"></i><b>15.2</b> Dynamic Causal Effects</a></li>
<li class="chapter" data-level="15.3" data-path="dynamic-multipliers-and-cumulative-dynamic-multipliers.html"><a href="dynamic-multipliers-and-cumulative-dynamic-multipliers.html"><i class="fa fa-check"></i><b>15.3</b> Dynamic Multipliers and Cumulative Dynamic Multipliers</a></li>
<li class="chapter" data-level="15.4" data-path="hac-standard-errors.html"><a href="hac-standard-errors.html"><i class="fa fa-check"></i><b>15.4</b> HAC Standard Errors</a></li>
<li class="chapter" data-level="15.5" data-path="estimation-of-dynamic-causal-effects-with-strictly-exogeneous-regressors.html"><a href="estimation-of-dynamic-causal-effects-with-strictly-exogeneous-regressors.html"><i class="fa fa-check"></i><b>15.5</b> Estimation of Dynamic Causal Effects with Strictly Exogeneous Regressors</a></li>
<li class="chapter" data-level="15.6" data-path="orange-juice-prices-and-cold-weather.html"><a href="orange-juice-prices-and-cold-weather.html"><i class="fa fa-check"></i><b>15.6</b> Orange Juice Prices and Cold Weather</a></li>
<li class="chapter" data-level="15.7" data-path="summary-7.html"><a href="summary-7.html"><i class="fa fa-check"></i><b>15.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="atitsr.html"><a href="atitsr.html"><i class="fa fa-check"></i><b>16</b> Additional Topics in Time Series Regression</a><ul>
<li class="chapter" data-level="16.1" data-path="vector-autoregressions.html"><a href="vector-autoregressions.html"><i class="fa fa-check"></i><b>16.1</b> Vector Autoregressions</a></li>
<li class="chapter" data-level="16.2" data-path="ooiatdfglsurt.html"><a href="ooiatdfglsurt.html"><i class="fa fa-check"></i><b>16.2</b> Orders of Integration and the DF-GLS Unit Root Test</a></li>
<li class="chapter" data-level="16.3" data-path="cointegration.html"><a href="cointegration.html"><i class="fa fa-check"></i><b>16.3</b> Cointegration</a></li>
<li class="chapter" data-level="16.4" data-path="volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><a href="volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><i class="fa fa-check"></i><b>16.4</b> Volatility Clustering and Autoregressive Conditional Heteroskedasticity</a><ul>
<li class="chapter" data-level="" data-path="volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><a href="volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html#arch-and-garch-models"><i class="fa fa-check"></i>ARCH and GARCH Models</a></li>
<li class="chapter" data-level="" data-path="volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><a href="volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html#application-to-stock-price-volatility"><i class="fa fa-check"></i>Application to Stock Price Volatility</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="summary-8.html"><a href="summary-8.html"><i class="fa fa-check"></i><b>16.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Using <tt>R</tt> for Introduction to Econometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div class = rmdreview>
This book is in <b>Open Review</b>. We want your feedback to make the book better for you and other students. You may annotate some text by <span style="background-color: #3297FD; color: white">selecting it with the cursor</span> and then click the <i class="h-icon-annotate"></i> on the pop-up menu. You can also see the annotations of others: click the <i class="h-icon-chevron-left"></i> in the upper right hand corner of the page <i class="fa fa-arrow-circle-right  fa-rotate-315" aria-hidden="true"></i>
</div>
<div id="nit" class="section level2">
<h2><span class="header-section-number">14.7</span> Nonstationarity I: Trends</h2>
<p>If a series is nonstationary, conventional hypothesis tests, confidence intervals and forecasts can be strongly misleading. The assumption of stationarity is violated if a series exhibits trends or breaks and the resulting complications in an econometric analysis depend on the specific type of the nonstationarity. This section focuses on time series that exhibit trends.</p>
<p>A series is said to exhibit a trend if it fluctuates around a persistent long-term movement. One distinguishes between <em>deterministic</em> and <em>stochastic</em> trends.</p>
<ul>
<li><p>A trend is <em>deterministic</em> if it is a nonrandom function of time.</p></li>
<li><p>A trend is said to be <em>stochastic</em> if it is a random function of time.</p></li>
</ul>
<p>A careful look at the figures we have produced in Chapter <a href="tsdasc.html#tsdasc">14.2</a> reveals that many economic time series show a trending behavior that is probably best modeled by stochastic trends. This is why the book focuses on the treatment of stochastic trends.</p>
<div id="the-random-walk-model-of-a-trend" class="section level4 unnumbered">
<h4>The Random Walk Model of a Trend</h4>
The simplest way to model a time series <span class="math inline">\(Y_t\)</span> that has stochastic trend is the <em>random walk</em>
<span class="math display" id="eq:randomwalk">\[\begin{align}
  Y_t = Y_{t-1} + u_t, \tag{14.6}
\end{align}\]</span>
where the <span class="math inline">\(u_t\)</span> are i.i.d. errors with <span class="math inline">\(E(u_t\vert Y_{t-1}, Y_{t-2}, \dots) = 0\)</span>. Note that
<span class="math display">\[\begin{align*}
  E(Y_t\vert Y_{t-1}, Y_{t-2}\dots) =&amp; \, E(Y_{t-1}\vert Y_{t-1}, Y_{t-2}\dots) + E(u_t\vert Y_{t-1}, Y_{t-2}\dots) \\
  =&amp; \, Y_{t-1}
\end{align*}\]</span>
<p>so the best forecast for <span class="math inline">\(Y_t\)</span>, today’s value of <span class="math inline">\(Y\)</span>, is <span class="math inline">\(Y_{t-1}\)</span>, the observation made yesterday so the difference between <span class="math inline">\(Y_t\)</span> and <span class="math inline">\(Y_{t-1}\)</span> is unpredictable. One can shows that the path followed by <span class="math inline">\(Y_t\)</span> consists of random steps <span class="math inline">\(u_t\)</span>, hence it is called a random walk.</p>
Assume that <span class="math inline">\(Y_0\)</span>, the starting value of the random walk is <span class="math inline">\(0\)</span>. Another way to write out <a href="nit.html#eq:randomwalk">(14.6)</a> is
<span class="math display">\[\begin{align*}
  Y_0 =&amp; \, 0 \\
  Y_1 =&amp; \, 0 + u_1 \\
  Y_2 =&amp; \, 0 + u_1 + u_2 \\
  \vdots &amp; \, \\
  Y_t =&amp; \, \sum_{i=1}^t u_i.
\end{align*}\]</span>
Therefore we have
<span class="math display">\[\begin{align*}
  var(Y_t) =&amp; \, Var(u_1 + u_2 + \dots + u_t) \\
           =&amp; \, t \sigma_u^2.
\end{align*}\]</span>
<p>Thus the variance of a random walk depends on <span class="math inline">\(t\)</span> which violates the assumption presented in Key Concept 14.5: a random walk is nonstationary.</p>
<p>Obviously, <a href="nit.html#eq:randomwalk">(14.6)</a> is a special case of an AR(<span class="math inline">\(1\)</span>) model where <span class="math inline">\(\beta_1 = 1\)</span>. One can show that a time series that follows an AR(<span class="math inline">\(1\)</span>) model is stationary if <span class="math inline">\(\lvert\beta_1\rvert &lt; 1\)</span>. In a general AR(<span class="math inline">\(p\)</span>) model, stationarity is linked to the roots of the polynomial <span class="math display">\[1-\beta_1 z - \beta_2 z^2 - \beta_3 z^3 - \dots - \beta_p z^p.\]</span> If all roots are greater than <span class="math inline">\(1\)</span> in absolute value, the AR(<span class="math inline">\(p\)</span>) series is stationary. If at least one root equals <span class="math inline">\(1\)</span>, the AR(<span class="math inline">\(p\)</span>) is said to have a <em>unit root</em> and thus has a stochastic trend.</p>
<p>It is straightforward to simulate random walks in <tt>R</tt> using <code>arima.sim()</code>. The function <code>matplot()</code> is convenient for simple plots of the columns of a matrix.</p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># simulate and plot random walks starting at 0</span>
<span class="kw">set.seed</span>(<span class="dv">1</span>)

RWs &lt;-<span class="st"> </span><span class="kw">ts</span>(
  <span class="kw">replicate</span>(<span class="dt">n =</span> <span class="dv">4</span>, 
            <span class="kw">arima.sim</span>(<span class="dt">model =</span> <span class="kw">list</span>(<span class="dt">order =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span> ,<span class="dv">0</span>)), <span class="dt">n =</span> <span class="dv">100</span>)
            )
  )

<span class="kw">matplot</span>(RWs, 
        <span class="dt">type =</span><span class="st">&quot;l&quot;</span>, 
        <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;steelblue&quot;</span>, <span class="st">&quot;darkgreen&quot;</span>, <span class="st">&quot;darkred&quot;</span>, <span class="st">&quot;orange&quot;</span>), 
        <span class="dt">lty =</span> <span class="dv">1</span>, 
        <span class="dt">lwd =</span> <span class="dv">2</span>,
        <span class="dt">main =</span> <span class="st">&quot;Four Random Walks&quot;</span>,
        <span class="dt">xlab =</span> <span class="st">&quot;Time&quot;</span>,
        <span class="dt">ylab =</span> <span class="st">&quot;Value&quot;</span>
        )</code></pre></div>
<p><img src="URFITE_files/figure-html/unnamed-chunk-600-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
Adding a constant to <a href="nit.html#eq:randomwalk">(14.6)</a> yields
<span class="math display" id="eq:randomwalkdrift">\[\begin{align}
  Y_t = \beta_0 + Y_{t-1} + u_t \tag{14.7},
\end{align}\]</span>
<p>a <em>random walk model with a drift</em> which allows to model the tendency of a series to move upwards or downwards. If <span class="math inline">\(\beta_0\)</span> is positive, the series drifts upwards and it follows a downward trend if <span class="math inline">\(\beta_0\)</span> is negative.</p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># simulate and plot random walks with drift</span>
<span class="kw">set.seed</span>(<span class="dv">1</span>)

RWsd &lt;-<span class="st"> </span><span class="kw">ts</span>(
  <span class="kw">replicate</span>(<span class="dt">n =</span> <span class="dv">4</span>, 
            <span class="kw">arima.sim</span>(<span class="dt">model =</span> <span class="kw">list</span>(<span class="dt">order =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>)), <span class="dt">n =</span> <span class="dv">100</span>, <span class="dt">mean =</span> <span class="fl">0.15</span>)
            )
  )

<span class="kw">matplot</span>(RWsd, 
        <span class="dt">type=</span><span class="st">&quot;l&quot;</span>, 
        <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;steelblue&quot;</span>, <span class="st">&quot;darkgreen&quot;</span>, <span class="st">&quot;darkred&quot;</span>, <span class="st">&quot;orange&quot;</span>), 
        <span class="dt">lty =</span> <span class="dv">1</span>, 
        <span class="dt">lwd =</span> <span class="dv">2</span>,
        <span class="dt">main =</span> <span class="st">&quot;Four Random Walks with Drift&quot;</span>,
        <span class="dt">xlab =</span> <span class="st">&quot;Time&quot;</span>,
        <span class="dt">ylab =</span> <span class="st">&quot;Value&quot;</span>
        )</code></pre></div>
<p><img src="URFITE_files/figure-html/unnamed-chunk-601-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="problems-caused-by-stochastic-trends" class="section level4 unnumbered">
<h4>Problems Caused by Stochastic Trends</h4>
<p>OLS estimation of the coefficients on regressors that have a stochastic trend is problematic because the distribution of the estimator and its <span class="math inline">\(t\)</span>-statistic is non-normal, even asymptotically. This has various consequences:</p>
<ul>
<li><p>Downward bias of autoregressive coefficients:</p>
<p>If <span class="math inline">\(Y_t\)</span> is a random walk, the coefficient <span class="math inline">\(\beta_1\)</span> can be consistently estimated by OLS but the estimator is biased toward zero. This bias is roughly <span class="math inline">\(E(\widehat{\beta}_1) = 1 - 5.3/T\)</span> which is substantial for sample sizes typically encountered in macroeconomics. This estimation bias causes forecasts of <span class="math inline">\(Y_t\)</span> to perform worse than a pure random walk model.</p></li>
<li><p>Non-normally distributed <span class="math inline">\(t\)</span>-statistics:</p>
<p>The nonnormal distribution of the estimated coefficient of a stochastic regressor translates to a nonnormal distribution of its <span class="math inline">\(t\)</span>-statistic so that normal critical values are invalid and therefore usual confidence intervals and hypothesis tests are invalid, too, and the true distribution of the <span class="math inline">\(t\)</span>-statistic cannot be readily determined.</p></li>
<li><p>Spurious Regression:</p>
<p>When a time series that exhibits a stochastic trend is regressed on another time series that does have a stochastic trend too, the estimated relationship may appear highly significant although the series are unrelated. This is what econometricians call a <em>spurious</em> relationship.</p></li>
</ul>
<p>As an example for spurious regression, consider again the green and the red random walks that we have simulated above. We know that there is no relationship between both series: they are purely random and independent of each other.</p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># plot spurious relationship</span>
<span class="kw">matplot</span>(RWs[, <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">3</span>)], 
        <span class="dt">lty =</span> <span class="dv">1</span>,
        <span class="dt">lwd =</span> <span class="dv">2</span>,
        <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>,
        <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;darkgreen&quot;</span>, <span class="st">&quot;darkred&quot;</span>),
        <span class="dt">xlab =</span> <span class="st">&quot;Time&quot;</span>,
        <span class="dt">ylab =</span> <span class="st">&quot;&quot;</span>,
        <span class="dt">main =</span> <span class="st">&quot;A Spurious Relationship&quot;</span>
        )    </code></pre></div>
<p><img src="URFITE_files/figure-html/unnamed-chunk-602-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
Imagine we did not have this information and instead conject that the green series is useful for predicting the red series and thus end up estimating the ADL(<span class="math inline">\(0\)</span>,<span class="math inline">\(1\)</span>) model
<span class="math display">\[\begin{align*}
  Red_t = \beta_0 + \beta_1 Green_{t-1} + u_t.
\end{align*}\]</span>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># estimate spurious AR model</span>
<span class="kw">summary</span>(
  <span class="kw">dynlm</span>(RWs[, <span class="dv">2</span>] <span class="op">~</span><span class="st"> </span><span class="kw">L</span>(RWs[, <span class="dv">3</span>]))
  )<span class="op">$</span>coefficients</code></pre></div>
<pre><code>##              Estimate Std. Error   t value     Pr(&gt;|t|)
## (Intercept) -3.459488  0.3635104 -9.516889 1.354156e-15
## L(RWs[, 3])  1.047195  0.1450874  7.217687 1.135828e-10</code></pre>
<p>The result is obviously spurious: the coefficient on <span class="math inline">\(Green_{t-1}\)</span> is estimated to be about <span class="math inline">\(1\)</span> and the <span class="math inline">\(p\)</span>-value of <span class="math inline">\(1.14 \cdot 10^{-10}\)</span> of the corresponding <span class="math inline">\(t\)</span>-test indicates that the coefficient is highly significant while its true value is in fact zero.</p>
<p>As an empirical example, consider the U.S. unemployment rate and the Japanese industrial production. Both series show an upward trending behavior from the mid-1960s through the early 1980s.</p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Plot U.S. unemployment rate &amp; Japanese industrial production</span>
<span class="kw">plot</span>(<span class="kw">merge</span>(<span class="kw">as.zoo</span>(USUnemp), <span class="kw">as.zoo</span>(JPIndProd)), 
     <span class="dt">plot.type =</span> <span class="st">&quot;single&quot;</span>, 
     <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;darkred&quot;</span>, <span class="st">&quot;steelblue&quot;</span>),
     <span class="dt">lwd =</span> <span class="dv">2</span>,
     <span class="dt">xlab =</span> <span class="st">&quot;Date&quot;</span>,
     <span class="dt">ylab =</span> <span class="st">&quot;&quot;</span>,
     <span class="dt">main =</span> <span class="st">&quot;Spurious Regression: Macroeconomic Time series&quot;</span>
)
<span class="kw">legend</span>(<span class="st">&quot;topleft&quot;</span>, 
       <span class="dt">legend =</span> <span class="kw">c</span>(<span class="st">&quot;USUnemp&quot;</span>, <span class="st">&quot;JPIndProd&quot;</span>),
       <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;darkred&quot;</span>, <span class="st">&quot;steelblue&quot;</span>),
       <span class="dt">lwd =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>)
       )</code></pre></div>
<p><img src="URFITE_files/figure-html/unnamed-chunk-604-1.png" width="672" /></p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Estimate regression using data from 1962 to 1985</span>
SR_Unemp1 &lt;-<span class="st"> </span><span class="kw">dynlm</span>(<span class="kw">ts</span>(USUnemp[<span class="st">&quot;1962::1985&quot;</span>]) <span class="op">~</span><span class="st"> </span><span class="kw">ts</span>(JPIndProd[<span class="st">&quot;1962::1985&quot;</span>]))
<span class="kw">coeftest</span>(SR_Unemp1, <span class="dt">vcov =</span> sandwich)</code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##                             Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                 -2.37452    1.12041 -2.1193    0.0367 *  
## ts(JPIndProd[&quot;1962::1985&quot;])  2.22057    0.29233  7.5961 2.227e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
A simple regression of the U.S. unemployment rate on Japanese industrial production using data from 1962 to 1985 yields
<span class="math display" id="eq:urjpip1">\[\begin{align}
  \widehat{U.S. UR}_t = -\underset{(1.12)}{2.37} + \underset{(0.29)}{2.22} \log(JapaneseIP_t). \tag{14.8}
\end{align}\]</span>
<p>This appears to be a significant relationship: the <span class="math inline">\(t\)</span>-statistic of the coefficient on <span class="math inline">\(\log(JapaneseIP_t)\)</span> is bigger than 7.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Estimate regression using data from 1986 to 2012</span>
SR_Unemp2 &lt;-<span class="st"> </span><span class="kw">dynlm</span>(<span class="kw">ts</span>(USUnemp[<span class="st">&quot;1986::2012&quot;</span>]) <span class="op">~</span><span class="st"> </span><span class="kw">ts</span>(JPIndProd[<span class="st">&quot;1986::2012&quot;</span>]))
<span class="kw">coeftest</span>(SR_Unemp2, <span class="dt">vcov =</span> sandwich)</code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##                             Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                  41.7763     5.4066  7.7270 6.596e-12 ***
## ts(JPIndProd[&quot;1986::2012&quot;])  -7.7771     1.1714 -6.6391 1.386e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
When estimating the same model, this time with data from 1986 to 2012, we obtain
<span class="math display" id="eq:urjpip2">\[\begin{align}
  \widehat{U.S. UR}_t = \underset{(5.41)}{41.78} -\underset{(1.17)}{7.78} \log(JapaneseIP)_t \tag{14.9}
\end{align}\]</span>
<p>which is surprisingly quite different from <a href="nit.html#eq:urjpip1">(14.8)</a> which indicates a moderate positive relationship, in contrast to the large negative coefficient in <a href="nit.html#eq:urjpip2">(14.9)</a>. This phenomenon can be attributed to stochastic trends in the series: since there is no economic reasoning that relates both trends, both regressions are spurious.</p>
</div>
<div id="testing-for-a-unit-ar-root" class="section level4 unnumbered">
<h4>Testing for a Unit AR Root</h4>
A formal test for a stochastic trend has been proposed by <span class="citation">Dickey &amp; Fuller (<a href="#ref-dickey1979">1979</a>)</span> which thus is termed the <em>Dickey-Fuller test</em>. As discussed above, a time series that follows an AR(<span class="math inline">\(1\)</span>) model with <span class="math inline">\(\beta_1 = 1\)</span> has a stochastic trend. Thus, the testing problem is
<span class="math display">\[\begin{align*}
  H_0: \beta_1 = 1 \ \ \ \text{vs.} \ \ \ H_1: \beta_1 &lt; 1.
\end{align*}\]</span>
The null hypothesis is that the AR(<span class="math inline">\(1\)</span>) has a unit root and the alternative hypothesis is that it is stationary. One often rewrites the AR(<span class="math inline">\(1\)</span>) by subtracting <span class="math inline">\(Y_{t-1}\)</span> on both sides:
<span class="math display">\[\begin{align*}
  Y_t = \beta_0 + \beta_1 Y_{t-1} + u_t \ \ \Leftrightarrow \ \ \Delta Y_t = \beta_0 + \delta_1 Y_{t-1} + u_i
\end{align*}\]</span>
where <span class="math inline">\(\delta_1 = \beta_1 - 1\)</span>. The testing problem then becomes
<span class="math display">\[\begin{align*}
  H_0: \delta_1 = 0 \ \ \ \text{vs.} \ \ \ H_1: \beta_1 &lt; 0
\end{align*}\]</span>
<p>which is convenient since the corresponding test statistic is reported by many relevant <tt>R</tt> functions.<a href="#fn13" class="footnoteRef" id="fnref13"><sup>13</sup></a></p>
<p>The Dickey-Fuller test can also be applied in an AR(<span class="math inline">\(p\)</span>) model. The <em>Augmented Dickey-Fuller (ADF) test</em> is summarized in Key Concept 14.8.</p>
<div class="keyconcept">
<h3 class="right">
Key Concept 14.8
</h3>
<h3 class="left">
The ADF Test for a Unit Root
</h3>
Consider the regression
<span class="math display" id="eq:ADFreg1">\[\begin{align}
  \Delta Y_t = \beta_0 + \delta Y_{t-1} + \gamma_1 \Delta_1 Y_{t-1} + \gamma_2 \Delta Y_{t-2} + \dots + \gamma_p \Delta Y_{t-p} + u_t. \tag{14.10}
\end{align}\]</span>
<p>The ADF test for a unit autoregressive root tests the hypothesis <span class="math inline">\(H_0: \delta = 0\)</span> (stochastic trend) against the one-sided alternative <span class="math inline">\(H_1: \delta &lt; 0\)</span> (stationarity) using the usual OLS <span class="math inline">\(t\)</span>-statistic.</p>
If it is assumed that <span class="math inline">\(Y_t\)</span> is stationary around a deterministic linear time trend, the model is augmented by the regressor <span class="math inline">\(t\)</span>, that is <span class="math inline">\(Y_t\)</span> becomes
<span class="math display" id="eq:ADFreg2">\[\begin{align}
  \Delta Y_t = \beta_0 + at + \delta Y_{t-1} + \gamma_1 \Delta_1 Y_{t-1} + \gamma_2 \Delta Y_{t-2} + \dots + \gamma_p \Delta Y_{t-p} + u_t,  \tag{14.11}
\end{align}\]</span>
<p>where again <span class="math inline">\(H_0: \delta = 0\)</span> is tested against <span class="math inline">\(H_1: \delta &lt; 0\)</span>.</p>
<p>The optimal lag length <span class="math inline">\(p\)</span> can be estimated using information criteria. Notice that in the regression <a href="nit.html#eq:ADFreg1">(14.10)</a>, <span class="math inline">\(p=0\)</span> (no lags of <span class="math inline">\(\Delta Y_t\)</span> are used as regressors) corresponds to a simple AR(<span class="math inline">\(1\)</span>).</p>
<p>Under the null hypothesis, the <span class="math inline">\(t\)</span>-statistic corresponding to <span class="math inline">\(H_0: \delta = 0\)</span> does not have a normal distribution. The critical values can only be obtained from simulation and differ for regressions <a href="nit.html#eq:ADFreg1">(14.10)</a> and <a href="nit.html#eq:ADFreg2">(14.11)</a> since the distribution of the ADF test statistic is sensitive to the deterministic components included in the regression.</p>
</div>
</div>
<div id="critical-values-for-the-adf-statistic" class="section level4 unnumbered">
<h4>Critical Values for the ADF Statistic</h4>
<p>Key Concept 14.8 states that the critical values for the ADF test in the regressions <a href="nit.html#eq:ADFreg1">(14.10)</a> and <a href="nit.html#eq:ADFreg2">(14.11)</a> can only be determined using simulation. The idea of the simulation study is to simulate a large number of ADF test test statistics and use them to estimate quantiles of their <em>asymptotic</em> distribution. This section shows how this is feasible within <tt>R</tt>.</p>
<p>First, consider an AR(<span class="math inline">\(1\)</span>) model with drift. The procedure is as follows:</p>
<ul>
<li>Simulate <span class="math inline">\(N\)</span> random walks with <span class="math inline">\(n\)</span> observations using the data generating process
<span class="math display">\[\begin{align*}
  Y_t =&amp; \, \beta_0 + \beta_1 Y_{t-1} + u_t,
\end{align*}\]</span>
<p><span class="math inline">\(t=1,\dots,n\)</span> where <span class="math inline">\(N\)</span> and <span class="math inline">\(n\)</span> are large numbers.</p></li>
<li>For each random walk, estimate the regression
<span class="math display">\[\begin{align*}
  \Delta Y_t =&amp; \, \beta_0 + \beta_1 Y_{t-1} + u_t
\end{align*}\]</span>
<p>and compute ADF test statistic. Save all <span class="math inline">\(N\)</span> test statistics in a vector.</p></li>
<li><p>Estimate quantiles of the distribution of the ADF test statistic using the <span class="math inline">\(N\)</span> test statistics obtained from the simulation.</p></li>
</ul>
For the case with drift and linear time trend we replace the data generating process by
<span class="math display">\[\begin{align*}
  Y_t =&amp; \, \beta_0 + \alpha t + \beta_1 Y_{t-1} + u_t
\end{align*}\]</span>
and estimate
<span class="math display">\[\begin{align*}
  \Delta Y_t =&amp; \, \beta_0 + \alpha t + \beta_1 Y_{t-1} + u_t.
\end{align*}\]</span>
<p>Loosely speaking, the precision of the estimated quantiles depends on two factors: <span class="math inline">\(n\)</span>, the length of the underlying series and <span class="math inline">\(N\)</span>, the number of test statistics used. Since we are interested in estimating quantiles of the <em>asymptotic</em> distribution (the Dickey-Fuller distribution) of the ADF test statistic so both using many observations and large number of simulated test statistics will increase the precision of the estimated quantiles. We choose <span class="math inline">\(n=N=1000\)</span> as the computational burden grows quickly with <span class="math inline">\(n\)</span> and <span class="math inline">\(N\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># repititions</span>
N &lt;-<span class="st"> </span><span class="dv">1000</span>

<span class="co"># observations</span>
n &lt;-<span class="st"> </span><span class="dv">1000</span>

<span class="co"># define drift a trend </span>
drift &lt;-<span class="st"> </span><span class="fl">0.5</span>
trend &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span>n

<span class="co"># simulate N random walks with drift </span>
RWD &lt;-<span class="st"> </span><span class="kw">ts</span>(<span class="kw">replicate</span>(<span class="dt">n =</span> N, 
            (n<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>drift <span class="op">+</span><span class="st"> </span><span class="kw">arima.sim</span>(<span class="dt">model =</span> <span class="kw">list</span>(<span class="dt">order =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>)),
                              <span class="dt">n =</span> n <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)
            )
          )

<span class="co"># compute ADF test statistics and store them in &#39;ADFD&#39;</span>
ADFD &lt;-<span class="st"> </span><span class="kw">numeric</span>(N)

<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">ncol</span>(RWD)) {
  ADFD[i] &lt;-<span class="st"> </span><span class="kw">summary</span>(
    <span class="kw">dynlm</span>(<span class="kw">diff</span>(RWD[, i], <span class="dv">1</span>) <span class="op">~</span><span class="st"> </span><span class="kw">L</span>(RWD[, i], <span class="dv">1</span>))
    )<span class="op">$</span>coef[<span class="dv">2</span>, <span class="dv">3</span>]
}

<span class="co"># simulate N random walks with drift + trend</span>
RWDT &lt;-<span class="st"> </span><span class="kw">ts</span>(<span class="kw">replicate</span>(<span class="dt">n =</span> N, 
                    trend <span class="op">+</span><span class="st"> </span>drift <span class="op">+</span><span class="st"> </span><span class="kw">arima.sim</span>(<span class="dt">model =</span> <span class="kw">list</span>(<span class="dt">order =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>)), 
                                              <span class="dt">n =</span> n <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)
                    )
           )

<span class="co"># compute ADF test statistics and store them in &#39;ADFDT&#39;</span>
ADFDT &lt;-<span class="st"> </span><span class="kw">numeric</span>(N)

<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">ncol</span>(RWDT)) {
  ADFDT[i] &lt;-<span class="st"> </span><span class="kw">summary</span>(
    <span class="kw">dynlm</span>(<span class="kw">diff</span>(RWDT[, i], <span class="dv">1</span>) <span class="op">~</span><span class="st"> </span><span class="kw">L</span>(RWDT[, i], <span class="dv">1</span>) <span class="op">+</span><span class="st"> </span><span class="kw">trend</span>(RWDT[, i], <span class="dt">scale =</span> F))
  )<span class="op">$</span>coef[<span class="dv">2</span>, <span class="dv">3</span>]
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># estimate quantiles for ADF regression with a drift</span>
<span class="kw">round</span>(<span class="kw">quantile</span>(ADFD, <span class="kw">c</span>(<span class="fl">0.1</span>, <span class="fl">0.05</span>, <span class="fl">0.01</span>)), <span class="dv">2</span>)</code></pre></div>
<pre><code>##   10%    5%    1% 
## -2.62 -2.83 -3.39</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># estimate quantiles for ADF regression with drift and trend</span>
<span class="kw">round</span>(<span class="kw">quantile</span>(ADFDT, <span class="kw">c</span>(<span class="fl">0.1</span>,<span class="fl">0.05</span>,<span class="fl">0.01</span>)),<span class="dv">2</span>)</code></pre></div>
<pre><code>##   10%    5%    1% 
## -3.11 -3.43 -3.97</code></pre>
<p>The estimated quantiles are close to the large sample critical values of the ADF test statistic reported in Table 14.4 of the book.</p>
<table>
<caption><span id="tab:DFcrits">Table 14.2: </span> Large Sample Critical Values of ADF Test</caption>
<thead>
<tr class="header">
<th align="left">Deterministic Regressors</th>
<th align="left">10%</th>
<th align="left">5%</th>
<th align="left">1%</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Intercept only</td>
<td align="left">-2.57</td>
<td align="left">-2.86</td>
<td align="left">-3.43</td>
</tr>
<tr class="even">
<td align="left">Intercept and time trend</td>
<td align="left">-3.12</td>
<td align="left">-3.41</td>
<td align="left">-3.96</td>
</tr>
</tbody>
</table>
<p>The results show that using standard normal critical values might be fatal: the 5% critical value of the standard normal distribution is <span class="math inline">\(-1.64\)</span> but for the Dickey-Fuller distributions the estimated critical values are <span class="math inline">\(-2.87\)</span> (drift) and <span class="math inline">\(-3.43\)</span> (drift and linear time trend). This implies that a true null hypothesis (the series has a stochastic trend) would be rejected far to often if the inappropriate normal critical values were used.</p>
<p>We may use the simulated test statistics for a graphical comparison of the standard normal density and (estimates of) both Dickey-Fuller densities.</p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># plot standard normal density</span>
<span class="kw">curve</span>(<span class="kw">dnorm</span>(x), 
      <span class="dt">from =</span> <span class="op">-</span><span class="dv">6</span>, <span class="dt">to =</span> <span class="dv">3</span>, 
      <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.6</span>), 
      <span class="dt">lty =</span> <span class="dv">2</span>,
      <span class="dt">ylab =</span> <span class="st">&quot;Density&quot;</span>,
      <span class="dt">xlab =</span> <span class="st">&quot;t-Statistic&quot;</span>,
      <span class="dt">main =</span> <span class="st">&quot;Distributions of ADF Test Statistics&quot;</span>,
      <span class="dt">col =</span> <span class="st">&quot;darkred&quot;</span>, 
      <span class="dt">lwd =</span> <span class="dv">2</span>)

<span class="co"># plot density estimates of both Dickey-Fuller distributions</span>
<span class="kw">lines</span>(<span class="kw">density</span>(ADFD), <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&quot;darkgreen&quot;</span>)
<span class="kw">lines</span>(<span class="kw">density</span>(ADFDT), <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>)

<span class="co"># add a legend</span>
<span class="kw">legend</span>(<span class="st">&quot;topleft&quot;</span>, 
       <span class="kw">c</span>(<span class="st">&quot;N(0,1)&quot;</span>, <span class="st">&quot;Drift&quot;</span>, <span class="st">&quot;Drift+Trend&quot;</span>),
       <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;darkred&quot;</span>, <span class="st">&quot;darkgreen&quot;</span>, <span class="st">&quot;blue&quot;</span>),
       <span class="dt">lty =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">1</span>),
       <span class="dt">lwd =</span> <span class="dv">2</span>
       )</code></pre></div>
<p><img src="URFITE_files/figure-html/unnamed-chunk-611-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<p>The deviations from the standard normal distribution are significant: both Dickey-Fuller distributions are skewed to the left and have a heavier left tail than the standard normal distribution.</p>
</div>
<div id="does-u.s.-gdp-have-a-unit-root" class="section level4 unnumbered">
<h4>Does U.S. GDP Have a Unit Root?</h4>
As an empirical example, we use the ADF test to assess whether there is a stochastic trend in U.S. GDP using the regression
<span class="math display">\[\begin{align*}
  \Delta\log(GDP_t) = \beta_0 + \alpha t + \beta_1 \log(GDP_{t-1}) + \beta_2 \Delta \log(GDP_{t-1}) + \beta_3 \Delta \log(GDP_{t-2}) + u_t.
\end{align*}\]</span>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># generate log GDP series</span>
LogGDP &lt;-<span class="st"> </span><span class="kw">ts</span>(<span class="kw">log</span>(GDP[<span class="st">&quot;1962::2012&quot;</span>]))

<span class="co"># estimate the model</span>
<span class="kw">coeftest</span>(
  <span class="kw">dynlm</span>(<span class="kw">diff</span>(LogGDP) <span class="op">~</span><span class="st"> </span><span class="kw">trend</span>(LogGDP, <span class="dt">scale =</span> F) <span class="op">+</span><span class="st"> </span><span class="kw">L</span>(LogGDP) 
                     <span class="op">+</span><span class="st"> </span><span class="kw">diff</span>(<span class="kw">L</span>(LogGDP)) <span class="op">+</span><span class="st"> </span><span class="kw">diff</span>(<span class="kw">L</span>(LogGDP), <span class="dv">2</span>))
  )</code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##                             Estimate  Std. Error t value Pr(&gt;|t|)   
## (Intercept)               0.27877045  0.11793233  2.3638 0.019066 * 
## trend(LogGDP, scale = F)  0.00023818  0.00011090  2.1476 0.032970 * 
## L(LogGDP)                -0.03332452  0.01441436 -2.3119 0.021822 * 
## diff(L(LogGDP))           0.08317976  0.11295542  0.7364 0.462371   
## diff(L(LogGDP), 2)        0.18763384  0.07055574  2.6594 0.008476 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
The estimation yields
<span class="math display">\[\begin{align*}
  \Delta\log(GDP_t) =&amp; \, \underset{(0.118)}{0.28} + \underset{(0.0001)}{0.0002} t -\underset{(0.014)}{0.033} \log(GDP_{t-1}) \\
  + &amp; \, \underset{(0.113)}{0.083} \Delta \log(GDP_{t-1}) + \underset{(0.071)}{0.188} \Delta \log(GDP_{t-2}) + u_t,
\end{align*}\]</span>
<p>so the ADF test statistic is <span class="math inline">\(t=-0.033/0.014 = - 2.35\)</span>. The corresponding <span class="math inline">\(5\%\)</span> critical value from table <a href="nit.html#tab:DFcrits">14.2</a> is <span class="math inline">\(-3.41\)</span> so we cannot reject the null hypothesis that <span class="math inline">\(\log(GDP)\)</span> has a stochastic trend in favor of the alternative that it is stationary around a deterministic linear time trend.</p>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-dickey1979">
<p>Dickey, D. A., &amp; Fuller, W. A. (1979). Distribution of the estimators for autoregressive time series with a unit root. <em>Journal of the American Statistical Association</em>, <em>74</em>(366), pp. 427–431.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="13">
<li id="fn13"><p>The <span class="math inline">\(t\)</span>-statistic of the Dickey-Fuller test is computed using homoskedasticity-only standard errors since under the null hypothesis, the usual <span class="math inline">\(t\)</span>-statistic is robust to heteroskedasticity.<a href="nit.html#fnref13">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="llsuic.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="niib.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 1
},
"edit": null,
"download": ["URFITE.pdf", "URFITE.epub"],
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
