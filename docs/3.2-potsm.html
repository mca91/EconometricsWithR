<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3.2 Properties of the Sample Mean | Introduction to Econometrics with R</title>
  <meta name="description" content="Beginners with little background in statistics and econometrics often have a hard time understanding the benefits of having programming skills for learning and applying Econometrics. ‘Introduction to Econometrics with R’ is an interactive companion to the well-received textbook ‘Introduction to Econometrics’ by James H. Stock and Mark W. Watson (2015). It gives a gentle introduction to the essentials of R programming and guides students in implementing the empirical applications presented throughout the textbook using the newly aquired skills. This is supported by interactive programming exercises generated with DataCamp Light and integration of interactive visualizations of central concepts which are based on the flexible JavaScript library D3.js." />
  <meta name="generator" content="bookdown 0.36 and GitBook 2.6.7" />

  <meta property="og:title" content="3.2 Properties of the Sample Mean | Introduction to Econometrics with R" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://www.econometrics-with-r.org//images/cover.png" />
  <meta property="og:description" content="Beginners with little background in statistics and econometrics often have a hard time understanding the benefits of having programming skills for learning and applying Econometrics. ‘Introduction to Econometrics with R’ is an interactive companion to the well-received textbook ‘Introduction to Econometrics’ by James H. Stock and Mark W. Watson (2015). It gives a gentle introduction to the essentials of R programming and guides students in implementing the empirical applications presented throughout the textbook using the newly aquired skills. This is supported by interactive programming exercises generated with DataCamp Light and integration of interactive visualizations of central concepts which are based on the flexible JavaScript library D3.js." />
  <meta name="github-repo" content="mca91/EconometricsWithR" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3.2 Properties of the Sample Mean | Introduction to Econometrics with R" />
  
  <meta name="twitter:description" content="Beginners with little background in statistics and econometrics often have a hard time understanding the benefits of having programming skills for learning and applying Econometrics. ‘Introduction to Econometrics with R’ is an interactive companion to the well-received textbook ‘Introduction to Econometrics’ by James H. Stock and Mark W. Watson (2015). It gives a gentle introduction to the essentials of R programming and guides students in implementing the empirical applications presented throughout the textbook using the newly aquired skills. This is supported by interactive programming exercises generated with DataCamp Light and integration of interactive visualizations of central concepts which are based on the flexible JavaScript library D3.js." />
  <meta name="twitter:image" content="https://www.econometrics-with-r.org//images/cover.png" />

<meta name="author" content="Christoph Hanck, Martin Arnold, Alexander Gerber, and Martin Schmelzer" />


<meta name="date" content="2024-02-13" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="3.1-estimation-of-the-population-mean.html"/>
<link rel="next" href="3.3-hypothesis-tests-concerning-the-population-mean.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.6.2/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.10.3/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.11.1/plotly-latest.min.js"></script>
<!-- font families -->

<link href="https://fonts.googleapis.com/css?family=PT+Sans|Pacifico|Source+Sans+Pro" rel="stylesheet">

<script src="js/hideOutput.js"></script>

<!-- Mathjax -->
<script type="text/javascript" id="MathJax-script" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/mml-chtml.min.js"></script>

 <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        extensions: ["tex2jax.js", "TeX/AMSmath.js"],
        tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
        jax: ["input/TeX","output/CommonHTML"]
      });
      MathJax.Hub.processSectionDelay = 0;
  </script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110299877-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110299877-1');
</script>

<!-- open review block -->

<script type="application/json" class="js-hypothesis-config">
{
"showHighlights": false
}
</script>
<script async defer src="https://hypothes.is/embed.js"></script>



<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #204a87; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #204a87; font-weight: bold; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #ce5c00; font-weight: bold; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><center><img src="images/logo.png" alt="logo" width="50%" height="50%"style="margin: 15px 0 0 0"></center></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="1-introduction.html"><a href="1-introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="1.1-colophon.html"><a href="1.1-colophon.html"><i class="fa fa-check"></i><b>1.1</b> Colophon</a></li>
<li class="chapter" data-level="1.2" data-path="1.2-a-very-short-introduction-to-r-and-rstudio.html"><a href="1.2-a-very-short-introduction-to-r-and-rstudio.html"><i class="fa fa-check"></i><b>1.2</b> A Very Short Introduction to <tt>R</tt> and <em>RStudio</em></a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-pt.html"><a href="2-pt.html"><i class="fa fa-check"></i><b>2</b> Probability Theory</a>
<ul>
<li class="chapter" data-level="2.1" data-path="2.1-random-variables-and-probability-distributions.html"><a href="2.1-random-variables-and-probability-distributions.html"><i class="fa fa-check"></i><b>2.1</b> Random Variables and Probability Distributions</a>
<ul>
<li class="chapter" data-level="" data-path="2.1-random-variables-and-probability-distributions.html"><a href="2.1-random-variables-and-probability-distributions.html#probability-distributions-of-discrete-random-variables"><i class="fa fa-check"></i>Probability Distributions of Discrete Random Variables</a></li>
<li class="chapter" data-level="" data-path="2.1-random-variables-and-probability-distributions.html"><a href="2.1-random-variables-and-probability-distributions.html#bernoulli-trials"><i class="fa fa-check"></i>Bernoulli Trials</a></li>
<li class="chapter" data-level="" data-path="2.1-random-variables-and-probability-distributions.html"><a href="2.1-random-variables-and-probability-distributions.html#expected-value-mean-and-variance"><i class="fa fa-check"></i>Expected Value, Mean and Variance</a></li>
<li class="chapter" data-level="" data-path="2.1-random-variables-and-probability-distributions.html"><a href="2.1-random-variables-and-probability-distributions.html#probability-distributions-of-continuous-random-variables"><i class="fa fa-check"></i>Probability Distributions of Continuous Random Variables</a></li>
<li class="chapter" data-level="" data-path="2.1-random-variables-and-probability-distributions.html"><a href="2.1-random-variables-and-probability-distributions.html#the-normal-distribution"><i class="fa fa-check"></i>The Normal Distribution</a></li>
<li class="chapter" data-level="" data-path="2.1-random-variables-and-probability-distributions.html"><a href="2.1-random-variables-and-probability-distributions.html#the-chi-squared-distribution"><i class="fa fa-check"></i>The Chi-Squared Distribution</a></li>
<li class="chapter" data-level="" data-path="2.1-random-variables-and-probability-distributions.html"><a href="2.1-random-variables-and-probability-distributions.html#thetdist"><i class="fa fa-check"></i>The Student t Distribution</a></li>
<li class="chapter" data-level="" data-path="2.1-random-variables-and-probability-distributions.html"><a href="2.1-random-variables-and-probability-distributions.html#the-f-distribution"><i class="fa fa-check"></i>The F Distribution</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="2.2-RSATDOSA.html"><a href="2.2-RSATDOSA.html"><i class="fa fa-check"></i><b>2.2</b> Random Sampling and the Distribution of Sample Averages</a>
<ul>
<li class="chapter" data-level="" data-path="2.2-RSATDOSA.html"><a href="2.2-RSATDOSA.html#mean-and-variance-of-the-sample-mean"><i class="fa fa-check"></i>Mean and Variance of the Sample Mean</a></li>
<li class="chapter" data-level="" data-path="2.2-RSATDOSA.html"><a href="2.2-RSATDOSA.html#large-sample-approximations-to-sampling-distributions"><i class="fa fa-check"></i>Large Sample Approximations to Sampling Distributions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="2.3-exercises-2.html"><a href="2.3-exercises-2.html"><i class="fa fa-check"></i><b>2.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-arosur.html"><a href="3-arosur.html"><i class="fa fa-check"></i><b>3</b> A Review of Statistics using R</a>
<ul>
<li class="chapter" data-level="3.1" data-path="3.1-estimation-of-the-population-mean.html"><a href="3.1-estimation-of-the-population-mean.html"><i class="fa fa-check"></i><b>3.1</b> Estimation of the Population Mean</a></li>
<li class="chapter" data-level="3.2" data-path="3.2-potsm.html"><a href="3.2-potsm.html"><i class="fa fa-check"></i><b>3.2</b> Properties of the Sample Mean</a></li>
<li class="chapter" data-level="3.3" data-path="3.3-hypothesis-tests-concerning-the-population-mean.html"><a href="3.3-hypothesis-tests-concerning-the-population-mean.html"><i class="fa fa-check"></i><b>3.3</b> Hypothesis Tests concerning the Population Mean</a>
<ul>
<li class="chapter" data-level="" data-path="3.3-hypothesis-tests-concerning-the-population-mean.html"><a href="3.3-hypothesis-tests-concerning-the-population-mean.html#the-p-value"><i class="fa fa-check"></i>The p-Value</a></li>
<li class="chapter" data-level="" data-path="3.3-hypothesis-tests-concerning-the-population-mean.html"><a href="3.3-hypothesis-tests-concerning-the-population-mean.html#calculating-the-p-value-when-the-standard-deviation-is-known"><i class="fa fa-check"></i>Calculating the p-Value when the Standard Deviation is Known</a></li>
<li class="chapter" data-level="" data-path="3.3-hypothesis-tests-concerning-the-population-mean.html"><a href="3.3-hypothesis-tests-concerning-the-population-mean.html#SVSSDASE"><i class="fa fa-check"></i>Sample Variance, Sample Standard Deviation and Standard Error</a></li>
<li class="chapter" data-level="" data-path="3.3-hypothesis-tests-concerning-the-population-mean.html"><a href="3.3-hypothesis-tests-concerning-the-population-mean.html#calculating-the-p-value-when-the-standard-deviation-is-unknown"><i class="fa fa-check"></i>Calculating the p-value When the Standard Deviation is Unknown</a></li>
<li class="chapter" data-level="" data-path="3.3-hypothesis-tests-concerning-the-population-mean.html"><a href="3.3-hypothesis-tests-concerning-the-population-mean.html#the-t-statistic"><i class="fa fa-check"></i>The t-statistic</a></li>
<li class="chapter" data-level="" data-path="3.3-hypothesis-tests-concerning-the-population-mean.html"><a href="3.3-hypothesis-tests-concerning-the-population-mean.html#hypothesis-testing-with-a-prespecified-significance-level"><i class="fa fa-check"></i>Hypothesis Testing with a Prespecified Significance Level</a></li>
<li class="chapter" data-level="" data-path="3.3-hypothesis-tests-concerning-the-population-mean.html"><a href="3.3-hypothesis-tests-concerning-the-population-mean.html#one-sided-alternatives"><i class="fa fa-check"></i>One-sided Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="3.4-confidence-intervals-for-the-population-mean.html"><a href="3.4-confidence-intervals-for-the-population-mean.html"><i class="fa fa-check"></i><b>3.4</b> Confidence Intervals for the Population Mean</a></li>
<li class="chapter" data-level="3.5" data-path="3.5-cmfdp.html"><a href="3.5-cmfdp.html"><i class="fa fa-check"></i><b>3.5</b> Comparing Means from Different Populations</a></li>
<li class="chapter" data-level="3.6" data-path="3.6-aattggoe.html"><a href="3.6-aattggoe.html"><i class="fa fa-check"></i><b>3.6</b> An Application to the Gender Gap of Earnings</a></li>
<li class="chapter" data-level="3.7" data-path="3.7-scatterplots-sample-covariance-and-sample-correlation.html"><a href="3.7-scatterplots-sample-covariance-and-sample-correlation.html"><i class="fa fa-check"></i><b>3.7</b> Scatterplots, Sample Covariance and Sample Correlation</a></li>
<li class="chapter" data-level="3.8" data-path="3.8-exercises-3.html"><a href="3.8-exercises-3.html"><i class="fa fa-check"></i><b>3.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-lrwor.html"><a href="4-lrwor.html"><i class="fa fa-check"></i><b>4</b> Linear Regression with One Regressor</a>
<ul>
<li class="chapter" data-level="4.1" data-path="4.1-simple-linear-regression.html"><a href="4.1-simple-linear-regression.html"><i class="fa fa-check"></i><b>4.1</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="4.2" data-path="4.2-estimating-the-coefficients-of-the-linear-regression-model.html"><a href="4.2-estimating-the-coefficients-of-the-linear-regression-model.html"><i class="fa fa-check"></i><b>4.2</b> Estimating the Coefficients of the Linear Regression Model</a>
<ul>
<li class="chapter" data-level="" data-path="4.2-estimating-the-coefficients-of-the-linear-regression-model.html"><a href="4.2-estimating-the-coefficients-of-the-linear-regression-model.html#the-ordinary-least-squares-estimator"><i class="fa fa-check"></i>The Ordinary Least Squares Estimator</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="4.3-measures-of-fit.html"><a href="4.3-measures-of-fit.html"><i class="fa fa-check"></i><b>4.3</b> Measures of Fit</a>
<ul>
<li class="chapter" data-level="" data-path="4.3-measures-of-fit.html"><a href="4.3-measures-of-fit.html#the-coefficient-of-determination"><i class="fa fa-check"></i>The Coefficient of Determination</a></li>
<li class="chapter" data-level="" data-path="4.3-measures-of-fit.html"><a href="4.3-measures-of-fit.html#the-standard-error-of-the-regression"><i class="fa fa-check"></i>The Standard Error of the Regression</a></li>
<li class="chapter" data-level="" data-path="4.3-measures-of-fit.html"><a href="4.3-measures-of-fit.html#application-to-the-test-score-data"><i class="fa fa-check"></i>Application to the Test Score Data</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="4.4-tlsa.html"><a href="4.4-tlsa.html"><i class="fa fa-check"></i><b>4.4</b> The Least Squares Assumptions</a>
<ul>
<li class="chapter" data-level="" data-path="4.4-tlsa.html"><a href="4.4-tlsa.html#assumption-1-the-error-term-has-conditional-mean-of-zero"><i class="fa fa-check"></i>Assumption 1: The Error Term has Conditional Mean of Zero</a></li>
<li class="chapter" data-level="" data-path="4.4-tlsa.html"><a href="4.4-tlsa.html#assumption-2-independently-and-identically-distributed-data"><i class="fa fa-check"></i>Assumption 2: Independently and Identically Distributed Data</a></li>
<li class="chapter" data-level="" data-path="4.4-tlsa.html"><a href="4.4-tlsa.html#assumption-3-large-outliers-are-unlikely"><i class="fa fa-check"></i>Assumption 3: Large Outliers are Unlikely</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="4.5-tsdotoe.html"><a href="4.5-tsdotoe.html"><i class="fa fa-check"></i><b>4.5</b> The Sampling Distribution of the OLS Estimator</a>
<ul>
<li class="chapter" data-level="" data-path="4.5-tsdotoe.html"><a href="4.5-tsdotoe.html#simulation-study-1"><i class="fa fa-check"></i>Simulation Study 1</a></li>
<li class="chapter" data-level="" data-path="4.5-tsdotoe.html"><a href="4.5-tsdotoe.html#simulation-study-2"><i class="fa fa-check"></i>Simulation Study 2</a></li>
<li class="chapter" data-level="" data-path="4.5-tsdotoe.html"><a href="4.5-tsdotoe.html#simulation-study-3"><i class="fa fa-check"></i>Simulation Study 3</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="4.6-exercises-4.html"><a href="4.6-exercises-4.html"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-htaciitslrm.html"><a href="5-htaciitslrm.html"><i class="fa fa-check"></i><b>5</b> Hypothesis Tests and Confidence Intervals in SLR Model</a>
<ul>
<li class="chapter" data-level="5.1" data-path="5.1-testing-two-sided-hypotheses-concerning-the-slope-coefficient.html"><a href="5.1-testing-two-sided-hypotheses-concerning-the-slope-coefficient.html"><i class="fa fa-check"></i><b>5.1</b> Testing Two-Sided Hypotheses concerning the Slope Coefficient</a></li>
<li class="chapter" data-level="5.2" data-path="5.2-cifrc.html"><a href="5.2-cifrc.html"><i class="fa fa-check"></i><b>5.2</b> Confidence Intervals for Regression Coefficients</a>
<ul>
<li class="chapter" data-level="" data-path="5.2-cifrc.html"><a href="5.2-cifrc.html#simulation-study-confidence-intervals"><i class="fa fa-check"></i>Simulation Study: Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="5.3-rwxiabv.html"><a href="5.3-rwxiabv.html"><i class="fa fa-check"></i><b>5.3</b> Regression when X is a Binary Variable</a></li>
<li class="chapter" data-level="5.4" data-path="5.4-hah.html"><a href="5.4-hah.html"><i class="fa fa-check"></i><b>5.4</b> Heteroskedasticity and Homoskedasticity</a>
<ul>
<li class="chapter" data-level="" data-path="5.4-hah.html"><a href="5.4-hah.html#a-real-world-example-for-heteroskedasticity"><i class="fa fa-check"></i>A Real-World Example for Heteroskedasticity</a></li>
<li class="chapter" data-level="" data-path="5.4-hah.html"><a href="5.4-hah.html#should-we-care-about-heteroskedasticity"><i class="fa fa-check"></i>Should We Care About Heteroskedasticity?</a></li>
<li class="chapter" data-level="" data-path="5.4-hah.html"><a href="5.4-hah.html#computation-of-heteroskedasticity-robust-standard-errors"><i class="fa fa-check"></i>Computation of Heteroskedasticity-Robust Standard Errors</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="5.5-the-gauss-markov-theorem.html"><a href="5.5-the-gauss-markov-theorem.html"><i class="fa fa-check"></i><b>5.5</b> The Gauss-Markov Theorem</a>
<ul>
<li class="chapter" data-level="" data-path="5.5-the-gauss-markov-theorem.html"><a href="5.5-the-gauss-markov-theorem.html#simulation-study-blue-estimator"><i class="fa fa-check"></i>Simulation Study: BLUE Estimator</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="5.6-using-the-t-statistic-in-regression-when-the-sample-size-is-small.html"><a href="5.6-using-the-t-statistic-in-regression-when-the-sample-size-is-small.html"><i class="fa fa-check"></i><b>5.6</b> Using the t-Statistic in Regression when the Sample Size Is Small</a></li>
<li class="chapter" data-level="5.7" data-path="5.7-exercises-5.html"><a href="5.7-exercises-5.html"><i class="fa fa-check"></i><b>5.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-rmwmr.html"><a href="6-rmwmr.html"><i class="fa fa-check"></i><b>6</b> Regression Models with Multiple Regressors</a>
<ul>
<li class="chapter" data-level="6.1" data-path="6.1-omitted-variable-bias.html"><a href="6.1-omitted-variable-bias.html"><i class="fa fa-check"></i><b>6.1</b> Omitted Variable Bias</a></li>
<li class="chapter" data-level="6.2" data-path="6.2-tmrm.html"><a href="6.2-tmrm.html"><i class="fa fa-check"></i><b>6.2</b> The Multiple Regression Model</a></li>
<li class="chapter" data-level="6.3" data-path="6.3-mofimr.html"><a href="6.3-mofimr.html"><i class="fa fa-check"></i><b>6.3</b> Measures of Fit in Multiple Regression</a></li>
<li class="chapter" data-level="6.4" data-path="6.4-ols-assumptions-in-multiple-regression.html"><a href="6.4-ols-assumptions-in-multiple-regression.html"><i class="fa fa-check"></i><b>6.4</b> OLS Assumptions in Multiple Regression</a>
<ul>
<li class="chapter" data-level="" data-path="6.4-ols-assumptions-in-multiple-regression.html"><a href="6.4-ols-assumptions-in-multiple-regression.html#multicollinearity"><i class="fa fa-check"></i>Multicollinearity</a></li>
<li class="chapter" data-level="" data-path="6.4-ols-assumptions-in-multiple-regression.html"><a href="6.4-ols-assumptions-in-multiple-regression.html#simulation-study-imperfect-multicollinearity"><i class="fa fa-check"></i>Simulation Study: Imperfect Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="6.5-the-distribution-of-the-ols-estimators-in-multiple-regression.html"><a href="6.5-the-distribution-of-the-ols-estimators-in-multiple-regression.html"><i class="fa fa-check"></i><b>6.5</b> The Distribution of the OLS Estimators in Multiple Regression</a></li>
<li class="chapter" data-level="6.6" data-path="6.6-exercises-6.html"><a href="6.6-exercises-6.html"><i class="fa fa-check"></i><b>6.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-htaciimr.html"><a href="7-htaciimr.html"><i class="fa fa-check"></i><b>7</b> Hypothesis Tests and Confidence Intervals in MR Models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="7.1-hypothesis-tests-and-confidence-intervals-for-a-single-coefficient.html"><a href="7.1-hypothesis-tests-and-confidence-intervals-for-a-single-coefficient.html"><i class="fa fa-check"></i><b>7.1</b> Hypothesis Tests and Confidence Intervals for a Single Coefficient</a></li>
<li class="chapter" data-level="7.2" data-path="7.2-an-application-to-test-scores-and-the-student-teacher-ratio.html"><a href="7.2-an-application-to-test-scores-and-the-student-teacher-ratio.html"><i class="fa fa-check"></i><b>7.2</b> An Application to Test Scores and the Student-Teacher Ratio</a>
<ul>
<li class="chapter" data-level="" data-path="7.2-an-application-to-test-scores-and-the-student-teacher-ratio.html"><a href="7.2-an-application-to-test-scores-and-the-student-teacher-ratio.html#another-augmentation-of-the-model"><i class="fa fa-check"></i>Another Augmentation of the Model</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="7.3-joint-hypothesis-testing-using-the-f-statistic.html"><a href="7.3-joint-hypothesis-testing-using-the-f-statistic.html"><i class="fa fa-check"></i><b>7.3</b> Joint Hypothesis Testing using the F-Statistic</a></li>
<li class="chapter" data-level="7.4" data-path="7.4-confidence-sets-for-multiple-coefficients.html"><a href="7.4-confidence-sets-for-multiple-coefficients.html"><i class="fa fa-check"></i><b>7.4</b> Confidence Sets for Multiple Coefficients</a></li>
<li class="chapter" data-level="7.5" data-path="7.5-model-specification-for-multiple-regression.html"><a href="7.5-model-specification-for-multiple-regression.html"><i class="fa fa-check"></i><b>7.5</b> Model Specification for Multiple Regression</a>
<ul>
<li class="chapter" data-level="" data-path="7.5-model-specification-for-multiple-regression.html"><a href="7.5-model-specification-for-multiple-regression.html#model-specification-in-theory-and-in-practice"><i class="fa fa-check"></i>Model Specification in Theory and in Practice</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="7.6-analysis-of-the-test-score-data-set.html"><a href="7.6-analysis-of-the-test-score-data-set.html"><i class="fa fa-check"></i><b>7.6</b> Analysis of the Test Score Data Set</a></li>
<li class="chapter" data-level="7.7" data-path="7.7-exercises-7.html"><a href="7.7-exercises-7.html"><i class="fa fa-check"></i><b>7.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="8-nrf.html"><a href="8-nrf.html"><i class="fa fa-check"></i><b>8</b> Nonlinear Regression Functions</a>
<ul>
<li class="chapter" data-level="8.1" data-path="8.1-a-general-strategy-for-modelling-nonlinear-regression-functions.html"><a href="8.1-a-general-strategy-for-modelling-nonlinear-regression-functions.html"><i class="fa fa-check"></i><b>8.1</b> A General Strategy for Modelling Nonlinear Regression Functions</a></li>
<li class="chapter" data-level="8.2" data-path="8.2-nfoasiv.html"><a href="8.2-nfoasiv.html"><i class="fa fa-check"></i><b>8.2</b> Nonlinear Functions of a Single Independent Variable</a>
<ul>
<li class="chapter" data-level="" data-path="8.2-nfoasiv.html"><a href="8.2-nfoasiv.html#polynomials"><i class="fa fa-check"></i>Polynomials</a></li>
<li class="chapter" data-level="" data-path="8.2-nfoasiv.html"><a href="8.2-nfoasiv.html#logarithms"><i class="fa fa-check"></i>Logarithms</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="8.3-interactions-between-independent-variables.html"><a href="8.3-interactions-between-independent-variables.html"><i class="fa fa-check"></i><b>8.3</b> Interactions between Independent Variables</a></li>
<li class="chapter" data-level="8.4" data-path="8.4-nonlinear-effects-on-test-scores-of-the-student-teacher-ratio.html"><a href="8.4-nonlinear-effects-on-test-scores-of-the-student-teacher-ratio.html"><i class="fa fa-check"></i><b>8.4</b> Nonlinear Effects on Test Scores of the Student-Teacher Ratio</a></li>
<li class="chapter" data-level="8.5" data-path="8.5-exercises-8.html"><a href="8.5-exercises-8.html"><i class="fa fa-check"></i><b>8.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="9-asbomr.html"><a href="9-asbomr.html"><i class="fa fa-check"></i><b>9</b> Assessing Studies Based on Multiple Regression</a>
<ul>
<li class="chapter" data-level="9.1" data-path="9.1-internal-and-external-validity.html"><a href="9.1-internal-and-external-validity.html"><i class="fa fa-check"></i><b>9.1</b> Internal and External Validity</a></li>
<li class="chapter" data-level="9.2" data-path="9.2-ttivomra.html"><a href="9.2-ttivomra.html"><i class="fa fa-check"></i><b>9.2</b> Threats to Internal Validity of Multiple Regression Analysis</a></li>
<li class="chapter" data-level="9.3" data-path="9.3-internal-and-external-validity-when-the-regression-is-used-for-forecasting.html"><a href="9.3-internal-and-external-validity-when-the-regression-is-used-for-forecasting.html"><i class="fa fa-check"></i><b>9.3</b> Internal and External Validity when the Regression is used for Forecasting</a></li>
<li class="chapter" data-level="9.4" data-path="9.4-etsacs.html"><a href="9.4-etsacs.html"><i class="fa fa-check"></i><b>9.4</b> Example: Test Scores and Class Size</a></li>
<li class="chapter" data-level="9.5" data-path="9.5-exercises-9.html"><a href="9.5-exercises-9.html"><i class="fa fa-check"></i><b>9.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="10-rwpd.html"><a href="10-rwpd.html"><i class="fa fa-check"></i><b>10</b> Regression with Panel Data</a>
<ul>
<li class="chapter" data-level="10.1" data-path="10.1-panel-data.html"><a href="10.1-panel-data.html"><i class="fa fa-check"></i><b>10.1</b> Panel Data</a></li>
<li class="chapter" data-level="10.2" data-path="10.2-PDWTTP.html"><a href="10.2-PDWTTP.html"><i class="fa fa-check"></i><b>10.2</b> Panel Data with Two Time Periods: “Before and After” Comparisons</a></li>
<li class="chapter" data-level="10.3" data-path="10.3-fixed-effects-regression.html"><a href="10.3-fixed-effects-regression.html"><i class="fa fa-check"></i><b>10.3</b> Fixed Effects Regression</a>
<ul>
<li class="chapter" data-level="" data-path="10.3-fixed-effects-regression.html"><a href="10.3-fixed-effects-regression.html#estimation-and-inference"><i class="fa fa-check"></i>Estimation and Inference</a></li>
<li class="chapter" data-level="" data-path="10.3-fixed-effects-regression.html"><a href="10.3-fixed-effects-regression.html#application-to-traffic-deaths"><i class="fa fa-check"></i>Application to Traffic Deaths</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="10.4-regression-with-time-fixed-effects.html"><a href="10.4-regression-with-time-fixed-effects.html"><i class="fa fa-check"></i><b>10.4</b> Regression with Time Fixed Effects</a></li>
<li class="chapter" data-level="10.5" data-path="10.5-tferaaseffer.html"><a href="10.5-tferaaseffer.html"><i class="fa fa-check"></i><b>10.5</b> The Fixed Effects Regression Assumptions and Standard Errors for Fixed Effects Regression</a></li>
<li class="chapter" data-level="10.6" data-path="10.6-drunk-driving-laws-and-traffic-deaths.html"><a href="10.6-drunk-driving-laws-and-traffic-deaths.html"><i class="fa fa-check"></i><b>10.6</b> Drunk Driving Laws and Traffic Deaths</a></li>
<li class="chapter" data-level="10.7" data-path="10.7-exercises-10.html"><a href="10.7-exercises-10.html"><i class="fa fa-check"></i><b>10.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="11-rwabdv.html"><a href="11-rwabdv.html"><i class="fa fa-check"></i><b>11</b> Regression with a Binary Dependent Variable</a>
<ul>
<li class="chapter" data-level="11.1" data-path="11.1-binary-dependent-variables-and-the-linear-probability-model.html"><a href="11.1-binary-dependent-variables-and-the-linear-probability-model.html"><i class="fa fa-check"></i><b>11.1</b> Binary Dependent Variables and the Linear Probability Model</a></li>
<li class="chapter" data-level="11.2" data-path="11.2-palr.html"><a href="11.2-palr.html"><i class="fa fa-check"></i><b>11.2</b> Probit and Logit Regression</a>
<ul>
<li class="chapter" data-level="" data-path="11.2-palr.html"><a href="11.2-palr.html#probit-regression"><i class="fa fa-check"></i>Probit Regression</a></li>
<li class="chapter" data-level="" data-path="11.2-palr.html"><a href="11.2-palr.html#logit-regression"><i class="fa fa-check"></i>Logit Regression</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="11.3-estimation-and-inference-in-the-logit-and-probit-models.html"><a href="11.3-estimation-and-inference-in-the-logit-and-probit-models.html"><i class="fa fa-check"></i><b>11.3</b> Estimation and Inference in the Logit and Probit Models</a></li>
<li class="chapter" data-level="11.4" data-path="11.4-application-to-the-boston-hmda-data.html"><a href="11.4-application-to-the-boston-hmda-data.html"><i class="fa fa-check"></i><b>11.4</b> Application to the Boston HMDA Data</a></li>
<li class="chapter" data-level="11.5" data-path="11.5-exercises-11.html"><a href="11.5-exercises-11.html"><i class="fa fa-check"></i><b>11.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="12-ivr.html"><a href="12-ivr.html"><i class="fa fa-check"></i><b>12</b> Instrumental Variables Regression</a>
<ul>
<li class="chapter" data-level="12.1" data-path="12.1-TIVEWASRAASI.html"><a href="12.1-TIVEWASRAASI.html"><i class="fa fa-check"></i><b>12.1</b> The IV Estimator with a Single Regressor and a Single Instrument</a></li>
<li class="chapter" data-level="12.2" data-path="12.2-TGIVRM.html"><a href="12.2-TGIVRM.html"><i class="fa fa-check"></i><b>12.2</b> The General IV Regression Model</a></li>
<li class="chapter" data-level="12.3" data-path="12.3-civ.html"><a href="12.3-civ.html"><i class="fa fa-check"></i><b>12.3</b> Checking Instrument Validity</a></li>
<li class="chapter" data-level="12.4" data-path="12.4-attdfc.html"><a href="12.4-attdfc.html"><i class="fa fa-check"></i><b>12.4</b> Application to the Demand for Cigarettes</a></li>
<li class="chapter" data-level="12.5" data-path="12.5-where-do-valid-instruments-come-from.html"><a href="12.5-where-do-valid-instruments-come-from.html"><i class="fa fa-check"></i><b>12.5</b> Where Do Valid Instruments Come From?</a></li>
<li class="chapter" data-level="12.6" data-path="12.6-exercises-12.html"><a href="12.6-exercises-12.html"><i class="fa fa-check"></i><b>12.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="13-eaqe.html"><a href="13-eaqe.html"><i class="fa fa-check"></i><b>13</b> Experiments and Quasi-Experiments</a>
<ul>
<li class="chapter" data-level="13.1" data-path="13.1-poceaie.html"><a href="13.1-poceaie.html"><i class="fa fa-check"></i><b>13.1</b> Potential Outcomes, Causal Effects and Idealized Experiments</a></li>
<li class="chapter" data-level="13.2" data-path="13.2-threats-to-validity-of-experiments.html"><a href="13.2-threats-to-validity-of-experiments.html"><i class="fa fa-check"></i><b>13.2</b> Threats to Validity of Experiments</a></li>
<li class="chapter" data-level="13.3" data-path="13.3-experimental-estimates-of-the-effect-of-class-size-reductions.html"><a href="13.3-experimental-estimates-of-the-effect-of-class-size-reductions.html"><i class="fa fa-check"></i><b>13.3</b> Experimental Estimates of the Effect of Class Size Reductions</a>
<ul>
<li class="chapter" data-level="" data-path="13.3-experimental-estimates-of-the-effect-of-class-size-reductions.html"><a href="13.3-experimental-estimates-of-the-effect-of-class-size-reductions.html#experimental-design-and-the-data-set"><i class="fa fa-check"></i>Experimental Design and the Data Set</a></li>
<li class="chapter" data-level="" data-path="13.3-experimental-estimates-of-the-effect-of-class-size-reductions.html"><a href="13.3-experimental-estimates-of-the-effect-of-class-size-reductions.html#analysis-of-the-star-data"><i class="fa fa-check"></i>Analysis of the STAR Data</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="13.4-qe.html"><a href="13.4-qe.html"><i class="fa fa-check"></i><b>13.4</b> Quasi Experiments</a>
<ul>
<li class="chapter" data-level="" data-path="13.4-qe.html"><a href="13.4-qe.html#the-differences-in-differences-estimator"><i class="fa fa-check"></i>The Differences-in-Differences Estimator</a></li>
<li class="chapter" data-level="" data-path="13.4-qe.html"><a href="13.4-qe.html#regression-discontinuity-estimators"><i class="fa fa-check"></i>Regression Discontinuity Estimators</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="13.5-exercises-13.html"><a href="13.5-exercises-13.html"><i class="fa fa-check"></i><b>13.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="14-ittsraf.html"><a href="14-ittsraf.html"><i class="fa fa-check"></i><b>14</b> Introduction to Time Series Regression and Forecasting</a>
<ul>
<li class="chapter" data-level="14.1" data-path="14.1-using-regression-models-for-forecasting.html"><a href="14.1-using-regression-models-for-forecasting.html"><i class="fa fa-check"></i><b>14.1</b> Using Regression Models for Forecasting</a></li>
<li class="chapter" data-level="14.2" data-path="14.2-tsdasc.html"><a href="14.2-tsdasc.html"><i class="fa fa-check"></i><b>14.2</b> Time Series Data and Serial Correlation</a>
<ul>
<li class="chapter" data-level="" data-path="14.2-tsdasc.html"><a href="14.2-tsdasc.html#notation-lags-differences-logarithms-and-growth-rates"><i class="fa fa-check"></i>Notation, Lags, Differences, Logarithms and Growth Rates</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="14.3-autoregressions.html"><a href="14.3-autoregressions.html"><i class="fa fa-check"></i><b>14.3</b> Autoregressions</a>
<ul>
<li class="chapter" data-level="" data-path="14.3-autoregressions.html"><a href="14.3-autoregressions.html#autoregressive-models-of-order-p"><i class="fa fa-check"></i>Autoregressive Models of Order <span class="math inline">\(p\)</span></a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="14.4-cybtmpi.html"><a href="14.4-cybtmpi.html"><i class="fa fa-check"></i><b>14.4</b> Can You Beat the Market? (Part I)</a></li>
<li class="chapter" data-level="14.5" data-path="14.5-apatadlm.html"><a href="14.5-apatadlm.html"><i class="fa fa-check"></i><b>14.5</b> Additional Predictors and The ADL Model</a>
<ul>
<li class="chapter" data-level="" data-path="14.5-apatadlm.html"><a href="14.5-apatadlm.html#forecast-uncertainty-and-forecast-intervals"><i class="fa fa-check"></i>Forecast Uncertainty and Forecast Intervals</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="14.6-llsuic.html"><a href="14.6-llsuic.html"><i class="fa fa-check"></i><b>14.6</b> Lag Length Selection using Information Criteria</a></li>
<li class="chapter" data-level="14.7" data-path="14.7-nit.html"><a href="14.7-nit.html"><i class="fa fa-check"></i><b>14.7</b> Nonstationarity I: Trends</a></li>
<li class="chapter" data-level="14.8" data-path="14.8-niib.html"><a href="14.8-niib.html"><i class="fa fa-check"></i><b>14.8</b> Nonstationarity II: Breaks</a></li>
<li class="chapter" data-level="14.9" data-path="14.9-can-you-beat-the-market-part-ii.html"><a href="14.9-can-you-beat-the-market-part-ii.html"><i class="fa fa-check"></i><b>14.9</b> Can You Beat the Market? (Part II)</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="15-eodce.html"><a href="15-eodce.html"><i class="fa fa-check"></i><b>15</b> Estimation of Dynamic Causal Effects</a>
<ul>
<li class="chapter" data-level="15.1" data-path="15.1-the-orange-juice-data.html"><a href="15.1-the-orange-juice-data.html"><i class="fa fa-check"></i><b>15.1</b> The Orange Juice Data</a></li>
<li class="chapter" data-level="15.2" data-path="15.2-dynamic-causal-effects.html"><a href="15.2-dynamic-causal-effects.html"><i class="fa fa-check"></i><b>15.2</b> Dynamic Causal Effects</a></li>
<li class="chapter" data-level="15.3" data-path="15.3-dynamic-multipliers-and-cumulative-dynamic-multipliers.html"><a href="15.3-dynamic-multipliers-and-cumulative-dynamic-multipliers.html"><i class="fa fa-check"></i><b>15.3</b> Dynamic Multipliers and Cumulative Dynamic Multipliers</a></li>
<li class="chapter" data-level="15.4" data-path="15.4-hac-standard-errors.html"><a href="15.4-hac-standard-errors.html"><i class="fa fa-check"></i><b>15.4</b> HAC Standard Errors</a></li>
<li class="chapter" data-level="15.5" data-path="15.5-estimation-of-dynamic-causal-effects-with-strictly-exogeneous-regressors.html"><a href="15.5-estimation-of-dynamic-causal-effects-with-strictly-exogeneous-regressors.html"><i class="fa fa-check"></i><b>15.5</b> Estimation of Dynamic Causal Effects with Strictly Exogeneous Regressors</a></li>
<li class="chapter" data-level="15.6" data-path="15.6-orange-juice-prices-and-cold-weather.html"><a href="15.6-orange-juice-prices-and-cold-weather.html"><i class="fa fa-check"></i><b>15.6</b> Orange Juice Prices and Cold Weather</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="16-atitsr.html"><a href="16-atitsr.html"><i class="fa fa-check"></i><b>16</b> Additional Topics in Time Series Regression</a>
<ul>
<li class="chapter" data-level="16.1" data-path="16.1-vector-autoregressions.html"><a href="16.1-vector-autoregressions.html"><i class="fa fa-check"></i><b>16.1</b> Vector Autoregressions</a></li>
<li class="chapter" data-level="16.2" data-path="16.2-ooiatdfglsurt.html"><a href="16.2-ooiatdfglsurt.html"><i class="fa fa-check"></i><b>16.2</b> Orders of Integration and the DF-GLS Unit Root Test</a></li>
<li class="chapter" data-level="16.3" data-path="16.3-cointegration.html"><a href="16.3-cointegration.html"><i class="fa fa-check"></i><b>16.3</b> Cointegration</a></li>
<li class="chapter" data-level="16.4" data-path="16.4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><a href="16.4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><i class="fa fa-check"></i><b>16.4</b> Volatility Clustering and Autoregressive Conditional Heteroskedasticity</a>
<ul>
<li class="chapter" data-level="" data-path="16.4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><a href="16.4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html#arch-and-garch-models"><i class="fa fa-check"></i>ARCH and GARCH Models</a></li>
<li class="chapter" data-level="" data-path="16.4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><a href="16.4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html#application-to-stock-price-volatility"><i class="fa fa-check"></i>Application to Stock Price Volatility</a></li>
<li class="chapter" data-level="" data-path="16.4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><a href="16.4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html#summary-8"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Econometrics with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div class = rmdreview>
This book is in <b>Open Review</b>. We want your feedback to make the book better for you and other students. You may annotate some text by <span style="background-color: #3297FD; color: white">selecting it with the cursor</span> and then click "Annotate" in the pop-up menu. You can also see the annotations of others: click the arrow in the upper right hand corner of the page <i class="fa fa-arrow-circle-right  fa-rotate-315" aria-hidden="true"></i>
</div>
<div id="potsm" class="section level2 hasAnchor" number="3.2">
<h2><span class="header-section-number">3.2</span> Properties of the Sample Mean<a href="3.2-potsm.html#potsm" class="anchor-section" aria-label="Anchor link to header"></a></h2>

<div class="rmdknit">
<p>A more precise way to express consistency of an estimator <span class="math inline">\(\hat\mu\)</span> for a parameter <span class="math inline">\(\mu\)</span> is</p>
<p><span class="math display">\[ P(|\hat{\mu} - \mu|&lt;\epsilon) \xrightarrow[n \rightarrow \infty]{p} 1 \quad \text{for any}\quad\epsilon&gt;0.\]</span></p>
This expression says that the probability of observing a deviation from the true value <span class="math inline">\(\mu\)</span> that is smaller than some arbitrary <span class="math inline">\(\epsilon &gt; 0\)</span> converges to <span class="math inline">\(1\)</span> as <span class="math inline">\(n\)</span> grows. Consistency does not require unbiasedness.
</div>
<p>To examine properties of the sample mean as an estimator for the corresponding population mean, consider the following <tt>R</tt> example.</p>
<p>We generate a population, denoted as <tt>pop</tt>, consisting of observations <span class="math inline">\(Y_i\)</span>, where <span class="math inline">\(i=1,\dots,10000\)</span>. These observations are generated from a normal distribution with mean <span class="math inline">\(\mu = 10\)</span> and variance <span class="math inline">\(\sigma^2 = 1\)</span>.</p>
<p>To investigate the behavior of the estimator <span class="math inline">\(\hat{\mu} = \bar{Y}\)</span>, we can draw random samples from this population and calculate <span class="math inline">\(\bar{Y}\)</span> for each of them. This is easily done by making use of the function <tt>replicate()</tt>. The argument <tt>expr</tt> is evaluated <tt>n</tt> times. In this case we draw samples of sizes <span class="math inline">\(n=5\)</span> and <span class="math inline">\(n=25\)</span>, compute the sample means and repeat this exactly <span class="math inline">\(N=25000\)</span> times.</p>
<p>For comparison purposes we store results for the estimator <span class="math inline">\(Y_1\)</span>, the first observation in a sample of size <span class="math inline">\(5\)</span>, separately.</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="3.2-potsm.html#cb49-1" tabindex="-1"></a><span class="co"># generate a fictious population</span></span>
<span id="cb49-2"><a href="3.2-potsm.html#cb49-2" tabindex="-1"></a>pop <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">10000</span>, <span class="dv">10</span>, <span class="dv">1</span>)</span>
<span id="cb49-3"><a href="3.2-potsm.html#cb49-3" tabindex="-1"></a></span>
<span id="cb49-4"><a href="3.2-potsm.html#cb49-4" tabindex="-1"></a><span class="co"># sample from the population and estimate the mean</span></span>
<span id="cb49-5"><a href="3.2-potsm.html#cb49-5" tabindex="-1"></a>est1 <span class="ot">&lt;-</span> <span class="fu">replicate</span>(<span class="at">expr =</span> <span class="fu">mean</span>(<span class="fu">sample</span>(<span class="at">x =</span> pop, <span class="at">size =</span> <span class="dv">5</span>)), <span class="at">n =</span> <span class="dv">25000</span>)</span>
<span id="cb49-6"><a href="3.2-potsm.html#cb49-6" tabindex="-1"></a></span>
<span id="cb49-7"><a href="3.2-potsm.html#cb49-7" tabindex="-1"></a>est2 <span class="ot">&lt;-</span> <span class="fu">replicate</span>(<span class="at">expr =</span> <span class="fu">mean</span>(<span class="fu">sample</span>(<span class="at">x =</span> pop, <span class="at">size =</span> <span class="dv">25</span>)), <span class="at">n =</span> <span class="dv">25000</span>)</span>
<span id="cb49-8"><a href="3.2-potsm.html#cb49-8" tabindex="-1"></a></span>
<span id="cb49-9"><a href="3.2-potsm.html#cb49-9" tabindex="-1"></a>fo <span class="ot">&lt;-</span> <span class="fu">replicate</span>(<span class="at">expr =</span> <span class="fu">sample</span>(<span class="at">x =</span> pop, <span class="at">size =</span> <span class="dv">5</span>)[<span class="dv">1</span>], <span class="at">n =</span> <span class="dv">25000</span>)</span></code></pre></div>
<p>Check that <tt>est1</tt> and <tt>est2</tt> are vectors of length <span class="math inline">\(25000\)</span>:</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="3.2-potsm.html#cb50-1" tabindex="-1"></a><span class="co"># check if object type is vector</span></span>
<span id="cb50-2"><a href="3.2-potsm.html#cb50-2" tabindex="-1"></a><span class="fu">is.vector</span>(est1)</span>
<span id="cb50-3"><a href="3.2-potsm.html#cb50-3" tabindex="-1"></a><span class="co">#&gt; [1] TRUE</span></span>
<span id="cb50-4"><a href="3.2-potsm.html#cb50-4" tabindex="-1"></a><span class="fu">is.vector</span>(est2)</span>
<span id="cb50-5"><a href="3.2-potsm.html#cb50-5" tabindex="-1"></a><span class="co">#&gt; [1] TRUE</span></span>
<span id="cb50-6"><a href="3.2-potsm.html#cb50-6" tabindex="-1"></a></span>
<span id="cb50-7"><a href="3.2-potsm.html#cb50-7" tabindex="-1"></a><span class="co"># check length</span></span>
<span id="cb50-8"><a href="3.2-potsm.html#cb50-8" tabindex="-1"></a><span class="fu">length</span>(est1)</span>
<span id="cb50-9"><a href="3.2-potsm.html#cb50-9" tabindex="-1"></a><span class="co">#&gt; [1] 25000</span></span>
<span id="cb50-10"><a href="3.2-potsm.html#cb50-10" tabindex="-1"></a><span class="fu">length</span>(est2)</span>
<span id="cb50-11"><a href="3.2-potsm.html#cb50-11" tabindex="-1"></a><span class="co">#&gt; [1] 25000</span></span></code></pre></div>
<p>The code chunk below produces a plot of the sampling distributions of the estimators <span class="math inline">\(\bar{Y}\)</span> and <span class="math inline">\(Y_1\)</span> on the basis of the <span class="math inline">\(25000\)</span> samples in each case. We also plot the density function of the <span class="math inline">\(\mathcal{N}(10,1)\)</span> distribution.</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="3.2-potsm.html#cb51-1" tabindex="-1"></a><span class="co"># plot density estimate Y_1</span></span>
<span id="cb51-2"><a href="3.2-potsm.html#cb51-2" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">density</span>(fo), </span>
<span id="cb51-3"><a href="3.2-potsm.html#cb51-3" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&quot;green&quot;</span>, </span>
<span id="cb51-4"><a href="3.2-potsm.html#cb51-4" tabindex="-1"></a>      <span class="at">lwd =</span> <span class="dv">2</span>,</span>
<span id="cb51-5"><a href="3.2-potsm.html#cb51-5" tabindex="-1"></a>      <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">2</span>),</span>
<span id="cb51-6"><a href="3.2-potsm.html#cb51-6" tabindex="-1"></a>      <span class="at">xlab =</span> <span class="st">&quot;Estimates&quot;</span>,</span>
<span id="cb51-7"><a href="3.2-potsm.html#cb51-7" tabindex="-1"></a>      <span class="at">main =</span> <span class="st">&quot;Sampling Distributions of Unbiased Estimators&quot;</span>)</span>
<span id="cb51-8"><a href="3.2-potsm.html#cb51-8" tabindex="-1"></a></span>
<span id="cb51-9"><a href="3.2-potsm.html#cb51-9" tabindex="-1"></a><span class="co"># add density estimate for the distribution of the sample mean with n=5 to the plot</span></span>
<span id="cb51-10"><a href="3.2-potsm.html#cb51-10" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">density</span>(est1), </span>
<span id="cb51-11"><a href="3.2-potsm.html#cb51-11" tabindex="-1"></a>     <span class="at">col =</span> <span class="st">&quot;steelblue&quot;</span>, </span>
<span id="cb51-12"><a href="3.2-potsm.html#cb51-12" tabindex="-1"></a>     <span class="at">lwd =</span> <span class="dv">2</span>, </span>
<span id="cb51-13"><a href="3.2-potsm.html#cb51-13" tabindex="-1"></a>     <span class="at">bty =</span> <span class="st">&quot;l&quot;</span>)</span>
<span id="cb51-14"><a href="3.2-potsm.html#cb51-14" tabindex="-1"></a></span>
<span id="cb51-15"><a href="3.2-potsm.html#cb51-15" tabindex="-1"></a><span class="co"># add density estimate for the distribution of the sample mean with n=25 to the plot</span></span>
<span id="cb51-16"><a href="3.2-potsm.html#cb51-16" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">density</span>(est2), </span>
<span id="cb51-17"><a href="3.2-potsm.html#cb51-17" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&quot;red2&quot;</span>, </span>
<span id="cb51-18"><a href="3.2-potsm.html#cb51-18" tabindex="-1"></a>      <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb51-19"><a href="3.2-potsm.html#cb51-19" tabindex="-1"></a></span>
<span id="cb51-20"><a href="3.2-potsm.html#cb51-20" tabindex="-1"></a><span class="co"># add a vertical line at the true parameter</span></span>
<span id="cb51-21"><a href="3.2-potsm.html#cb51-21" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="dv">10</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb51-22"><a href="3.2-potsm.html#cb51-22" tabindex="-1"></a></span>
<span id="cb51-23"><a href="3.2-potsm.html#cb51-23" tabindex="-1"></a><span class="co"># add N(10,1) density to the plot</span></span>
<span id="cb51-24"><a href="3.2-potsm.html#cb51-24" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dnorm</span>(x, <span class="at">mean =</span> <span class="dv">10</span>), </span>
<span id="cb51-25"><a href="3.2-potsm.html#cb51-25" tabindex="-1"></a>     <span class="at">lwd =</span> <span class="dv">2</span>,</span>
<span id="cb51-26"><a href="3.2-potsm.html#cb51-26" tabindex="-1"></a>     <span class="at">lty =</span> <span class="dv">2</span>,</span>
<span id="cb51-27"><a href="3.2-potsm.html#cb51-27" tabindex="-1"></a>     <span class="at">add =</span> T)</span>
<span id="cb51-28"><a href="3.2-potsm.html#cb51-28" tabindex="-1"></a></span>
<span id="cb51-29"><a href="3.2-potsm.html#cb51-29" tabindex="-1"></a><span class="co"># add a legend</span></span>
<span id="cb51-30"><a href="3.2-potsm.html#cb51-30" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topleft&quot;</span>,</span>
<span id="cb51-31"><a href="3.2-potsm.html#cb51-31" tabindex="-1"></a>       <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">&quot;N(10,1)&quot;</span>,</span>
<span id="cb51-32"><a href="3.2-potsm.html#cb51-32" tabindex="-1"></a>                  <span class="fu">expression</span>(Y[n <span class="sc">==</span> <span class="dv">1</span>]),</span>
<span id="cb51-33"><a href="3.2-potsm.html#cb51-33" tabindex="-1"></a>                  <span class="fu">expression</span>(<span class="fu">bar</span>(Y)[n <span class="sc">==</span> <span class="dv">5</span>]),</span>
<span id="cb51-34"><a href="3.2-potsm.html#cb51-34" tabindex="-1"></a>                  <span class="fu">expression</span>(<span class="fu">bar</span>(Y)[n <span class="sc">==</span> <span class="dv">25</span>])</span>
<span id="cb51-35"><a href="3.2-potsm.html#cb51-35" tabindex="-1"></a>                  ), </span>
<span id="cb51-36"><a href="3.2-potsm.html#cb51-36" tabindex="-1"></a>       <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>), </span>
<span id="cb51-37"><a href="3.2-potsm.html#cb51-37" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;black&quot;</span>,<span class="st">&quot;green&quot;</span>, <span class="st">&quot;steelblue&quot;</span>, <span class="st">&quot;red2&quot;</span>),</span>
<span id="cb51-38"><a href="3.2-potsm.html#cb51-38" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="ITER_files/figure-html/unnamed-chunk-96-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>First, <em>all</em> sampling distributions (represented by the solid lines) are centered around <span class="math inline">\(\mu = 10\)</span>. This is evidence for the <em>unbiasedness</em> of <span class="math inline">\(Y_1\)</span>, <span class="math inline">\(\overline{Y}_{5}\)</span> and <span class="math inline">\(\overline{Y}_{25}\)</span>. Of course, the theoretical density <span class="math inline">\(\mathcal{N}(10,1)\)</span> is also centered at <span class="math inline">\(10\)</span>.</p>
<p>Next, have a look at the spread of the sampling distributions. Several things are noteworthy:</p>
<ul>
<li><p>The sampling distribution of <span class="math inline">\(Y_1\)</span> (green curve) tracks the density of the <span class="math inline">\(\mathcal{N}(10,1)\)</span> distribution (black dashed line) pretty closely. In fact, the sampling distribution of <span class="math inline">\(Y_1\)</span> is the <span class="math inline">\(\mathcal{N}(10,1)\)</span> distribution. This is less surprising if you keep in mind that the <span class="math inline">\(Y_1\)</span> estimator does nothing but reporting an observation that is randomly selected from a population with <span class="math inline">\(\mathcal{N}(10,1)\)</span> distribution. Hence, <span class="math inline">\(Y_1 \sim \mathcal{N}(10,1)\)</span>. Note that this result does not depend on the sample size <span class="math inline">\(n\)</span>: the sampling distribution of <span class="math inline">\(Y_1\)</span> <em>is always</em> the population distribution, no matter how large the sample is, <span class="math inline">\(Y_1\)</span> is a good estimate of <span class="math inline">\(\mu_Y\)</span>, but we can do better.</p></li>
<li><p>Both the sampling distributions of <span class="math inline">\(\overline{Y}\)</span> show less dispersion than the sampling distribution of <span class="math inline">\(Y_1\)</span>. This means that <span class="math inline">\(\overline{Y}\)</span> has a lower variance than <span class="math inline">\(Y_1\)</span>. In view of Key Concepts 3.2 and 3.3, we find that <span class="math inline">\(\overline{Y}\)</span> is a more efficient estimator than <span class="math inline">\(Y_1\)</span>. In fact, this holds for all <span class="math inline">\(n&gt;1\)</span>.</p></li>
<li><p><span class="math inline">\(\overline{Y}\)</span> shows a behavior illustrating consistency (see Key Concept 3.2). The blue and the red densities are much more concentrated around <span class="math inline">\(\mu=10\)</span> than the green one. As the number of observations is increased from <span class="math inline">\(1\)</span> to <span class="math inline">\(5\)</span>, the sampling distribution tightens around the true parameter. By increasing the sample size to <span class="math inline">\(25\)</span>, this effect becomes more apparent. This implies that the probability of obtaining estimates that are close to the true value increases with <span class="math inline">\(n\)</span>. This is also reflected by the estimated values of the density function close to 10: the larger the sample size, the larger the value of the density.</p></li>
</ul>
<p>We encourage you to go ahead and modify the code. Try out different values for the sample size and see how the sampling distribution of <span class="math inline">\(\overline{Y}\)</span> changes!</p>
<div id="overliney-is-the-least-squares-estimator-of-mu_y" class="section level4 unnumbered hasAnchor">
<h4><span class="math inline">\(\overline{Y}\)</span> is the Least Squares Estimator of <span class="math inline">\(\mu_Y\)</span><a href="3.2-potsm.html#overliney-is-the-least-squares-estimator-of-mu_y" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Assume you have some observations <span class="math inline">\(Y_1,\dots,Y_n\)</span> on <span class="math inline">\(Y \sim \mathcal{N}(10,1)\)</span> (which is unknown) and would like to find an estimator <span class="math inline">\(m\)</span> that predicts the observations as good as possible. Here, we aim to find an estimator <span class="math inline">\(m\)</span> that results in a small total squared deviation between the predicted and observed values. Mathematically, this means we want to find an <span class="math inline">\(m\)</span> that minimizes</p>
<p><span class="math display" id="eq:sqm">\[\begin{equation}
  \sum_{i=1}^n (Y_i - m)^2. \tag{3.1}
\end{equation}\]</span></p>
<p>Think of <span class="math inline">\(Y_i - m\)</span> as the mistake made when predicting <span class="math inline">\(Y_i\)</span> by <span class="math inline">\(m\)</span>. We could also minimize the sum of absolute deviations from <span class="math inline">\(m\)</span> but minimizing the sum of squared deviations is mathematically more convenient (and will lead to a different result). That is why the estimator we are looking for is called the <em>least squares estimator</em>. <span class="math inline">\(m = \overline{Y}\)</span>, the sample mean, is this estimator.</p>
<p>We can show this by generating a random sample and plotting <a href="3.2-potsm.html#eq:sqm">(3.1)</a> as a function of <span class="math inline">\(m\)</span>.</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="3.2-potsm.html#cb52-1" tabindex="-1"></a><span class="co"># define the function and vectorize it</span></span>
<span id="cb52-2"><a href="3.2-potsm.html#cb52-2" tabindex="-1"></a>sqm <span class="ot">&lt;-</span> <span class="cf">function</span>(m) {</span>
<span id="cb52-3"><a href="3.2-potsm.html#cb52-3" tabindex="-1"></a> <span class="fu">sum</span>((y<span class="sc">-</span>m)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb52-4"><a href="3.2-potsm.html#cb52-4" tabindex="-1"></a>}</span>
<span id="cb52-5"><a href="3.2-potsm.html#cb52-5" tabindex="-1"></a>sqm <span class="ot">&lt;-</span> <span class="fu">Vectorize</span>(sqm)</span>
<span id="cb52-6"><a href="3.2-potsm.html#cb52-6" tabindex="-1"></a></span>
<span id="cb52-7"><a href="3.2-potsm.html#cb52-7" tabindex="-1"></a><span class="co"># draw random sample and compute the mean</span></span>
<span id="cb52-8"><a href="3.2-potsm.html#cb52-8" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="dv">10</span>, <span class="dv">1</span>)</span>
<span id="cb52-9"><a href="3.2-potsm.html#cb52-9" tabindex="-1"></a><span class="fu">mean</span>(y)</span>
<span id="cb52-10"><a href="3.2-potsm.html#cb52-10" tabindex="-1"></a><span class="co">#&gt; [1] 10.1364</span></span></code></pre></div>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="3.2-potsm.html#cb53-1" tabindex="-1"></a><span class="co"># plot the objective function</span></span>
<span id="cb53-2"><a href="3.2-potsm.html#cb53-2" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">sqm</span>(x), </span>
<span id="cb53-3"><a href="3.2-potsm.html#cb53-3" tabindex="-1"></a>      <span class="at">from =</span> <span class="sc">-</span><span class="dv">50</span>, </span>
<span id="cb53-4"><a href="3.2-potsm.html#cb53-4" tabindex="-1"></a>      <span class="at">to =</span> <span class="dv">70</span>,</span>
<span id="cb53-5"><a href="3.2-potsm.html#cb53-5" tabindex="-1"></a>      <span class="at">xlab =</span> <span class="st">&quot;m&quot;</span>,</span>
<span id="cb53-6"><a href="3.2-potsm.html#cb53-6" tabindex="-1"></a>      <span class="at">ylab =</span> <span class="st">&quot;sqm(m)&quot;</span>)</span>
<span id="cb53-7"><a href="3.2-potsm.html#cb53-7" tabindex="-1"></a></span>
<span id="cb53-8"><a href="3.2-potsm.html#cb53-8" tabindex="-1"></a><span class="co"># add vertical line at mean(y)</span></span>
<span id="cb53-9"><a href="3.2-potsm.html#cb53-9" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">mean</span>(y), </span>
<span id="cb53-10"><a href="3.2-potsm.html#cb53-10" tabindex="-1"></a>       <span class="at">lty =</span> <span class="dv">2</span>, </span>
<span id="cb53-11"><a href="3.2-potsm.html#cb53-11" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">&quot;darkred&quot;</span>)</span>
<span id="cb53-12"><a href="3.2-potsm.html#cb53-12" tabindex="-1"></a></span>
<span id="cb53-13"><a href="3.2-potsm.html#cb53-13" tabindex="-1"></a><span class="co"># add annotation at mean(y)</span></span>
<span id="cb53-14"><a href="3.2-potsm.html#cb53-14" tabindex="-1"></a><span class="fu">text</span>(<span class="at">x =</span> <span class="fu">mean</span>(y), </span>
<span id="cb53-15"><a href="3.2-potsm.html#cb53-15" tabindex="-1"></a>     <span class="at">y =</span> <span class="dv">0</span>, </span>
<span id="cb53-16"><a href="3.2-potsm.html#cb53-16" tabindex="-1"></a>     <span class="at">labels =</span> <span class="fu">paste</span>(<span class="fu">round</span>(<span class="fu">mean</span>(y), <span class="dv">2</span>)))</span></code></pre></div>
<p><img src="ITER_files/figure-html/unnamed-chunk-98-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Notice that <a href="3.2-potsm.html#eq:sqm">(3.1)</a> is a quadratic function so that there is only one minimum. The plot shows that this minimum lies exactly at the sample mean of the sample data.</p>

<div class="rmdknit">
<p>Some <tt>R</tt> functions can only interact with functions that take a vector as an input and evaluate the function body on every entry of the vector, for example <tt>curve()</tt>. We call such functions vectorized functions and it is often a good idea to write vectorized functions yourself, although this is cumbersome in some cases. Having a vectorized function in <tt>R</tt> is never a drawback since, these functions work on both single values and vectors.</p>
<p>Let us look at the function <tt>sqm()</tt>, which is non-vectorized:</p>
<p><tt>
sqm &lt;- function(m) {<br />
     sum((y-m)^2) #body of the function<br />
}
</tt></p>
<p>Providing, e.g., <tt>c(1,2,3)</tt> as the argument <tt>m</tt> would cause an error since then the operation <tt>y-m</tt> is invalid: the vectors <tt>y</tt> and <tt>m</tt> are of incompatible dimensions. This is why we cannot use <tt>sqm()</tt> in conjunction with <tt>curve()</tt>.</p>
Here <tt>Vectorize()</tt> comes into play. It generates a vectorized version of a non-vectorized function.
</div>
</div>
<div id="why-is-random-sampling-important" class="section level4 unnumbered hasAnchor">
<h4>Why is Random Sampling Important ?<a href="3.2-potsm.html#why-is-random-sampling-important" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>So far, we assumed (sometimes implicitly) that the observed data <span class="math inline">\(Y_1, \dots, Y_n\)</span> are the result of a sampling process that satisfies the assumption of simple random sampling. This assumption often is fulfilled when estimating a population mean using <span class="math inline">\(\overline{Y}\)</span>. If this is not the case, estimates may be biased.</p>
<p>Let us fall back to <tt>pop</tt>, the fictitious population of <span class="math inline">\(10000\)</span> observations and compute the population mean <span class="math inline">\(\mu_{\texttt{pop}}\)</span>:</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="3.2-potsm.html#cb54-1" tabindex="-1"></a><span class="co"># compute the population mean of pop</span></span>
<span id="cb54-2"><a href="3.2-potsm.html#cb54-2" tabindex="-1"></a><span class="fu">mean</span>(pop)</span>
<span id="cb54-3"><a href="3.2-potsm.html#cb54-3" tabindex="-1"></a><span class="co">#&gt; [1] 9.992604</span></span></code></pre></div>
<p>Next we sample <span class="math inline">\(25\)</span> observations from <tt>pop</tt> with <tt>sample()</tt> and estimate <span class="math inline">\(\mu_{\texttt{pop}}\)</span> using <span class="math inline">\(\overline{Y}\)</span> repeatedly. However, now we use a sampling scheme that deviates from simple random sampling: instead of ensuring that each member of the population has the same chance to end up in a sample, we assign a higher probability of being sampled to the <span class="math inline">\(2500\)</span> smallest observations of the population by setting the argument <tt>prob</tt> to a suitable vector of probability weights:</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="3.2-potsm.html#cb55-1" tabindex="-1"></a><span class="co"># simulate outcomes for the sample mean when the i.i.d. assumption fails</span></span>
<span id="cb55-2"><a href="3.2-potsm.html#cb55-2" tabindex="-1"></a>est3 <span class="ot">&lt;-</span>  <span class="fu">replicate</span>(<span class="at">n =</span> <span class="dv">25000</span>, </span>
<span id="cb55-3"><a href="3.2-potsm.html#cb55-3" tabindex="-1"></a>                   <span class="at">expr =</span> <span class="fu">mean</span>(<span class="fu">sample</span>(<span class="at">x =</span> <span class="fu">sort</span>(pop), </span>
<span id="cb55-4"><a href="3.2-potsm.html#cb55-4" tabindex="-1"></a>                                      <span class="at">size =</span> <span class="dv">25</span>, </span>
<span id="cb55-5"><a href="3.2-potsm.html#cb55-5" tabindex="-1"></a>                                      <span class="at">prob =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">4</span>, <span class="dv">2500</span>), <span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">7500</span>)))))</span>
<span id="cb55-6"><a href="3.2-potsm.html#cb55-6" tabindex="-1"></a></span>
<span id="cb55-7"><a href="3.2-potsm.html#cb55-7" tabindex="-1"></a><span class="co"># compute the sample mean of the outcomes</span></span>
<span id="cb55-8"><a href="3.2-potsm.html#cb55-8" tabindex="-1"></a><span class="fu">mean</span>(est3)</span>
<span id="cb55-9"><a href="3.2-potsm.html#cb55-9" tabindex="-1"></a><span class="co">#&gt; [1] 9.443067</span></span></code></pre></div>
<p>Next we plot the sampling distribution of <span class="math inline">\(\overline{Y}\)</span> for this non-i.i.d. case and compare it to the sampling distribution when the i.i.d. assumption holds.</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="3.2-potsm.html#cb56-1" tabindex="-1"></a><span class="co"># sampling distribution of sample mean, i.i.d. holds, n=25</span></span>
<span id="cb56-2"><a href="3.2-potsm.html#cb56-2" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">density</span>(est2), </span>
<span id="cb56-3"><a href="3.2-potsm.html#cb56-3" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&quot;steelblue&quot;</span>,</span>
<span id="cb56-4"><a href="3.2-potsm.html#cb56-4" tabindex="-1"></a>      <span class="at">lwd =</span> <span class="dv">2</span>,</span>
<span id="cb56-5"><a href="3.2-potsm.html#cb56-5" tabindex="-1"></a>      <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">8</span>, <span class="dv">11</span>),</span>
<span id="cb56-6"><a href="3.2-potsm.html#cb56-6" tabindex="-1"></a>      <span class="at">xlab =</span> <span class="st">&quot;Estimates&quot;</span>,</span>
<span id="cb56-7"><a href="3.2-potsm.html#cb56-7" tabindex="-1"></a>      <span class="at">main =</span> <span class="st">&quot;When the i.i.d. Assumption Fails&quot;</span>)</span>
<span id="cb56-8"><a href="3.2-potsm.html#cb56-8" tabindex="-1"></a></span>
<span id="cb56-9"><a href="3.2-potsm.html#cb56-9" tabindex="-1"></a><span class="co"># sampling distribution of sample mean, i.i.d. fails, n=25</span></span>
<span id="cb56-10"><a href="3.2-potsm.html#cb56-10" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">density</span>(est3),</span>
<span id="cb56-11"><a href="3.2-potsm.html#cb56-11" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&quot;red2&quot;</span>,</span>
<span id="cb56-12"><a href="3.2-potsm.html#cb56-12" tabindex="-1"></a>      <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb56-13"><a href="3.2-potsm.html#cb56-13" tabindex="-1"></a></span>
<span id="cb56-14"><a href="3.2-potsm.html#cb56-14" tabindex="-1"></a><span class="co"># add a legend</span></span>
<span id="cb56-15"><a href="3.2-potsm.html#cb56-15" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topleft&quot;</span>,</span>
<span id="cb56-16"><a href="3.2-potsm.html#cb56-16" tabindex="-1"></a>       <span class="at">legend =</span> <span class="fu">c</span>(<span class="fu">expression</span>(<span class="fu">bar</span>(Y)[n <span class="sc">==</span> <span class="dv">25</span>]<span class="sc">~</span><span class="st">&quot;, i.i.d. fails&quot;</span>),</span>
<span id="cb56-17"><a href="3.2-potsm.html#cb56-17" tabindex="-1"></a>                  <span class="fu">expression</span>(<span class="fu">bar</span>(Y)[n <span class="sc">==</span> <span class="dv">25</span>]<span class="sc">~</span><span class="st">&quot;, i.i.d. holds&quot;</span>)</span>
<span id="cb56-18"><a href="3.2-potsm.html#cb56-18" tabindex="-1"></a>                  ), </span>
<span id="cb56-19"><a href="3.2-potsm.html#cb56-19" tabindex="-1"></a>       <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), </span>
<span id="cb56-20"><a href="3.2-potsm.html#cb56-20" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;red2&quot;</span>, <span class="st">&quot;steelblue&quot;</span>),</span>
<span id="cb56-21"><a href="3.2-potsm.html#cb56-21" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="ITER_files/figure-html/unnamed-chunk-101-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Here, the failure of the i.i.d. assumption implies that, on average, we <em>underestimate</em> <span class="math inline">\(\mu_Y\)</span> using <span class="math inline">\(\overline{Y}\)</span>: the corresponding distribution of <span class="math inline">\(\overline{Y}\)</span> is shifted to the left. In other words, <span class="math inline">\(\overline{Y}\)</span> is a <em>biased</em> estimator for <span class="math inline">\(\mu_Y\)</span> if the i.i.d. assumption does not hold.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="3.1-estimation-of-the-population-mean.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="3.3-hypothesis-tests-concerning-the-population-mean.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": true,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": {
"link": "https://github.com/mca91/EconometricsWithR/edit/master/03-ch3.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ITER.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
