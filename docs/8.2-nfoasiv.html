<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>8.2 Nonlinear Functions of a Single Independent Variable | Introduction to Econometrics with R</title>
  <meta name="description" content="Beginners with little background in statistics and econometrics often have a hard time understanding the benefits of having programming skills for learning and applying Econometrics. ‘Introduction to Econometrics with R’ is an interactive companion to the well-received textbook ‘Introduction to Econometrics’ by James H. Stock and Mark W. Watson (2015). It gives a gentle introduction to the essentials of R programming and guides students in implementing the empirical applications presented throughout the textbook using the newly aquired skills. This is supported by interactive programming exercises generated with DataCamp Light and integration of interactive visualizations of central concepts which are based on the flexible JavaScript library D3.js." />
  <meta name="generator" content="bookdown 0.36 and GitBook 2.6.7" />

  <meta property="og:title" content="8.2 Nonlinear Functions of a Single Independent Variable | Introduction to Econometrics with R" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://www.econometrics-with-r.org//images/cover.png" />
  <meta property="og:description" content="Beginners with little background in statistics and econometrics often have a hard time understanding the benefits of having programming skills for learning and applying Econometrics. ‘Introduction to Econometrics with R’ is an interactive companion to the well-received textbook ‘Introduction to Econometrics’ by James H. Stock and Mark W. Watson (2015). It gives a gentle introduction to the essentials of R programming and guides students in implementing the empirical applications presented throughout the textbook using the newly aquired skills. This is supported by interactive programming exercises generated with DataCamp Light and integration of interactive visualizations of central concepts which are based on the flexible JavaScript library D3.js." />
  <meta name="github-repo" content="mca91/EconometricsWithR" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="8.2 Nonlinear Functions of a Single Independent Variable | Introduction to Econometrics with R" />
  
  <meta name="twitter:description" content="Beginners with little background in statistics and econometrics often have a hard time understanding the benefits of having programming skills for learning and applying Econometrics. ‘Introduction to Econometrics with R’ is an interactive companion to the well-received textbook ‘Introduction to Econometrics’ by James H. Stock and Mark W. Watson (2015). It gives a gentle introduction to the essentials of R programming and guides students in implementing the empirical applications presented throughout the textbook using the newly aquired skills. This is supported by interactive programming exercises generated with DataCamp Light and integration of interactive visualizations of central concepts which are based on the flexible JavaScript library D3.js." />
  <meta name="twitter:image" content="https://www.econometrics-with-r.org//images/cover.png" />

<meta name="author" content="Christoph Hanck, Martin Arnold, Alexander Gerber, and Martin Schmelzer" />


<meta name="date" content="2024-02-13" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="8.1-a-general-strategy-for-modelling-nonlinear-regression-functions.html"/>
<link rel="next" href="8.3-interactions-between-independent-variables.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.6.2/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.10.3/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.11.1/plotly-latest.min.js"></script>
<!-- font families -->

<link href="https://fonts.googleapis.com/css?family=PT+Sans|Pacifico|Source+Sans+Pro" rel="stylesheet">

<script src="js/hideOutput.js"></script>

<!-- Mathjax -->
<script type="text/javascript" id="MathJax-script" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/mml-chtml.min.js"></script>

 <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        extensions: ["tex2jax.js", "TeX/AMSmath.js"],
        tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
        jax: ["input/TeX","output/CommonHTML"]
      });
      MathJax.Hub.processSectionDelay = 0;
  </script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110299877-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110299877-1');
</script>

<!-- open review block -->

<script type="application/json" class="js-hypothesis-config">
{
"showHighlights": false
}
</script>
<script async defer src="https://hypothes.is/embed.js"></script>



<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #204a87; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #204a87; font-weight: bold; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #ce5c00; font-weight: bold; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><center><img src="images/logo.png" alt="logo" width="50%" height="50%"style="margin: 15px 0 0 0"></center></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="1-introduction.html"><a href="1-introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="1.1-colophon.html"><a href="1.1-colophon.html"><i class="fa fa-check"></i><b>1.1</b> Colophon</a></li>
<li class="chapter" data-level="1.2" data-path="1.2-a-very-short-introduction-to-r-and-rstudio.html"><a href="1.2-a-very-short-introduction-to-r-and-rstudio.html"><i class="fa fa-check"></i><b>1.2</b> A Very Short Introduction to <tt>R</tt> and <em>RStudio</em></a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-pt.html"><a href="2-pt.html"><i class="fa fa-check"></i><b>2</b> Probability Theory</a>
<ul>
<li class="chapter" data-level="2.1" data-path="2.1-random-variables-and-probability-distributions.html"><a href="2.1-random-variables-and-probability-distributions.html"><i class="fa fa-check"></i><b>2.1</b> Random Variables and Probability Distributions</a>
<ul>
<li class="chapter" data-level="" data-path="2.1-random-variables-and-probability-distributions.html"><a href="2.1-random-variables-and-probability-distributions.html#probability-distributions-of-discrete-random-variables"><i class="fa fa-check"></i>Probability Distributions of Discrete Random Variables</a></li>
<li class="chapter" data-level="" data-path="2.1-random-variables-and-probability-distributions.html"><a href="2.1-random-variables-and-probability-distributions.html#bernoulli-trials"><i class="fa fa-check"></i>Bernoulli Trials</a></li>
<li class="chapter" data-level="" data-path="2.1-random-variables-and-probability-distributions.html"><a href="2.1-random-variables-and-probability-distributions.html#expected-value-mean-and-variance"><i class="fa fa-check"></i>Expected Value, Mean and Variance</a></li>
<li class="chapter" data-level="" data-path="2.1-random-variables-and-probability-distributions.html"><a href="2.1-random-variables-and-probability-distributions.html#probability-distributions-of-continuous-random-variables"><i class="fa fa-check"></i>Probability Distributions of Continuous Random Variables</a></li>
<li class="chapter" data-level="" data-path="2.1-random-variables-and-probability-distributions.html"><a href="2.1-random-variables-and-probability-distributions.html#the-normal-distribution"><i class="fa fa-check"></i>The Normal Distribution</a></li>
<li class="chapter" data-level="" data-path="2.1-random-variables-and-probability-distributions.html"><a href="2.1-random-variables-and-probability-distributions.html#the-chi-squared-distribution"><i class="fa fa-check"></i>The Chi-Squared Distribution</a></li>
<li class="chapter" data-level="" data-path="2.1-random-variables-and-probability-distributions.html"><a href="2.1-random-variables-and-probability-distributions.html#thetdist"><i class="fa fa-check"></i>The Student t Distribution</a></li>
<li class="chapter" data-level="" data-path="2.1-random-variables-and-probability-distributions.html"><a href="2.1-random-variables-and-probability-distributions.html#the-f-distribution"><i class="fa fa-check"></i>The F Distribution</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="2.2-RSATDOSA.html"><a href="2.2-RSATDOSA.html"><i class="fa fa-check"></i><b>2.2</b> Random Sampling and the Distribution of Sample Averages</a>
<ul>
<li class="chapter" data-level="" data-path="2.2-RSATDOSA.html"><a href="2.2-RSATDOSA.html#mean-and-variance-of-the-sample-mean"><i class="fa fa-check"></i>Mean and Variance of the Sample Mean</a></li>
<li class="chapter" data-level="" data-path="2.2-RSATDOSA.html"><a href="2.2-RSATDOSA.html#large-sample-approximations-to-sampling-distributions"><i class="fa fa-check"></i>Large Sample Approximations to Sampling Distributions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="2.3-exercises-2.html"><a href="2.3-exercises-2.html"><i class="fa fa-check"></i><b>2.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-arosur.html"><a href="3-arosur.html"><i class="fa fa-check"></i><b>3</b> A Review of Statistics using R</a>
<ul>
<li class="chapter" data-level="3.1" data-path="3.1-estimation-of-the-population-mean.html"><a href="3.1-estimation-of-the-population-mean.html"><i class="fa fa-check"></i><b>3.1</b> Estimation of the Population Mean</a></li>
<li class="chapter" data-level="3.2" data-path="3.2-potsm.html"><a href="3.2-potsm.html"><i class="fa fa-check"></i><b>3.2</b> Properties of the Sample Mean</a></li>
<li class="chapter" data-level="3.3" data-path="3.3-hypothesis-tests-concerning-the-population-mean.html"><a href="3.3-hypothesis-tests-concerning-the-population-mean.html"><i class="fa fa-check"></i><b>3.3</b> Hypothesis Tests concerning the Population Mean</a>
<ul>
<li class="chapter" data-level="" data-path="3.3-hypothesis-tests-concerning-the-population-mean.html"><a href="3.3-hypothesis-tests-concerning-the-population-mean.html#the-p-value"><i class="fa fa-check"></i>The p-Value</a></li>
<li class="chapter" data-level="" data-path="3.3-hypothesis-tests-concerning-the-population-mean.html"><a href="3.3-hypothesis-tests-concerning-the-population-mean.html#calculating-the-p-value-when-the-standard-deviation-is-known"><i class="fa fa-check"></i>Calculating the p-Value when the Standard Deviation is Known</a></li>
<li class="chapter" data-level="" data-path="3.3-hypothesis-tests-concerning-the-population-mean.html"><a href="3.3-hypothesis-tests-concerning-the-population-mean.html#SVSSDASE"><i class="fa fa-check"></i>Sample Variance, Sample Standard Deviation and Standard Error</a></li>
<li class="chapter" data-level="" data-path="3.3-hypothesis-tests-concerning-the-population-mean.html"><a href="3.3-hypothesis-tests-concerning-the-population-mean.html#calculating-the-p-value-when-the-standard-deviation-is-unknown"><i class="fa fa-check"></i>Calculating the p-value When the Standard Deviation is Unknown</a></li>
<li class="chapter" data-level="" data-path="3.3-hypothesis-tests-concerning-the-population-mean.html"><a href="3.3-hypothesis-tests-concerning-the-population-mean.html#the-t-statistic"><i class="fa fa-check"></i>The t-statistic</a></li>
<li class="chapter" data-level="" data-path="3.3-hypothesis-tests-concerning-the-population-mean.html"><a href="3.3-hypothesis-tests-concerning-the-population-mean.html#hypothesis-testing-with-a-prespecified-significance-level"><i class="fa fa-check"></i>Hypothesis Testing with a Prespecified Significance Level</a></li>
<li class="chapter" data-level="" data-path="3.3-hypothesis-tests-concerning-the-population-mean.html"><a href="3.3-hypothesis-tests-concerning-the-population-mean.html#one-sided-alternatives"><i class="fa fa-check"></i>One-sided Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="3.4-confidence-intervals-for-the-population-mean.html"><a href="3.4-confidence-intervals-for-the-population-mean.html"><i class="fa fa-check"></i><b>3.4</b> Confidence Intervals for the Population Mean</a></li>
<li class="chapter" data-level="3.5" data-path="3.5-cmfdp.html"><a href="3.5-cmfdp.html"><i class="fa fa-check"></i><b>3.5</b> Comparing Means from Different Populations</a></li>
<li class="chapter" data-level="3.6" data-path="3.6-aattggoe.html"><a href="3.6-aattggoe.html"><i class="fa fa-check"></i><b>3.6</b> An Application to the Gender Gap of Earnings</a></li>
<li class="chapter" data-level="3.7" data-path="3.7-scatterplots-sample-covariance-and-sample-correlation.html"><a href="3.7-scatterplots-sample-covariance-and-sample-correlation.html"><i class="fa fa-check"></i><b>3.7</b> Scatterplots, Sample Covariance and Sample Correlation</a></li>
<li class="chapter" data-level="3.8" data-path="3.8-exercises-3.html"><a href="3.8-exercises-3.html"><i class="fa fa-check"></i><b>3.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-lrwor.html"><a href="4-lrwor.html"><i class="fa fa-check"></i><b>4</b> Linear Regression with One Regressor</a>
<ul>
<li class="chapter" data-level="4.1" data-path="4.1-simple-linear-regression.html"><a href="4.1-simple-linear-regression.html"><i class="fa fa-check"></i><b>4.1</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="4.2" data-path="4.2-estimating-the-coefficients-of-the-linear-regression-model.html"><a href="4.2-estimating-the-coefficients-of-the-linear-regression-model.html"><i class="fa fa-check"></i><b>4.2</b> Estimating the Coefficients of the Linear Regression Model</a>
<ul>
<li class="chapter" data-level="" data-path="4.2-estimating-the-coefficients-of-the-linear-regression-model.html"><a href="4.2-estimating-the-coefficients-of-the-linear-regression-model.html#the-ordinary-least-squares-estimator"><i class="fa fa-check"></i>The Ordinary Least Squares Estimator</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="4.3-measures-of-fit.html"><a href="4.3-measures-of-fit.html"><i class="fa fa-check"></i><b>4.3</b> Measures of Fit</a>
<ul>
<li class="chapter" data-level="" data-path="4.3-measures-of-fit.html"><a href="4.3-measures-of-fit.html#the-coefficient-of-determination"><i class="fa fa-check"></i>The Coefficient of Determination</a></li>
<li class="chapter" data-level="" data-path="4.3-measures-of-fit.html"><a href="4.3-measures-of-fit.html#the-standard-error-of-the-regression"><i class="fa fa-check"></i>The Standard Error of the Regression</a></li>
<li class="chapter" data-level="" data-path="4.3-measures-of-fit.html"><a href="4.3-measures-of-fit.html#application-to-the-test-score-data"><i class="fa fa-check"></i>Application to the Test Score Data</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="4.4-tlsa.html"><a href="4.4-tlsa.html"><i class="fa fa-check"></i><b>4.4</b> The Least Squares Assumptions</a>
<ul>
<li class="chapter" data-level="" data-path="4.4-tlsa.html"><a href="4.4-tlsa.html#assumption-1-the-error-term-has-conditional-mean-of-zero"><i class="fa fa-check"></i>Assumption 1: The Error Term has Conditional Mean of Zero</a></li>
<li class="chapter" data-level="" data-path="4.4-tlsa.html"><a href="4.4-tlsa.html#assumption-2-independently-and-identically-distributed-data"><i class="fa fa-check"></i>Assumption 2: Independently and Identically Distributed Data</a></li>
<li class="chapter" data-level="" data-path="4.4-tlsa.html"><a href="4.4-tlsa.html#assumption-3-large-outliers-are-unlikely"><i class="fa fa-check"></i>Assumption 3: Large Outliers are Unlikely</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="4.5-tsdotoe.html"><a href="4.5-tsdotoe.html"><i class="fa fa-check"></i><b>4.5</b> The Sampling Distribution of the OLS Estimator</a>
<ul>
<li class="chapter" data-level="" data-path="4.5-tsdotoe.html"><a href="4.5-tsdotoe.html#simulation-study-1"><i class="fa fa-check"></i>Simulation Study 1</a></li>
<li class="chapter" data-level="" data-path="4.5-tsdotoe.html"><a href="4.5-tsdotoe.html#simulation-study-2"><i class="fa fa-check"></i>Simulation Study 2</a></li>
<li class="chapter" data-level="" data-path="4.5-tsdotoe.html"><a href="4.5-tsdotoe.html#simulation-study-3"><i class="fa fa-check"></i>Simulation Study 3</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="4.6-exercises-4.html"><a href="4.6-exercises-4.html"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-htaciitslrm.html"><a href="5-htaciitslrm.html"><i class="fa fa-check"></i><b>5</b> Hypothesis Tests and Confidence Intervals in SLR Model</a>
<ul>
<li class="chapter" data-level="5.1" data-path="5.1-testing-two-sided-hypotheses-concerning-the-slope-coefficient.html"><a href="5.1-testing-two-sided-hypotheses-concerning-the-slope-coefficient.html"><i class="fa fa-check"></i><b>5.1</b> Testing Two-Sided Hypotheses concerning the Slope Coefficient</a></li>
<li class="chapter" data-level="5.2" data-path="5.2-cifrc.html"><a href="5.2-cifrc.html"><i class="fa fa-check"></i><b>5.2</b> Confidence Intervals for Regression Coefficients</a>
<ul>
<li class="chapter" data-level="" data-path="5.2-cifrc.html"><a href="5.2-cifrc.html#simulation-study-confidence-intervals"><i class="fa fa-check"></i>Simulation Study: Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="5.3-rwxiabv.html"><a href="5.3-rwxiabv.html"><i class="fa fa-check"></i><b>5.3</b> Regression when X is a Binary Variable</a></li>
<li class="chapter" data-level="5.4" data-path="5.4-hah.html"><a href="5.4-hah.html"><i class="fa fa-check"></i><b>5.4</b> Heteroskedasticity and Homoskedasticity</a>
<ul>
<li class="chapter" data-level="" data-path="5.4-hah.html"><a href="5.4-hah.html#a-real-world-example-for-heteroskedasticity"><i class="fa fa-check"></i>A Real-World Example for Heteroskedasticity</a></li>
<li class="chapter" data-level="" data-path="5.4-hah.html"><a href="5.4-hah.html#should-we-care-about-heteroskedasticity"><i class="fa fa-check"></i>Should We Care About Heteroskedasticity?</a></li>
<li class="chapter" data-level="" data-path="5.4-hah.html"><a href="5.4-hah.html#computation-of-heteroskedasticity-robust-standard-errors"><i class="fa fa-check"></i>Computation of Heteroskedasticity-Robust Standard Errors</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="5.5-the-gauss-markov-theorem.html"><a href="5.5-the-gauss-markov-theorem.html"><i class="fa fa-check"></i><b>5.5</b> The Gauss-Markov Theorem</a>
<ul>
<li class="chapter" data-level="" data-path="5.5-the-gauss-markov-theorem.html"><a href="5.5-the-gauss-markov-theorem.html#simulation-study-blue-estimator"><i class="fa fa-check"></i>Simulation Study: BLUE Estimator</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="5.6-using-the-t-statistic-in-regression-when-the-sample-size-is-small.html"><a href="5.6-using-the-t-statistic-in-regression-when-the-sample-size-is-small.html"><i class="fa fa-check"></i><b>5.6</b> Using the t-Statistic in Regression when the Sample Size Is Small</a></li>
<li class="chapter" data-level="5.7" data-path="5.7-exercises-5.html"><a href="5.7-exercises-5.html"><i class="fa fa-check"></i><b>5.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-rmwmr.html"><a href="6-rmwmr.html"><i class="fa fa-check"></i><b>6</b> Regression Models with Multiple Regressors</a>
<ul>
<li class="chapter" data-level="6.1" data-path="6.1-omitted-variable-bias.html"><a href="6.1-omitted-variable-bias.html"><i class="fa fa-check"></i><b>6.1</b> Omitted Variable Bias</a></li>
<li class="chapter" data-level="6.2" data-path="6.2-tmrm.html"><a href="6.2-tmrm.html"><i class="fa fa-check"></i><b>6.2</b> The Multiple Regression Model</a></li>
<li class="chapter" data-level="6.3" data-path="6.3-mofimr.html"><a href="6.3-mofimr.html"><i class="fa fa-check"></i><b>6.3</b> Measures of Fit in Multiple Regression</a></li>
<li class="chapter" data-level="6.4" data-path="6.4-ols-assumptions-in-multiple-regression.html"><a href="6.4-ols-assumptions-in-multiple-regression.html"><i class="fa fa-check"></i><b>6.4</b> OLS Assumptions in Multiple Regression</a>
<ul>
<li class="chapter" data-level="" data-path="6.4-ols-assumptions-in-multiple-regression.html"><a href="6.4-ols-assumptions-in-multiple-regression.html#multicollinearity"><i class="fa fa-check"></i>Multicollinearity</a></li>
<li class="chapter" data-level="" data-path="6.4-ols-assumptions-in-multiple-regression.html"><a href="6.4-ols-assumptions-in-multiple-regression.html#simulation-study-imperfect-multicollinearity"><i class="fa fa-check"></i>Simulation Study: Imperfect Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="6.5-the-distribution-of-the-ols-estimators-in-multiple-regression.html"><a href="6.5-the-distribution-of-the-ols-estimators-in-multiple-regression.html"><i class="fa fa-check"></i><b>6.5</b> The Distribution of the OLS Estimators in Multiple Regression</a></li>
<li class="chapter" data-level="6.6" data-path="6.6-exercises-6.html"><a href="6.6-exercises-6.html"><i class="fa fa-check"></i><b>6.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-htaciimr.html"><a href="7-htaciimr.html"><i class="fa fa-check"></i><b>7</b> Hypothesis Tests and Confidence Intervals in MR Models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="7.1-hypothesis-tests-and-confidence-intervals-for-a-single-coefficient.html"><a href="7.1-hypothesis-tests-and-confidence-intervals-for-a-single-coefficient.html"><i class="fa fa-check"></i><b>7.1</b> Hypothesis Tests and Confidence Intervals for a Single Coefficient</a></li>
<li class="chapter" data-level="7.2" data-path="7.2-an-application-to-test-scores-and-the-student-teacher-ratio.html"><a href="7.2-an-application-to-test-scores-and-the-student-teacher-ratio.html"><i class="fa fa-check"></i><b>7.2</b> An Application to Test Scores and the Student-Teacher Ratio</a>
<ul>
<li class="chapter" data-level="" data-path="7.2-an-application-to-test-scores-and-the-student-teacher-ratio.html"><a href="7.2-an-application-to-test-scores-and-the-student-teacher-ratio.html#another-augmentation-of-the-model"><i class="fa fa-check"></i>Another Augmentation of the Model</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="7.3-joint-hypothesis-testing-using-the-f-statistic.html"><a href="7.3-joint-hypothesis-testing-using-the-f-statistic.html"><i class="fa fa-check"></i><b>7.3</b> Joint Hypothesis Testing using the F-Statistic</a></li>
<li class="chapter" data-level="7.4" data-path="7.4-confidence-sets-for-multiple-coefficients.html"><a href="7.4-confidence-sets-for-multiple-coefficients.html"><i class="fa fa-check"></i><b>7.4</b> Confidence Sets for Multiple Coefficients</a></li>
<li class="chapter" data-level="7.5" data-path="7.5-model-specification-for-multiple-regression.html"><a href="7.5-model-specification-for-multiple-regression.html"><i class="fa fa-check"></i><b>7.5</b> Model Specification for Multiple Regression</a>
<ul>
<li class="chapter" data-level="" data-path="7.5-model-specification-for-multiple-regression.html"><a href="7.5-model-specification-for-multiple-regression.html#model-specification-in-theory-and-in-practice"><i class="fa fa-check"></i>Model Specification in Theory and in Practice</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="7.6-analysis-of-the-test-score-data-set.html"><a href="7.6-analysis-of-the-test-score-data-set.html"><i class="fa fa-check"></i><b>7.6</b> Analysis of the Test Score Data Set</a></li>
<li class="chapter" data-level="7.7" data-path="7.7-exercises-7.html"><a href="7.7-exercises-7.html"><i class="fa fa-check"></i><b>7.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="8-nrf.html"><a href="8-nrf.html"><i class="fa fa-check"></i><b>8</b> Nonlinear Regression Functions</a>
<ul>
<li class="chapter" data-level="8.1" data-path="8.1-a-general-strategy-for-modelling-nonlinear-regression-functions.html"><a href="8.1-a-general-strategy-for-modelling-nonlinear-regression-functions.html"><i class="fa fa-check"></i><b>8.1</b> A General Strategy for Modelling Nonlinear Regression Functions</a></li>
<li class="chapter" data-level="8.2" data-path="8.2-nfoasiv.html"><a href="8.2-nfoasiv.html"><i class="fa fa-check"></i><b>8.2</b> Nonlinear Functions of a Single Independent Variable</a>
<ul>
<li class="chapter" data-level="" data-path="8.2-nfoasiv.html"><a href="8.2-nfoasiv.html#polynomials"><i class="fa fa-check"></i>Polynomials</a></li>
<li class="chapter" data-level="" data-path="8.2-nfoasiv.html"><a href="8.2-nfoasiv.html#logarithms"><i class="fa fa-check"></i>Logarithms</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="8.3-interactions-between-independent-variables.html"><a href="8.3-interactions-between-independent-variables.html"><i class="fa fa-check"></i><b>8.3</b> Interactions between Independent Variables</a></li>
<li class="chapter" data-level="8.4" data-path="8.4-nonlinear-effects-on-test-scores-of-the-student-teacher-ratio.html"><a href="8.4-nonlinear-effects-on-test-scores-of-the-student-teacher-ratio.html"><i class="fa fa-check"></i><b>8.4</b> Nonlinear Effects on Test Scores of the Student-Teacher Ratio</a></li>
<li class="chapter" data-level="8.5" data-path="8.5-exercises-8.html"><a href="8.5-exercises-8.html"><i class="fa fa-check"></i><b>8.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="9-asbomr.html"><a href="9-asbomr.html"><i class="fa fa-check"></i><b>9</b> Assessing Studies Based on Multiple Regression</a>
<ul>
<li class="chapter" data-level="9.1" data-path="9.1-internal-and-external-validity.html"><a href="9.1-internal-and-external-validity.html"><i class="fa fa-check"></i><b>9.1</b> Internal and External Validity</a></li>
<li class="chapter" data-level="9.2" data-path="9.2-ttivomra.html"><a href="9.2-ttivomra.html"><i class="fa fa-check"></i><b>9.2</b> Threats to Internal Validity of Multiple Regression Analysis</a></li>
<li class="chapter" data-level="9.3" data-path="9.3-internal-and-external-validity-when-the-regression-is-used-for-forecasting.html"><a href="9.3-internal-and-external-validity-when-the-regression-is-used-for-forecasting.html"><i class="fa fa-check"></i><b>9.3</b> Internal and External Validity when the Regression is used for Forecasting</a></li>
<li class="chapter" data-level="9.4" data-path="9.4-etsacs.html"><a href="9.4-etsacs.html"><i class="fa fa-check"></i><b>9.4</b> Example: Test Scores and Class Size</a></li>
<li class="chapter" data-level="9.5" data-path="9.5-exercises-9.html"><a href="9.5-exercises-9.html"><i class="fa fa-check"></i><b>9.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="10-rwpd.html"><a href="10-rwpd.html"><i class="fa fa-check"></i><b>10</b> Regression with Panel Data</a>
<ul>
<li class="chapter" data-level="10.1" data-path="10.1-panel-data.html"><a href="10.1-panel-data.html"><i class="fa fa-check"></i><b>10.1</b> Panel Data</a></li>
<li class="chapter" data-level="10.2" data-path="10.2-PDWTTP.html"><a href="10.2-PDWTTP.html"><i class="fa fa-check"></i><b>10.2</b> Panel Data with Two Time Periods: “Before and After” Comparisons</a></li>
<li class="chapter" data-level="10.3" data-path="10.3-fixed-effects-regression.html"><a href="10.3-fixed-effects-regression.html"><i class="fa fa-check"></i><b>10.3</b> Fixed Effects Regression</a>
<ul>
<li class="chapter" data-level="" data-path="10.3-fixed-effects-regression.html"><a href="10.3-fixed-effects-regression.html#estimation-and-inference"><i class="fa fa-check"></i>Estimation and Inference</a></li>
<li class="chapter" data-level="" data-path="10.3-fixed-effects-regression.html"><a href="10.3-fixed-effects-regression.html#application-to-traffic-deaths"><i class="fa fa-check"></i>Application to Traffic Deaths</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="10.4-regression-with-time-fixed-effects.html"><a href="10.4-regression-with-time-fixed-effects.html"><i class="fa fa-check"></i><b>10.4</b> Regression with Time Fixed Effects</a></li>
<li class="chapter" data-level="10.5" data-path="10.5-tferaaseffer.html"><a href="10.5-tferaaseffer.html"><i class="fa fa-check"></i><b>10.5</b> The Fixed Effects Regression Assumptions and Standard Errors for Fixed Effects Regression</a></li>
<li class="chapter" data-level="10.6" data-path="10.6-drunk-driving-laws-and-traffic-deaths.html"><a href="10.6-drunk-driving-laws-and-traffic-deaths.html"><i class="fa fa-check"></i><b>10.6</b> Drunk Driving Laws and Traffic Deaths</a></li>
<li class="chapter" data-level="10.7" data-path="10.7-exercises-10.html"><a href="10.7-exercises-10.html"><i class="fa fa-check"></i><b>10.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="11-rwabdv.html"><a href="11-rwabdv.html"><i class="fa fa-check"></i><b>11</b> Regression with a Binary Dependent Variable</a>
<ul>
<li class="chapter" data-level="11.1" data-path="11.1-binary-dependent-variables-and-the-linear-probability-model.html"><a href="11.1-binary-dependent-variables-and-the-linear-probability-model.html"><i class="fa fa-check"></i><b>11.1</b> Binary Dependent Variables and the Linear Probability Model</a></li>
<li class="chapter" data-level="11.2" data-path="11.2-palr.html"><a href="11.2-palr.html"><i class="fa fa-check"></i><b>11.2</b> Probit and Logit Regression</a>
<ul>
<li class="chapter" data-level="" data-path="11.2-palr.html"><a href="11.2-palr.html#probit-regression"><i class="fa fa-check"></i>Probit Regression</a></li>
<li class="chapter" data-level="" data-path="11.2-palr.html"><a href="11.2-palr.html#logit-regression"><i class="fa fa-check"></i>Logit Regression</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="11.3-estimation-and-inference-in-the-logit-and-probit-models.html"><a href="11.3-estimation-and-inference-in-the-logit-and-probit-models.html"><i class="fa fa-check"></i><b>11.3</b> Estimation and Inference in the Logit and Probit Models</a></li>
<li class="chapter" data-level="11.4" data-path="11.4-application-to-the-boston-hmda-data.html"><a href="11.4-application-to-the-boston-hmda-data.html"><i class="fa fa-check"></i><b>11.4</b> Application to the Boston HMDA Data</a></li>
<li class="chapter" data-level="11.5" data-path="11.5-exercises-11.html"><a href="11.5-exercises-11.html"><i class="fa fa-check"></i><b>11.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="12-ivr.html"><a href="12-ivr.html"><i class="fa fa-check"></i><b>12</b> Instrumental Variables Regression</a>
<ul>
<li class="chapter" data-level="12.1" data-path="12.1-TIVEWASRAASI.html"><a href="12.1-TIVEWASRAASI.html"><i class="fa fa-check"></i><b>12.1</b> The IV Estimator with a Single Regressor and a Single Instrument</a></li>
<li class="chapter" data-level="12.2" data-path="12.2-TGIVRM.html"><a href="12.2-TGIVRM.html"><i class="fa fa-check"></i><b>12.2</b> The General IV Regression Model</a></li>
<li class="chapter" data-level="12.3" data-path="12.3-civ.html"><a href="12.3-civ.html"><i class="fa fa-check"></i><b>12.3</b> Checking Instrument Validity</a></li>
<li class="chapter" data-level="12.4" data-path="12.4-attdfc.html"><a href="12.4-attdfc.html"><i class="fa fa-check"></i><b>12.4</b> Application to the Demand for Cigarettes</a></li>
<li class="chapter" data-level="12.5" data-path="12.5-where-do-valid-instruments-come-from.html"><a href="12.5-where-do-valid-instruments-come-from.html"><i class="fa fa-check"></i><b>12.5</b> Where Do Valid Instruments Come From?</a></li>
<li class="chapter" data-level="12.6" data-path="12.6-exercises-12.html"><a href="12.6-exercises-12.html"><i class="fa fa-check"></i><b>12.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="13-eaqe.html"><a href="13-eaqe.html"><i class="fa fa-check"></i><b>13</b> Experiments and Quasi-Experiments</a>
<ul>
<li class="chapter" data-level="13.1" data-path="13.1-poceaie.html"><a href="13.1-poceaie.html"><i class="fa fa-check"></i><b>13.1</b> Potential Outcomes, Causal Effects and Idealized Experiments</a></li>
<li class="chapter" data-level="13.2" data-path="13.2-threats-to-validity-of-experiments.html"><a href="13.2-threats-to-validity-of-experiments.html"><i class="fa fa-check"></i><b>13.2</b> Threats to Validity of Experiments</a></li>
<li class="chapter" data-level="13.3" data-path="13.3-experimental-estimates-of-the-effect-of-class-size-reductions.html"><a href="13.3-experimental-estimates-of-the-effect-of-class-size-reductions.html"><i class="fa fa-check"></i><b>13.3</b> Experimental Estimates of the Effect of Class Size Reductions</a>
<ul>
<li class="chapter" data-level="" data-path="13.3-experimental-estimates-of-the-effect-of-class-size-reductions.html"><a href="13.3-experimental-estimates-of-the-effect-of-class-size-reductions.html#experimental-design-and-the-data-set"><i class="fa fa-check"></i>Experimental Design and the Data Set</a></li>
<li class="chapter" data-level="" data-path="13.3-experimental-estimates-of-the-effect-of-class-size-reductions.html"><a href="13.3-experimental-estimates-of-the-effect-of-class-size-reductions.html#analysis-of-the-star-data"><i class="fa fa-check"></i>Analysis of the STAR Data</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="13.4-qe.html"><a href="13.4-qe.html"><i class="fa fa-check"></i><b>13.4</b> Quasi Experiments</a>
<ul>
<li class="chapter" data-level="" data-path="13.4-qe.html"><a href="13.4-qe.html#the-differences-in-differences-estimator"><i class="fa fa-check"></i>The Differences-in-Differences Estimator</a></li>
<li class="chapter" data-level="" data-path="13.4-qe.html"><a href="13.4-qe.html#regression-discontinuity-estimators"><i class="fa fa-check"></i>Regression Discontinuity Estimators</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="13.5-exercises-13.html"><a href="13.5-exercises-13.html"><i class="fa fa-check"></i><b>13.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="14-ittsraf.html"><a href="14-ittsraf.html"><i class="fa fa-check"></i><b>14</b> Introduction to Time Series Regression and Forecasting</a>
<ul>
<li class="chapter" data-level="14.1" data-path="14.1-using-regression-models-for-forecasting.html"><a href="14.1-using-regression-models-for-forecasting.html"><i class="fa fa-check"></i><b>14.1</b> Using Regression Models for Forecasting</a></li>
<li class="chapter" data-level="14.2" data-path="14.2-tsdasc.html"><a href="14.2-tsdasc.html"><i class="fa fa-check"></i><b>14.2</b> Time Series Data and Serial Correlation</a>
<ul>
<li class="chapter" data-level="" data-path="14.2-tsdasc.html"><a href="14.2-tsdasc.html#notation-lags-differences-logarithms-and-growth-rates"><i class="fa fa-check"></i>Notation, Lags, Differences, Logarithms and Growth Rates</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="14.3-autoregressions.html"><a href="14.3-autoregressions.html"><i class="fa fa-check"></i><b>14.3</b> Autoregressions</a>
<ul>
<li class="chapter" data-level="" data-path="14.3-autoregressions.html"><a href="14.3-autoregressions.html#autoregressive-models-of-order-p"><i class="fa fa-check"></i>Autoregressive Models of Order <span class="math inline">\(p\)</span></a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="14.4-cybtmpi.html"><a href="14.4-cybtmpi.html"><i class="fa fa-check"></i><b>14.4</b> Can You Beat the Market? (Part I)</a></li>
<li class="chapter" data-level="14.5" data-path="14.5-apatadlm.html"><a href="14.5-apatadlm.html"><i class="fa fa-check"></i><b>14.5</b> Additional Predictors and The ADL Model</a>
<ul>
<li class="chapter" data-level="" data-path="14.5-apatadlm.html"><a href="14.5-apatadlm.html#forecast-uncertainty-and-forecast-intervals"><i class="fa fa-check"></i>Forecast Uncertainty and Forecast Intervals</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="14.6-llsuic.html"><a href="14.6-llsuic.html"><i class="fa fa-check"></i><b>14.6</b> Lag Length Selection using Information Criteria</a></li>
<li class="chapter" data-level="14.7" data-path="14.7-nit.html"><a href="14.7-nit.html"><i class="fa fa-check"></i><b>14.7</b> Nonstationarity I: Trends</a></li>
<li class="chapter" data-level="14.8" data-path="14.8-niib.html"><a href="14.8-niib.html"><i class="fa fa-check"></i><b>14.8</b> Nonstationarity II: Breaks</a></li>
<li class="chapter" data-level="14.9" data-path="14.9-can-you-beat-the-market-part-ii.html"><a href="14.9-can-you-beat-the-market-part-ii.html"><i class="fa fa-check"></i><b>14.9</b> Can You Beat the Market? (Part II)</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="15-eodce.html"><a href="15-eodce.html"><i class="fa fa-check"></i><b>15</b> Estimation of Dynamic Causal Effects</a>
<ul>
<li class="chapter" data-level="15.1" data-path="15.1-the-orange-juice-data.html"><a href="15.1-the-orange-juice-data.html"><i class="fa fa-check"></i><b>15.1</b> The Orange Juice Data</a></li>
<li class="chapter" data-level="15.2" data-path="15.2-dynamic-causal-effects.html"><a href="15.2-dynamic-causal-effects.html"><i class="fa fa-check"></i><b>15.2</b> Dynamic Causal Effects</a></li>
<li class="chapter" data-level="15.3" data-path="15.3-dynamic-multipliers-and-cumulative-dynamic-multipliers.html"><a href="15.3-dynamic-multipliers-and-cumulative-dynamic-multipliers.html"><i class="fa fa-check"></i><b>15.3</b> Dynamic Multipliers and Cumulative Dynamic Multipliers</a></li>
<li class="chapter" data-level="15.4" data-path="15.4-hac-standard-errors.html"><a href="15.4-hac-standard-errors.html"><i class="fa fa-check"></i><b>15.4</b> HAC Standard Errors</a></li>
<li class="chapter" data-level="15.5" data-path="15.5-estimation-of-dynamic-causal-effects-with-strictly-exogeneous-regressors.html"><a href="15.5-estimation-of-dynamic-causal-effects-with-strictly-exogeneous-regressors.html"><i class="fa fa-check"></i><b>15.5</b> Estimation of Dynamic Causal Effects with Strictly Exogeneous Regressors</a></li>
<li class="chapter" data-level="15.6" data-path="15.6-orange-juice-prices-and-cold-weather.html"><a href="15.6-orange-juice-prices-and-cold-weather.html"><i class="fa fa-check"></i><b>15.6</b> Orange Juice Prices and Cold Weather</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="16-atitsr.html"><a href="16-atitsr.html"><i class="fa fa-check"></i><b>16</b> Additional Topics in Time Series Regression</a>
<ul>
<li class="chapter" data-level="16.1" data-path="16.1-vector-autoregressions.html"><a href="16.1-vector-autoregressions.html"><i class="fa fa-check"></i><b>16.1</b> Vector Autoregressions</a></li>
<li class="chapter" data-level="16.2" data-path="16.2-ooiatdfglsurt.html"><a href="16.2-ooiatdfglsurt.html"><i class="fa fa-check"></i><b>16.2</b> Orders of Integration and the DF-GLS Unit Root Test</a></li>
<li class="chapter" data-level="16.3" data-path="16.3-cointegration.html"><a href="16.3-cointegration.html"><i class="fa fa-check"></i><b>16.3</b> Cointegration</a></li>
<li class="chapter" data-level="16.4" data-path="16.4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><a href="16.4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><i class="fa fa-check"></i><b>16.4</b> Volatility Clustering and Autoregressive Conditional Heteroskedasticity</a>
<ul>
<li class="chapter" data-level="" data-path="16.4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><a href="16.4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html#arch-and-garch-models"><i class="fa fa-check"></i>ARCH and GARCH Models</a></li>
<li class="chapter" data-level="" data-path="16.4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><a href="16.4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html#application-to-stock-price-volatility"><i class="fa fa-check"></i>Application to Stock Price Volatility</a></li>
<li class="chapter" data-level="" data-path="16.4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><a href="16.4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html#summary-8"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Econometrics with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div class = rmdreview>
This book is in <b>Open Review</b>. We want your feedback to make the book better for you and other students. You may annotate some text by <span style="background-color: #3297FD; color: white">selecting it with the cursor</span> and then click "Annotate" in the pop-up menu. You can also see the annotations of others: click the arrow in the upper right hand corner of the page <i class="fa fa-arrow-circle-right  fa-rotate-315" aria-hidden="true"></i>
</div>
<div id="nfoasiv" class="section level2 hasAnchor" number="8.2">
<h2><span class="header-section-number">8.2</span> Nonlinear Functions of a Single Independent Variable<a href="8.2-nfoasiv.html#nfoasiv" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="polynomials" class="section level3 unnumbered hasAnchor">
<h3>Polynomials<a href="8.2-nfoasiv.html#polynomials" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The approach used to obtain a quadratic model can be generalized to polynomial models of arbitrary degree <span class="math inline">\(r\)</span>,
<span class="math display">\[Y_i = \beta_0 + \beta_1 X_i + \beta_2 X_i^2 + \cdots + \beta_r X_i^r + u_i.\]</span></p>
<p>A cubic model for instance can be estimated in the same way as the quadratic model; we just have to use a polynomial of degree <span class="math inline">\(r=3\)</span> in <tt>income</tt>. This is conveniently done using the function <tt>poly()</tt>.</p>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb179-1"><a href="8.2-nfoasiv.html#cb179-1" tabindex="-1"></a><span class="co"># estimate a cubic model</span></span>
<span id="cb179-2"><a href="8.2-nfoasiv.html#cb179-2" tabindex="-1"></a>cubic_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(score <span class="sc">~</span> <span class="fu">poly</span>(income, <span class="at">degree =</span> <span class="dv">3</span>, <span class="at">raw =</span> <span class="cn">TRUE</span>), <span class="at">data =</span> CASchools)</span></code></pre></div>
<p><tt>poly()</tt> generates orthogonal polynomials which are orthogonal to the constant by default. Here, we set <tt>raw = TRUE</tt> such that raw polynomials are evaluated, see <code>?poly</code>.</p>
<p>In practice the question will arise which polynomial order should be chosen. First, similarly as for <span class="math inline">\(r=2\)</span>, we can test the null hypothesis that the true relation is linear against the alternative hypothesis that the relationship is a polynomial of degree <span class="math inline">\(r\)</span>:</p>
<p><span class="math display">\[ H_0: \beta_2=0, \ \beta_3=0,\dots,\beta_r=0 \ \ \ \text{vs.} \ \ \ H_1: \text{at least one} \ \beta_j\neq0, \ j=2,\dots,r. \]</span></p>
<p>This is a joint null hypothesis with <span class="math inline">\(r-1\)</span> restrictions so it can be tested using the <span class="math inline">\(F\)</span>-test presented in Chapter <a href="7-htaciimr.html#htaciimr">7</a>. <tt>linearHypothesis()</tt> can be used to conduct such tests. For example, we may test the null of a linear model against the alternative of a polynomial of a maximal degree <span class="math inline">\(r=3\)</span> as follows.</p>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="8.2-nfoasiv.html#cb180-1" tabindex="-1"></a><span class="co"># test the hypothesis of a linear model against quadratic or polynomial</span></span>
<span id="cb180-2"><a href="8.2-nfoasiv.html#cb180-2" tabindex="-1"></a><span class="co"># alternatives</span></span>
<span id="cb180-3"><a href="8.2-nfoasiv.html#cb180-3" tabindex="-1"></a></span>
<span id="cb180-4"><a href="8.2-nfoasiv.html#cb180-4" tabindex="-1"></a><span class="co"># set up hypothesis matrix</span></span>
<span id="cb180-5"><a href="8.2-nfoasiv.html#cb180-5" tabindex="-1"></a>R <span class="ot">&lt;-</span> <span class="fu">rbind</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>),</span>
<span id="cb180-6"><a href="8.2-nfoasiv.html#cb180-6" tabindex="-1"></a>            <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>))</span>
<span id="cb180-7"><a href="8.2-nfoasiv.html#cb180-7" tabindex="-1"></a></span>
<span id="cb180-8"><a href="8.2-nfoasiv.html#cb180-8" tabindex="-1"></a><span class="co"># do the test</span></span>
<span id="cb180-9"><a href="8.2-nfoasiv.html#cb180-9" tabindex="-1"></a><span class="fu">linearHypothesis</span>(cubic_model,</span>
<span id="cb180-10"><a href="8.2-nfoasiv.html#cb180-10" tabindex="-1"></a>                 <span class="at">hypothesis.matrix =</span> R,</span>
<span id="cb180-11"><a href="8.2-nfoasiv.html#cb180-11" tabindex="-1"></a>                 <span class="at">white.adj =</span> <span class="st">&quot;hc1&quot;</span>)</span>
<span id="cb180-12"><a href="8.2-nfoasiv.html#cb180-12" tabindex="-1"></a><span class="co">#&gt; Linear hypothesis test</span></span>
<span id="cb180-13"><a href="8.2-nfoasiv.html#cb180-13" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb180-14"><a href="8.2-nfoasiv.html#cb180-14" tabindex="-1"></a><span class="co">#&gt; Hypothesis:</span></span>
<span id="cb180-15"><a href="8.2-nfoasiv.html#cb180-15" tabindex="-1"></a><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)2 = 0</span></span>
<span id="cb180-16"><a href="8.2-nfoasiv.html#cb180-16" tabindex="-1"></a><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)3 = 0</span></span>
<span id="cb180-17"><a href="8.2-nfoasiv.html#cb180-17" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb180-18"><a href="8.2-nfoasiv.html#cb180-18" tabindex="-1"></a><span class="co">#&gt; Model 1: restricted model</span></span>
<span id="cb180-19"><a href="8.2-nfoasiv.html#cb180-19" tabindex="-1"></a><span class="co">#&gt; Model 2: score ~ poly(income, degree = 3, raw = TRUE)</span></span>
<span id="cb180-20"><a href="8.2-nfoasiv.html#cb180-20" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb180-21"><a href="8.2-nfoasiv.html#cb180-21" tabindex="-1"></a><span class="co">#&gt; Note: Coefficient covariance matrix supplied.</span></span>
<span id="cb180-22"><a href="8.2-nfoasiv.html#cb180-22" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb180-23"><a href="8.2-nfoasiv.html#cb180-23" tabindex="-1"></a><span class="co">#&gt;   Res.Df Df      F    Pr(&gt;F)    </span></span>
<span id="cb180-24"><a href="8.2-nfoasiv.html#cb180-24" tabindex="-1"></a><span class="co">#&gt; 1    418                        </span></span>
<span id="cb180-25"><a href="8.2-nfoasiv.html#cb180-25" tabindex="-1"></a><span class="co">#&gt; 2    416  2 37.691 9.043e-16 ***</span></span>
<span id="cb180-26"><a href="8.2-nfoasiv.html#cb180-26" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb180-27"><a href="8.2-nfoasiv.html#cb180-27" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span></code></pre></div>
<p>We provide a hypothesis matrix as the argument <tt>hypothesis.matrix</tt>. This is useful when the coefficients have long names, as is the case here due to using <tt>poly()</tt>, or when the restrictions include multiple coefficients. How the hypothesis matrix <span class="math inline">\(\mathbf{R}\)</span> is interpreted by <tt>linearHypothesis()</tt> is best seen using matrix algebra:</p>
<p>For the two linear constraints above, we have
<span class="math display">\[\begin{align*}
  \mathbf{R}\boldsymbol{\beta} =&amp; \mathbf{s} \\
  \\
  \begin{pmatrix}
    0 &amp; 0 &amp; 1 &amp; 0 \\
    0 &amp; 0 &amp; 0 &amp; 1
  \end{pmatrix}
  \begin{pmatrix}
    \beta_0 \\
    \beta_1 \\
    \beta_2 \\
    \beta_3 \\
  \end{pmatrix} =&amp;
  \begin{pmatrix}
   0 \\
   0
  \end{pmatrix} =&gt;
  \begin{pmatrix}
    \beta_2 \\
    \beta_3
  \end{pmatrix} =
  \begin{pmatrix}
    0 \\
    0
  \end{pmatrix}.
\end{align*}\]</span>
<tt>linearHypothesis()</tt> uses the zero vector for <span class="math inline">\(\mathbf{s}\)</span> by default, see <code>?linearHypothesis</code>.</p>
<p>The <span class="math inline">\(p\)</span>-value for the test is very small so that we reject the null hypothesis. However, this does not tell us <em>which</em> <span class="math inline">\(r\)</span> to choose. In practice, one approach to determine the degree of the polynomial is to use <em>sequential testing</em>:</p>
<ol style="list-style-type: decimal">
<li>Estimate a polynomial model for some maximum value <span class="math inline">\(r\)</span>.</li>
<li>Use a <span class="math inline">\(t\)</span>-test to test <span class="math inline">\(\beta_r = 0\)</span>. <em>Rejection</em> of the null means that <span class="math inline">\(X^r\)</span> belongs in the regression equation.</li>
<li><em>Acceptance</em> of the null in step 2 means that <span class="math inline">\(X^r\)</span> can be eliminated from the model. Continue by repeating step 1 with order <span class="math inline">\(r-1\)</span> and test whether <span class="math inline">\(\beta_{r-1}=0\)</span>. If the test rejects, use a polynomial model of order <span class="math inline">\(r-1\)</span>.</li>
<li>If the test from step 3 rejects, continue with the procedure until the coefficient on the highest power is statistically significant.</li>
</ol>
<p>There is no unambiguous guideline on how to choose <span class="math inline">\(r\)</span> in step one. However, as pointed out in <span class="citation">Stock and Watson (<a href="#ref-stock2015">2015</a>)</span>, economic data is often smooth such that it is appropriate to choose small orders like <span class="math inline">\(2\)</span>, <span class="math inline">\(3\)</span>, or <span class="math inline">\(4\)</span>.</p>
<p>We will demonstrate how to apply sequential testing by the example of the cubic model.</p>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb181-1"><a href="8.2-nfoasiv.html#cb181-1" tabindex="-1"></a><span class="fu">summary</span>(cubic_model)</span>
<span id="cb181-2"><a href="8.2-nfoasiv.html#cb181-2" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb181-3"><a href="8.2-nfoasiv.html#cb181-3" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb181-4"><a href="8.2-nfoasiv.html#cb181-4" tabindex="-1"></a><span class="co">#&gt; lm(formula = score ~ poly(income, degree = 3, raw = TRUE), data = CASchools)</span></span>
<span id="cb181-5"><a href="8.2-nfoasiv.html#cb181-5" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb181-6"><a href="8.2-nfoasiv.html#cb181-6" tabindex="-1"></a><span class="co">#&gt; Residuals:</span></span>
<span id="cb181-7"><a href="8.2-nfoasiv.html#cb181-7" tabindex="-1"></a><span class="co">#&gt;    Min     1Q Median     3Q    Max </span></span>
<span id="cb181-8"><a href="8.2-nfoasiv.html#cb181-8" tabindex="-1"></a><span class="co">#&gt; -44.28  -9.21   0.20   8.32  31.16 </span></span>
<span id="cb181-9"><a href="8.2-nfoasiv.html#cb181-9" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb181-10"><a href="8.2-nfoasiv.html#cb181-10" tabindex="-1"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb181-11"><a href="8.2-nfoasiv.html#cb181-11" tabindex="-1"></a><span class="co">#&gt;                                         Estimate Std. Error t value Pr(&gt;|t|)</span></span>
<span id="cb181-12"><a href="8.2-nfoasiv.html#cb181-12" tabindex="-1"></a><span class="co">#&gt; (Intercept)                            6.001e+02  5.830e+00 102.937  &lt; 2e-16</span></span>
<span id="cb181-13"><a href="8.2-nfoasiv.html#cb181-13" tabindex="-1"></a><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)1  5.019e+00  8.595e-01   5.839 1.06e-08</span></span>
<span id="cb181-14"><a href="8.2-nfoasiv.html#cb181-14" tabindex="-1"></a><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)2 -9.581e-02  3.736e-02  -2.564   0.0107</span></span>
<span id="cb181-15"><a href="8.2-nfoasiv.html#cb181-15" tabindex="-1"></a><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)3  6.855e-04  4.720e-04   1.452   0.1471</span></span>
<span id="cb181-16"><a href="8.2-nfoasiv.html#cb181-16" tabindex="-1"></a><span class="co">#&gt;                                          </span></span>
<span id="cb181-17"><a href="8.2-nfoasiv.html#cb181-17" tabindex="-1"></a><span class="co">#&gt; (Intercept)                           ***</span></span>
<span id="cb181-18"><a href="8.2-nfoasiv.html#cb181-18" tabindex="-1"></a><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)1 ***</span></span>
<span id="cb181-19"><a href="8.2-nfoasiv.html#cb181-19" tabindex="-1"></a><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)2 *  </span></span>
<span id="cb181-20"><a href="8.2-nfoasiv.html#cb181-20" tabindex="-1"></a><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)3    </span></span>
<span id="cb181-21"><a href="8.2-nfoasiv.html#cb181-21" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb181-22"><a href="8.2-nfoasiv.html#cb181-22" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb181-23"><a href="8.2-nfoasiv.html#cb181-23" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb181-24"><a href="8.2-nfoasiv.html#cb181-24" tabindex="-1"></a><span class="co">#&gt; Residual standard error: 12.71 on 416 degrees of freedom</span></span>
<span id="cb181-25"><a href="8.2-nfoasiv.html#cb181-25" tabindex="-1"></a><span class="co">#&gt; Multiple R-squared:  0.5584, Adjusted R-squared:  0.5552 </span></span>
<span id="cb181-26"><a href="8.2-nfoasiv.html#cb181-26" tabindex="-1"></a><span class="co">#&gt; F-statistic: 175.4 on 3 and 416 DF,  p-value: &lt; 2.2e-16</span></span></code></pre></div>
<p>The estimated cubic model stored in <tt>cubic_model</tt> is</p>
<p><span class="math display">\[ \widehat{TestScore}_i = \underset{(5.83)}{600.1} + \underset{(0.86)}{5.02} \times income -\underset{(0.037)}{0.096} \times income^2 - \underset{(0.00047)}{0.00069} \times income^3. \]</span></p>
<p>The <span class="math inline">\(t\)</span>-statistic on <span class="math inline">\(income^3\)</span> is <span class="math inline">\(1.45\)</span> so the null that the relationship is quadratic cannot be rejected, even at the <span class="math inline">\(10\%\)</span> level. This is contrary to the result presented in the book which reports robust standard errors throughout, so we will also use robust variance-covariance estimation to reproduce these results.</p>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb182-1"><a href="8.2-nfoasiv.html#cb182-1" tabindex="-1"></a><span class="co"># test the hypothesis using robust standard errors</span></span>
<span id="cb182-2"><a href="8.2-nfoasiv.html#cb182-2" tabindex="-1"></a><span class="fu">coeftest</span>(cubic_model, <span class="at">vcov. =</span> vcovHC, <span class="at">type =</span> <span class="st">&quot;HC1&quot;</span>)</span>
<span id="cb182-3"><a href="8.2-nfoasiv.html#cb182-3" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb182-4"><a href="8.2-nfoasiv.html#cb182-4" tabindex="-1"></a><span class="co">#&gt; t test of coefficients:</span></span>
<span id="cb182-5"><a href="8.2-nfoasiv.html#cb182-5" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb182-6"><a href="8.2-nfoasiv.html#cb182-6" tabindex="-1"></a><span class="co">#&gt;                                          Estimate  Std. Error  t value</span></span>
<span id="cb182-7"><a href="8.2-nfoasiv.html#cb182-7" tabindex="-1"></a><span class="co">#&gt; (Intercept)                            6.0008e+02  5.1021e+00 117.6150</span></span>
<span id="cb182-8"><a href="8.2-nfoasiv.html#cb182-8" tabindex="-1"></a><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)1  5.0187e+00  7.0735e-01   7.0950</span></span>
<span id="cb182-9"><a href="8.2-nfoasiv.html#cb182-9" tabindex="-1"></a><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)2 -9.5805e-02  2.8954e-02  -3.3089</span></span>
<span id="cb182-10"><a href="8.2-nfoasiv.html#cb182-10" tabindex="-1"></a><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)3  6.8549e-04  3.4706e-04   1.9751</span></span>
<span id="cb182-11"><a href="8.2-nfoasiv.html#cb182-11" tabindex="-1"></a><span class="co">#&gt;                                        Pr(&gt;|t|)    </span></span>
<span id="cb182-12"><a href="8.2-nfoasiv.html#cb182-12" tabindex="-1"></a><span class="co">#&gt; (Intercept)                           &lt; 2.2e-16 ***</span></span>
<span id="cb182-13"><a href="8.2-nfoasiv.html#cb182-13" tabindex="-1"></a><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)1 5.606e-12 ***</span></span>
<span id="cb182-14"><a href="8.2-nfoasiv.html#cb182-14" tabindex="-1"></a><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)2  0.001018 ** </span></span>
<span id="cb182-15"><a href="8.2-nfoasiv.html#cb182-15" tabindex="-1"></a><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)3  0.048918 *  </span></span>
<span id="cb182-16"><a href="8.2-nfoasiv.html#cb182-16" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb182-17"><a href="8.2-nfoasiv.html#cb182-17" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span></code></pre></div>
<p>The reported standard errors have changed. Furthermore, the coefficient for <code>income^3</code> is now significant at the <span class="math inline">\(5\%\)</span> level. This means we reject the hypothesis that the regression function is quadratic against the alternative that it is cubic. Furthermore, we can also test if the coefficients for <tt>income^2</tt> and <tt>income^3</tt> are jointly significant using a robust version of the <span class="math inline">\(F\)</span>-test.</p>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb183-1"><a href="8.2-nfoasiv.html#cb183-1" tabindex="-1"></a><span class="co"># perform robust F-test </span></span>
<span id="cb183-2"><a href="8.2-nfoasiv.html#cb183-2" tabindex="-1"></a><span class="fu">linearHypothesis</span>(cubic_model, </span>
<span id="cb183-3"><a href="8.2-nfoasiv.html#cb183-3" tabindex="-1"></a>                 <span class="at">hypothesis.matrix =</span> R,</span>
<span id="cb183-4"><a href="8.2-nfoasiv.html#cb183-4" tabindex="-1"></a>                 <span class="at">vcov. =</span> vcovHC, <span class="at">type =</span> <span class="st">&quot;HC1&quot;</span>)</span>
<span id="cb183-5"><a href="8.2-nfoasiv.html#cb183-5" tabindex="-1"></a><span class="co">#&gt; Linear hypothesis test</span></span>
<span id="cb183-6"><a href="8.2-nfoasiv.html#cb183-6" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb183-7"><a href="8.2-nfoasiv.html#cb183-7" tabindex="-1"></a><span class="co">#&gt; Hypothesis:</span></span>
<span id="cb183-8"><a href="8.2-nfoasiv.html#cb183-8" tabindex="-1"></a><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)2 = 0</span></span>
<span id="cb183-9"><a href="8.2-nfoasiv.html#cb183-9" tabindex="-1"></a><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)3 = 0</span></span>
<span id="cb183-10"><a href="8.2-nfoasiv.html#cb183-10" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb183-11"><a href="8.2-nfoasiv.html#cb183-11" tabindex="-1"></a><span class="co">#&gt; Model 1: restricted model</span></span>
<span id="cb183-12"><a href="8.2-nfoasiv.html#cb183-12" tabindex="-1"></a><span class="co">#&gt; Model 2: score ~ poly(income, degree = 3, raw = TRUE)</span></span>
<span id="cb183-13"><a href="8.2-nfoasiv.html#cb183-13" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb183-14"><a href="8.2-nfoasiv.html#cb183-14" tabindex="-1"></a><span class="co">#&gt; Note: Coefficient covariance matrix supplied.</span></span>
<span id="cb183-15"><a href="8.2-nfoasiv.html#cb183-15" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb183-16"><a href="8.2-nfoasiv.html#cb183-16" tabindex="-1"></a><span class="co">#&gt;   Res.Df Df      F    Pr(&gt;F)    </span></span>
<span id="cb183-17"><a href="8.2-nfoasiv.html#cb183-17" tabindex="-1"></a><span class="co">#&gt; 1    418                        </span></span>
<span id="cb183-18"><a href="8.2-nfoasiv.html#cb183-18" tabindex="-1"></a><span class="co">#&gt; 2    416  2 29.678 8.945e-13 ***</span></span>
<span id="cb183-19"><a href="8.2-nfoasiv.html#cb183-19" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb183-20"><a href="8.2-nfoasiv.html#cb183-20" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span></code></pre></div>
<p>With a <span class="math inline">\(p\)</span>-value of <span class="math inline">\(8.945e-13\)</span>, i.e., much less than <span class="math inline">\(0.05\)</span>, the null hypothesis of linearity is rejected in favor of the alternative that the relationship is quadratic or cubic.</p>
<div id="interpretation-of-coefficients-in-nonlinear-regression-models" class="section level4 unnumbered hasAnchor">
<h4>Interpretation of Coefficients in Nonlinear Regression Models<a href="8.2-nfoasiv.html#interpretation-of-coefficients-in-nonlinear-regression-models" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The coefficients in the polynomial regressions do not have a simple interpretation. Why? Think of a quadratic model: it is not helpful to think of the coefficient on <span class="math inline">\(X\)</span> as the expected change in <span class="math inline">\(Y\)</span> associated with a change in <span class="math inline">\(X\)</span> holding the other regressors constant because <span class="math inline">\(X^2\)</span> changes as <span class="math inline">\(X\)</span> varies. This is also the case for other deviations from linearity, for example in models where regressors and/or the dependent variable are log-transformed. A way to approach this is to calculate the estimated effect on <span class="math inline">\(Y\)</span> associated with a change in <span class="math inline">\(X\)</span> for one or more values of <span class="math inline">\(X\)</span>. This idea is summarized in Key Concept 8.1.</p>
<div id="KC8.1" class="keyconcept">
<h3 class="right">
Key Concept 8.1
</h3>
<h3 class="left">
The Expected Effect on <span class="math inline">\(Y\)</span> for a Change in <span class="math inline">\(X_1\)</span> in a Nonlinear Regression Model
</h3>
<p>Consider the nonlinear population regression model</p>
<p><span class="math display">\[ Y_i = f(X_{1i}, X_{2i}, \dots, X_{ki}) + u_i \ , \ i=1,\dots,n,\]</span></p>
<p>where <span class="math inline">\(f(X_{1i}, X_{2i}, \dots, X_{ki})\)</span> is the population regression function and <span class="math inline">\(u_i\)</span> is the error term.</p>
<p>Denote by <span class="math inline">\(\Delta Y\)</span> the expected change in <span class="math inline">\(Y\)</span> associated with <span class="math inline">\(\Delta X_1\)</span>, the change in <span class="math inline">\(X_1\)</span> while holding <span class="math inline">\(X_2, \cdots , X_k\)</span> constant. That is, the expected change in <span class="math inline">\(Y\)</span> is the difference</p>
<p><span class="math display">\[\Delta Y = f(X_1 + \Delta X_1, X_2, \cdots, X_k) - f(X_1, X_2, \cdots, X_k).\]</span></p>
<p>The estimator of this unknown population difference is the difference between the predicted values for these two cases. Let <span class="math inline">\(\hat{f}(X_1, X_2, \cdots, X_k)\)</span> be the predicted value of of <span class="math inline">\(Y\)</span> based on the estimator <span class="math inline">\(\hat{f}\)</span> of the population regression function. Then the predicted change in <span class="math inline">\(Y\)</span> is</p>
<span class="math display">\[\Delta \widehat{Y} = \hat{f}(X_1 + \Delta X_1, X_2, \cdots, X_k) - \hat{f}(X_1, X_2, \cdots, X_k).\]</span>
</p>
</div>
<p>For example, we may ask the following: what is the predicted change in test scores associated with a one unit change (i.e., <span class="math inline">\(\$1000\)</span>) in income, based on the estimated quadratic regression function</p>
<p><span class="math display">\[\widehat{TestScore} = 607.3 + 3.85 \times income - 0.0423 \times income^2\ ?\]</span></p>
<p>Because the regression function is quadratic, this effect depends on the <em>initial</em> district income. We therefore consider two cases:</p>
<ol style="list-style-type: decimal">
<li><p>An increase in district income form <span class="math inline">\(10\)</span> to <span class="math inline">\(11\)</span> (from <span class="math inline">\(\$10000\)</span> per capita to <span class="math inline">\(\$11000\)</span>).</p></li>
<li><p>An increase in district income from <span class="math inline">\(40\)</span> to <span class="math inline">\(41\)</span> (that is from <span class="math inline">\(\$40000\)</span> to <span class="math inline">\(\$41000\)</span>).</p></li>
</ol>
<p>In order to obtain the <span class="math inline">\(\Delta \widehat{Y}\)</span> associated with a change in income form <span class="math inline">\(10\)</span> to <span class="math inline">\(11\)</span>, we use the following formula:</p>
<p><span class="math display">\[\Delta \widehat{Y} = \left(\hat{\beta}_0 + \hat{\beta}_1 \times 11 + \hat{\beta}_2 \times 11^2\right) - \left(\hat{\beta}_0 + \hat{\beta}_1 \times 10 + \hat{\beta}_2 \times 10^2\right). \]</span>
To compute <span class="math inline">\(\widehat{Y}\)</span> using <tt>R</tt> we may use <tt>predict()</tt>.</p>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb184-1"><a href="8.2-nfoasiv.html#cb184-1" tabindex="-1"></a><span class="co"># compute and assign the quadratic model</span></span>
<span id="cb184-2"><a href="8.2-nfoasiv.html#cb184-2" tabindex="-1"></a>quadratic_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(score <span class="sc">~</span> income <span class="sc">+</span> <span class="fu">I</span>(income<span class="sc">^</span><span class="dv">2</span>), <span class="at">data =</span> CASchools)</span>
<span id="cb184-3"><a href="8.2-nfoasiv.html#cb184-3" tabindex="-1"></a></span>
<span id="cb184-4"><a href="8.2-nfoasiv.html#cb184-4" tabindex="-1"></a><span class="co"># set up data for prediction</span></span>
<span id="cb184-5"><a href="8.2-nfoasiv.html#cb184-5" tabindex="-1"></a>new_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">income =</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">11</span>))</span>
<span id="cb184-6"><a href="8.2-nfoasiv.html#cb184-6" tabindex="-1"></a></span>
<span id="cb184-7"><a href="8.2-nfoasiv.html#cb184-7" tabindex="-1"></a><span class="co"># do the prediction</span></span>
<span id="cb184-8"><a href="8.2-nfoasiv.html#cb184-8" tabindex="-1"></a>Y_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(quadratic_model, <span class="at">newdata =</span> new_data)</span>
<span id="cb184-9"><a href="8.2-nfoasiv.html#cb184-9" tabindex="-1"></a></span>
<span id="cb184-10"><a href="8.2-nfoasiv.html#cb184-10" tabindex="-1"></a><span class="co"># compute the difference</span></span>
<span id="cb184-11"><a href="8.2-nfoasiv.html#cb184-11" tabindex="-1"></a><span class="fu">diff</span>(Y_hat)</span>
<span id="cb184-12"><a href="8.2-nfoasiv.html#cb184-12" tabindex="-1"></a><span class="co">#&gt;        2 </span></span>
<span id="cb184-13"><a href="8.2-nfoasiv.html#cb184-13" tabindex="-1"></a><span class="co">#&gt; 2.962517</span></span></code></pre></div>
<p>Analogously we can compute the effect of a change in district income from <span class="math inline">\(40\)</span> to <span class="math inline">\(41\)</span>:</p>
<div class="sourceCode" id="cb185"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb185-1"><a href="8.2-nfoasiv.html#cb185-1" tabindex="-1"></a><span class="co"># set up data for prediction</span></span>
<span id="cb185-2"><a href="8.2-nfoasiv.html#cb185-2" tabindex="-1"></a>new_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">income =</span> <span class="fu">c</span>(<span class="dv">40</span>, <span class="dv">41</span>))</span>
<span id="cb185-3"><a href="8.2-nfoasiv.html#cb185-3" tabindex="-1"></a></span>
<span id="cb185-4"><a href="8.2-nfoasiv.html#cb185-4" tabindex="-1"></a><span class="co"># do the prediction</span></span>
<span id="cb185-5"><a href="8.2-nfoasiv.html#cb185-5" tabindex="-1"></a>Y_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(quadratic_model, <span class="at">newdata =</span> new_data)</span>
<span id="cb185-6"><a href="8.2-nfoasiv.html#cb185-6" tabindex="-1"></a></span>
<span id="cb185-7"><a href="8.2-nfoasiv.html#cb185-7" tabindex="-1"></a><span class="co"># compute the difference</span></span>
<span id="cb185-8"><a href="8.2-nfoasiv.html#cb185-8" tabindex="-1"></a><span class="fu">diff</span>(Y_hat)</span>
<span id="cb185-9"><a href="8.2-nfoasiv.html#cb185-9" tabindex="-1"></a><span class="co">#&gt;         2 </span></span>
<span id="cb185-10"><a href="8.2-nfoasiv.html#cb185-10" tabindex="-1"></a><span class="co">#&gt; 0.4240097</span></span></code></pre></div>
<p>So for the quadratic model, the expected change in <span class="math inline">\(TestScore\)</span> induced by an increase in <span class="math inline">\(income\)</span> from <span class="math inline">\(10\)</span> to <span class="math inline">\(11\)</span> is about <span class="math inline">\(2.96\)</span> points but an increase in <span class="math inline">\(income\)</span> from <span class="math inline">\(40\)</span> to <span class="math inline">\(41\)</span> increases the predicted score by only <span class="math inline">\(0.42\)</span>. Hence, the slope of the estimated quadratic regression function is <em>steeper</em> at low levels of income than at higher levels.</p>
</div>
</div>
<div id="logarithms" class="section level3 unnumbered hasAnchor">
<h3>Logarithms<a href="8.2-nfoasiv.html#logarithms" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Another way to specify a nonlinear regression function is to use the natural logarithm of <span class="math inline">\(Y\)</span> and/or <span class="math inline">\(X\)</span>.
Logarithms convert changes in variables into percentage changes. This is convenient as many relationships are naturally expressed in terms of percentages.</p>
<p>There are three different cases in which logarithms might be used.</p>
<ol style="list-style-type: decimal">
<li><p>Transform <span class="math inline">\(X\)</span> to its logarithm, but not <span class="math inline">\(Y\)</span>.</p></li>
<li><p>Analogously we can transform <span class="math inline">\(Y\)</span> to its logarithm but leave <span class="math inline">\(X\)</span> at level.</p></li>
<li><p>Both <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> are transformed to their logarithms.</p></li>
</ol>
<p>The interpretation of the regression coefficients is different in each case.</p>
<div id="case-i-x-is-in-logarithm-y-is-not." class="section level4 unnumbered hasAnchor">
<h4>Case I: <span class="math inline">\(X\)</span> is in Logarithm, <span class="math inline">\(Y\)</span> is not.<a href="8.2-nfoasiv.html#case-i-x-is-in-logarithm-y-is-not." class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The regression model then is <span class="math display">\[Y_i = \beta_0 + \beta_1 \times \ln(X_i) + u_i \text{, } i=1,...,n. \]</span> Similar as for polynomial regressions, we do not have to create a new variable before using <tt>lm()</tt>. We can simply adjust the
<tt>formula</tt> argument of <tt>lm()</tt> to tell <tt>R</tt> that the log-transformation of a variable should be used.</p>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb186-1"><a href="8.2-nfoasiv.html#cb186-1" tabindex="-1"></a><span class="co"># estimate a level-log model</span></span>
<span id="cb186-2"><a href="8.2-nfoasiv.html#cb186-2" tabindex="-1"></a>LinearLog_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(score <span class="sc">~</span> <span class="fu">log</span>(income), <span class="at">data =</span> CASchools)</span>
<span id="cb186-3"><a href="8.2-nfoasiv.html#cb186-3" tabindex="-1"></a></span>
<span id="cb186-4"><a href="8.2-nfoasiv.html#cb186-4" tabindex="-1"></a><span class="co"># compute robust summary</span></span>
<span id="cb186-5"><a href="8.2-nfoasiv.html#cb186-5" tabindex="-1"></a><span class="fu">coeftest</span>(LinearLog_model, </span>
<span id="cb186-6"><a href="8.2-nfoasiv.html#cb186-6" tabindex="-1"></a>         <span class="at">vcov =</span> vcovHC, <span class="at">type =</span> <span class="st">&quot;HC1&quot;</span>)</span>
<span id="cb186-7"><a href="8.2-nfoasiv.html#cb186-7" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb186-8"><a href="8.2-nfoasiv.html#cb186-8" tabindex="-1"></a><span class="co">#&gt; t test of coefficients:</span></span>
<span id="cb186-9"><a href="8.2-nfoasiv.html#cb186-9" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb186-10"><a href="8.2-nfoasiv.html#cb186-10" tabindex="-1"></a><span class="co">#&gt;             Estimate Std. Error t value  Pr(&gt;|t|)    </span></span>
<span id="cb186-11"><a href="8.2-nfoasiv.html#cb186-11" tabindex="-1"></a><span class="co">#&gt; (Intercept) 557.8323     3.8399 145.271 &lt; 2.2e-16 ***</span></span>
<span id="cb186-12"><a href="8.2-nfoasiv.html#cb186-12" tabindex="-1"></a><span class="co">#&gt; log(income)  36.4197     1.3969  26.071 &lt; 2.2e-16 ***</span></span>
<span id="cb186-13"><a href="8.2-nfoasiv.html#cb186-13" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb186-14"><a href="8.2-nfoasiv.html#cb186-14" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span></code></pre></div>
<p>Hence, the estimated regression function is</p>
<p><span class="math display">\[\widehat{TestScore} = 557.8 + 36.42 \times \ln(income).\]</span></p>
<p>Let us draw a plot of this function.</p>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb187-1"><a href="8.2-nfoasiv.html#cb187-1" tabindex="-1"></a><span class="co"># draw a scatterplot</span></span>
<span id="cb187-2"><a href="8.2-nfoasiv.html#cb187-2" tabindex="-1"></a><span class="fu">plot</span>(score <span class="sc">~</span> income, </span>
<span id="cb187-3"><a href="8.2-nfoasiv.html#cb187-3" tabindex="-1"></a>     <span class="at">col =</span> <span class="st">&quot;steelblue&quot;</span>,</span>
<span id="cb187-4"><a href="8.2-nfoasiv.html#cb187-4" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">20</span>,</span>
<span id="cb187-5"><a href="8.2-nfoasiv.html#cb187-5" tabindex="-1"></a>     <span class="at">data =</span> CASchools,</span>
<span id="cb187-6"><a href="8.2-nfoasiv.html#cb187-6" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">&quot;Score&quot;</span>,</span>
<span id="cb187-7"><a href="8.2-nfoasiv.html#cb187-7" tabindex="-1"></a>     <span class="at">xlab=</span><span class="st">&quot;Income&quot;</span>,</span>
<span id="cb187-8"><a href="8.2-nfoasiv.html#cb187-8" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;Linear-Log Regression Line&quot;</span>)</span>
<span id="cb187-9"><a href="8.2-nfoasiv.html#cb187-9" tabindex="-1"></a></span>
<span id="cb187-10"><a href="8.2-nfoasiv.html#cb187-10" tabindex="-1"></a><span class="co"># add the linear-log regression line</span></span>
<span id="cb187-11"><a href="8.2-nfoasiv.html#cb187-11" tabindex="-1"></a>order_id  <span class="ot">&lt;-</span> <span class="fu">order</span>(CASchools<span class="sc">$</span>income)</span>
<span id="cb187-12"><a href="8.2-nfoasiv.html#cb187-12" tabindex="-1"></a></span>
<span id="cb187-13"><a href="8.2-nfoasiv.html#cb187-13" tabindex="-1"></a><span class="fu">lines</span>(CASchools<span class="sc">$</span>income[order_id],</span>
<span id="cb187-14"><a href="8.2-nfoasiv.html#cb187-14" tabindex="-1"></a>      <span class="fu">fitted</span>(LinearLog_model)[order_id], </span>
<span id="cb187-15"><a href="8.2-nfoasiv.html#cb187-15" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, </span>
<span id="cb187-16"><a href="8.2-nfoasiv.html#cb187-16" tabindex="-1"></a>      <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb187-17"><a href="8.2-nfoasiv.html#cb187-17" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;bottomright&quot;</span>,<span class="at">legend =</span> <span class="st">&quot;Linear-log line&quot;</span>,<span class="at">lwd =</span> <span class="dv">2</span>,<span class="at">col =</span><span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="ITER_files/figure-html/unnamed-chunk-328-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>We can interpret <span class="math inline">\(\hat{\beta}_1\)</span> as follows: a <span class="math inline">\(1\%\)</span> increase in income is associated with an increase in test scores of <span class="math inline">\(0.01 \times 36.42 = 0.36\)</span> points. In order to get the estimated effect of a one unit change in income (that is, a change in the original units, thousands of dollars) on test scores, the method presented in Key Concept 8.1 can be used.</p>
<div class="sourceCode" id="cb188"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb188-1"><a href="8.2-nfoasiv.html#cb188-1" tabindex="-1"></a><span class="co"># set up new data</span></span>
<span id="cb188-2"><a href="8.2-nfoasiv.html#cb188-2" tabindex="-1"></a>new_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">income =</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">11</span>, <span class="dv">40</span>, <span class="dv">41</span>))</span>
<span id="cb188-3"><a href="8.2-nfoasiv.html#cb188-3" tabindex="-1"></a></span>
<span id="cb188-4"><a href="8.2-nfoasiv.html#cb188-4" tabindex="-1"></a><span class="co"># predict the outcomes </span></span>
<span id="cb188-5"><a href="8.2-nfoasiv.html#cb188-5" tabindex="-1"></a>Y_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(LinearLog_model, <span class="at">newdata =</span> new_data)</span>
<span id="cb188-6"><a href="8.2-nfoasiv.html#cb188-6" tabindex="-1"></a></span>
<span id="cb188-7"><a href="8.2-nfoasiv.html#cb188-7" tabindex="-1"></a><span class="co"># compute the expected difference</span></span>
<span id="cb188-8"><a href="8.2-nfoasiv.html#cb188-8" tabindex="-1"></a>Y_hat_matrix <span class="ot">&lt;-</span> <span class="fu">matrix</span>(Y_hat, <span class="at">nrow =</span> <span class="dv">2</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb188-9"><a href="8.2-nfoasiv.html#cb188-9" tabindex="-1"></a>Y_hat_matrix[, <span class="dv">2</span>] <span class="sc">-</span> Y_hat_matrix[, <span class="dv">1</span>]</span>
<span id="cb188-10"><a href="8.2-nfoasiv.html#cb188-10" tabindex="-1"></a><span class="co">#&gt; [1] 3.471166 0.899297</span></span></code></pre></div>
<p>By setting <tt>nrow = 2</tt> and <tt>byrow = TRUE</tt> in <tt>matrix()</tt>, we ensure that <tt>Y_hat_matrix</tt> is a <span class="math inline">\(2\times2\)</span> matrix filled row-wise with the entries of <tt>Y_hat</tt>.</p>
<p>The estimated model states that for an income increase from <span class="math inline">\(\$10000\)</span> to <span class="math inline">\(\$11000\)</span>, test scores increase by an expected amount of <span class="math inline">\(3.47\)</span> points. When income increases from <span class="math inline">\(\$40000\)</span> to <span class="math inline">\(\$41000\)</span>, the expected increase in test scores is only about <span class="math inline">\(0.90\)</span> points.</p>
</div>
<div id="case-ii-y-is-in-logarithm-x-is-not" class="section level4 unnumbered hasAnchor">
<h4>Case II: <span class="math inline">\(Y\)</span> is in Logarithm, <span class="math inline">\(X\)</span> is not<a href="8.2-nfoasiv.html#case-ii-y-is-in-logarithm-x-is-not" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>There are cases where it is useful to regress <span class="math inline">\(\ln(Y)\)</span>.</p>
<p>The corresponding regression model then is</p>
<p><span class="math display">\[ \ln(Y_i) = \beta_0 + \beta_1 \times X_i + u_i , \ \ i=1,...,n. \]</span></p>
<div class="sourceCode" id="cb189"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb189-1"><a href="8.2-nfoasiv.html#cb189-1" tabindex="-1"></a><span class="co"># estimate a log-linear model </span></span>
<span id="cb189-2"><a href="8.2-nfoasiv.html#cb189-2" tabindex="-1"></a>LogLinear_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">log</span>(score) <span class="sc">~</span> income, <span class="at">data =</span> CASchools)</span>
<span id="cb189-3"><a href="8.2-nfoasiv.html#cb189-3" tabindex="-1"></a></span>
<span id="cb189-4"><a href="8.2-nfoasiv.html#cb189-4" tabindex="-1"></a><span class="co"># obtain a robust coefficient summary</span></span>
<span id="cb189-5"><a href="8.2-nfoasiv.html#cb189-5" tabindex="-1"></a><span class="fu">coeftest</span>(LogLinear_model, </span>
<span id="cb189-6"><a href="8.2-nfoasiv.html#cb189-6" tabindex="-1"></a>         <span class="at">vcov =</span> vcovHC, <span class="at">type =</span> <span class="st">&quot;HC1&quot;</span>)</span>
<span id="cb189-7"><a href="8.2-nfoasiv.html#cb189-7" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb189-8"><a href="8.2-nfoasiv.html#cb189-8" tabindex="-1"></a><span class="co">#&gt; t test of coefficients:</span></span>
<span id="cb189-9"><a href="8.2-nfoasiv.html#cb189-9" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb189-10"><a href="8.2-nfoasiv.html#cb189-10" tabindex="-1"></a><span class="co">#&gt;               Estimate Std. Error  t value  Pr(&gt;|t|)    </span></span>
<span id="cb189-11"><a href="8.2-nfoasiv.html#cb189-11" tabindex="-1"></a><span class="co">#&gt; (Intercept) 6.43936234 0.00289382 2225.210 &lt; 2.2e-16 ***</span></span>
<span id="cb189-12"><a href="8.2-nfoasiv.html#cb189-12" tabindex="-1"></a><span class="co">#&gt; income      0.00284407 0.00017509   16.244 &lt; 2.2e-16 ***</span></span>
<span id="cb189-13"><a href="8.2-nfoasiv.html#cb189-13" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb189-14"><a href="8.2-nfoasiv.html#cb189-14" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span></code></pre></div>
<p>The estimated regression function is <span class="math display">\[\widehat{\ln(TestScore)} = 6.439 + 0.00284 \times income.\]</span> An increase in district income by <span class="math inline">\(\$1000\)</span> is expected to increase test scores by <span class="math inline">\(100\times 0.00284 \% = 0.284\%\)</span>.</p>
<p>When the dependent variable in logarithm, one cannot simply use <span class="math inline">\(e^{\log(\cdot)}\)</span> to transform predictions back to the original scale, see page of the book.</p>
</div>
<div id="case-iii-x-and-y-are-in-logarithms" class="section level4 unnumbered hasAnchor">
<h4>Case III: <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are in Logarithms<a href="8.2-nfoasiv.html#case-iii-x-and-y-are-in-logarithms" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The log-log regression model is <span class="math display">\[\ln(Y_i) = \beta_0 + \beta_1 \times \ln(X_i) + u_i, \ \ i=1,...,n.\]</span></p>
<div class="sourceCode" id="cb190"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb190-1"><a href="8.2-nfoasiv.html#cb190-1" tabindex="-1"></a><span class="co"># estimate the log-log model</span></span>
<span id="cb190-2"><a href="8.2-nfoasiv.html#cb190-2" tabindex="-1"></a>LogLog_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">log</span>(score) <span class="sc">~</span> <span class="fu">log</span>(income), <span class="at">data =</span> CASchools)</span>
<span id="cb190-3"><a href="8.2-nfoasiv.html#cb190-3" tabindex="-1"></a></span>
<span id="cb190-4"><a href="8.2-nfoasiv.html#cb190-4" tabindex="-1"></a><span class="co"># print robust coefficient summary to the console</span></span>
<span id="cb190-5"><a href="8.2-nfoasiv.html#cb190-5" tabindex="-1"></a><span class="fu">coeftest</span>(LogLog_model, </span>
<span id="cb190-6"><a href="8.2-nfoasiv.html#cb190-6" tabindex="-1"></a>         <span class="at">vcov =</span> vcovHC, <span class="at">type =</span> <span class="st">&quot;HC1&quot;</span>)</span>
<span id="cb190-7"><a href="8.2-nfoasiv.html#cb190-7" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb190-8"><a href="8.2-nfoasiv.html#cb190-8" tabindex="-1"></a><span class="co">#&gt; t test of coefficients:</span></span>
<span id="cb190-9"><a href="8.2-nfoasiv.html#cb190-9" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb190-10"><a href="8.2-nfoasiv.html#cb190-10" tabindex="-1"></a><span class="co">#&gt;              Estimate Std. Error  t value  Pr(&gt;|t|)    </span></span>
<span id="cb190-11"><a href="8.2-nfoasiv.html#cb190-11" tabindex="-1"></a><span class="co">#&gt; (Intercept) 6.3363494  0.0059246 1069.501 &lt; 2.2e-16 ***</span></span>
<span id="cb190-12"><a href="8.2-nfoasiv.html#cb190-12" tabindex="-1"></a><span class="co">#&gt; log(income) 0.0554190  0.0021446   25.841 &lt; 2.2e-16 ***</span></span>
<span id="cb190-13"><a href="8.2-nfoasiv.html#cb190-13" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb190-14"><a href="8.2-nfoasiv.html#cb190-14" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span></code></pre></div>
<p>The estimated regression function hence is <span class="math display">\[\widehat{\ln(TestScore)} = 6.336 + 0.0554 \times \ln(income).\]</span> In a log-log model, a <span class="math inline">\(1\%\)</span> change in <span class="math inline">\(X\)</span> is associated with an estimated <span class="math inline">\(\hat\beta_1 \%\)</span> change in <span class="math inline">\(Y\)</span>.</p>
<p>We now reproduce Figure 8.5 of the book.</p>
<div class="sourceCode" id="cb191"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb191-1"><a href="8.2-nfoasiv.html#cb191-1" tabindex="-1"></a><span class="co"># generate a scatterplot</span></span>
<span id="cb191-2"><a href="8.2-nfoasiv.html#cb191-2" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">log</span>(score) <span class="sc">~</span> income, </span>
<span id="cb191-3"><a href="8.2-nfoasiv.html#cb191-3" tabindex="-1"></a>     <span class="at">col =</span> <span class="st">&quot;steelblue&quot;</span>, </span>
<span id="cb191-4"><a href="8.2-nfoasiv.html#cb191-4" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">20</span>, </span>
<span id="cb191-5"><a href="8.2-nfoasiv.html#cb191-5" tabindex="-1"></a>     <span class="at">data =</span> CASchools,</span>
<span id="cb191-6"><a href="8.2-nfoasiv.html#cb191-6" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">&quot;log(Score)&quot;</span>,</span>
<span id="cb191-7"><a href="8.2-nfoasiv.html#cb191-7" tabindex="-1"></a>     <span class="at">xlab=</span><span class="st">&quot;Income&quot;</span>,</span>
<span id="cb191-8"><a href="8.2-nfoasiv.html#cb191-8" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;Log-Linear Regression Function&quot;</span>)</span>
<span id="cb191-9"><a href="8.2-nfoasiv.html#cb191-9" tabindex="-1"></a></span>
<span id="cb191-10"><a href="8.2-nfoasiv.html#cb191-10" tabindex="-1"></a><span class="co"># add the log-linear regression line</span></span>
<span id="cb191-11"><a href="8.2-nfoasiv.html#cb191-11" tabindex="-1"></a>order_id  <span class="ot">&lt;-</span> <span class="fu">order</span>(CASchools<span class="sc">$</span>income)</span>
<span id="cb191-12"><a href="8.2-nfoasiv.html#cb191-12" tabindex="-1"></a></span>
<span id="cb191-13"><a href="8.2-nfoasiv.html#cb191-13" tabindex="-1"></a><span class="fu">lines</span>(CASchools<span class="sc">$</span>income[order_id], </span>
<span id="cb191-14"><a href="8.2-nfoasiv.html#cb191-14" tabindex="-1"></a>      <span class="fu">fitted</span>(LogLinear_model)[order_id], </span>
<span id="cb191-15"><a href="8.2-nfoasiv.html#cb191-15" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, </span>
<span id="cb191-16"><a href="8.2-nfoasiv.html#cb191-16" tabindex="-1"></a>      <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb191-17"><a href="8.2-nfoasiv.html#cb191-17" tabindex="-1"></a></span>
<span id="cb191-18"><a href="8.2-nfoasiv.html#cb191-18" tabindex="-1"></a><span class="co"># add the log-log regression line</span></span>
<span id="cb191-19"><a href="8.2-nfoasiv.html#cb191-19" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">sort</span>(CASchools<span class="sc">$</span>income), </span>
<span id="cb191-20"><a href="8.2-nfoasiv.html#cb191-20" tabindex="-1"></a>      <span class="fu">fitted</span>(LogLog_model)[<span class="fu">order</span>(CASchools<span class="sc">$</span>income)], </span>
<span id="cb191-21"><a href="8.2-nfoasiv.html#cb191-21" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&quot;green&quot;</span>, </span>
<span id="cb191-22"><a href="8.2-nfoasiv.html#cb191-22" tabindex="-1"></a>      <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb191-23"><a href="8.2-nfoasiv.html#cb191-23" tabindex="-1"></a></span>
<span id="cb191-24"><a href="8.2-nfoasiv.html#cb191-24" tabindex="-1"></a><span class="co"># add a legend</span></span>
<span id="cb191-25"><a href="8.2-nfoasiv.html#cb191-25" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;bottomright&quot;</span>,</span>
<span id="cb191-26"><a href="8.2-nfoasiv.html#cb191-26" tabindex="-1"></a>       <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">&quot;log-linear model&quot;</span>, <span class="st">&quot;log-log model&quot;</span>),</span>
<span id="cb191-27"><a href="8.2-nfoasiv.html#cb191-27" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="dv">2</span>,</span>
<span id="cb191-28"><a href="8.2-nfoasiv.html#cb191-28" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;green&quot;</span>))</span></code></pre></div>
<p><img src="ITER_files/figure-html/unnamed-chunk-331-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Key Concept 8.2 summarizes the three logarithmic regression models.</p>
<div id="KC8.2" class="keyconcept">
<h3 class="right">
Key Concept 8.2
</h3>
<h3 class="left">
Logarithms in Regression: Three Cases
</h3>
<p>
Logarithms can be used to transform the dependent variable <span class="math inline">\(Y\)</span> or the independent variable <span class="math inline">\(X\)</span>, or both
(the variable being transformed must be positive). The following table summarizes these three cases and the interpretation of the regression coefficient <span class="math inline">\(\beta_1\)</span>. In each case, <span class="math inline">\(\beta_1\)</span>, can be estimated by applying OLS after taking the logarithm(s) of the dependent and/or the independent variable.
</p>
<table>
<thead>
<tr class="header">
<th align="left">
Case
</th>
<th align="left">
Model Specification
</th>
<th align="left">
Interpretation of <span class="math inline">\(\beta_1\)</span>
</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">
<span class="math inline">\((I)\)</span>
</td>
<td align="left">
<span class="math inline">\(Y_i = \beta_0 + \beta_1 \ln(X_i) + u_i\)</span>
</td>
<td align="left">
A <span class="math inline">\(1 \%\)</span> change in <span class="math inline">\(X\)</span> is associated with a change in <span class="math inline">\(Y\)</span> of <span class="math inline">\(0.01 \times \beta_1\)</span>.
</td>
</tr>
<tr class="even">
<td align="left">
<span class="math inline">\((II)\)</span>
</td>
<td align="left">
<span class="math inline">\(\ln(Y_i) = \beta_0 + \beta_1 X_i + u_i\)</span>
</td>
<td align="left">
A change in <span class="math inline">\(X\)</span> by one unit (<span class="math inline">\(\Delta X = 1\)</span>) is associated with a <span class="math inline">\(100 \times \beta_1 \%\)</span> change in <span class="math inline">\(Y\)</span>.
</td>
</tr>
<tr class="odd">
<td align="left">
<span class="math inline">\((III)\)</span>
</td>
<td align="left">
<span class="math inline">\(\ln(Y_i) = \beta_0 + \beta_1 \ln(X_i) + u_i\)</span>
</td>
<td align="left">
A <span class="math inline">\(1\%\)</span> change in <span class="math inline">\(X\)</span> is associated with a <span class="math inline">\(\beta_1\%\)</span> change in <span class="math inline">\(Y\)</span>, so <span class="math inline">\(\beta_1\)</span> is the elasticity of <span class="math inline">\(Y\)</span> with respect to <span class="math inline">\(X\)</span>.
</td>
</tr>
</tbody>
</table>
</div>
<p>Of course we can also estimate a <em>polylog</em> model like</p>
<p><span class="math display">\[ TestScore_i = \beta_0 + \beta_1 \times \ln(income_i) + \beta_2 \times \ln(income_i)^2 + \beta_3 \times \ln(income_i)^3 + u_i, \]</span></p>
<p>which models the dependent variable <span class="math inline">\(TestScore\)</span> by a third-degree polynomial of the log-transformed regressor <span class="math inline">\(income\)</span>.</p>
<div class="sourceCode" id="cb192"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb192-1"><a href="8.2-nfoasiv.html#cb192-1" tabindex="-1"></a><span class="co"># estimate the polylog model</span></span>
<span id="cb192-2"><a href="8.2-nfoasiv.html#cb192-2" tabindex="-1"></a>polyLog_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(score <span class="sc">~</span> <span class="fu">log</span>(income) <span class="sc">+</span> <span class="fu">I</span>(<span class="fu">log</span>(income)<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> <span class="fu">I</span>(<span class="fu">log</span>(income)<span class="sc">^</span><span class="dv">3</span>), </span>
<span id="cb192-3"><a href="8.2-nfoasiv.html#cb192-3" tabindex="-1"></a>                    <span class="at">data =</span> CASchools)</span>
<span id="cb192-4"><a href="8.2-nfoasiv.html#cb192-4" tabindex="-1"></a></span>
<span id="cb192-5"><a href="8.2-nfoasiv.html#cb192-5" tabindex="-1"></a><span class="co"># print robust summary to the console</span></span>
<span id="cb192-6"><a href="8.2-nfoasiv.html#cb192-6" tabindex="-1"></a><span class="fu">coeftest</span>(polyLog_model, </span>
<span id="cb192-7"><a href="8.2-nfoasiv.html#cb192-7" tabindex="-1"></a>         <span class="at">vcov =</span> vcovHC, <span class="at">type =</span> <span class="st">&quot;HC1&quot;</span>)</span>
<span id="cb192-8"><a href="8.2-nfoasiv.html#cb192-8" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb192-9"><a href="8.2-nfoasiv.html#cb192-9" tabindex="-1"></a><span class="co">#&gt; t test of coefficients:</span></span>
<span id="cb192-10"><a href="8.2-nfoasiv.html#cb192-10" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb192-11"><a href="8.2-nfoasiv.html#cb192-11" tabindex="-1"></a><span class="co">#&gt;                  Estimate Std. Error t value  Pr(&gt;|t|)    </span></span>
<span id="cb192-12"><a href="8.2-nfoasiv.html#cb192-12" tabindex="-1"></a><span class="co">#&gt; (Intercept)      486.1341    79.3825  6.1239 2.115e-09 ***</span></span>
<span id="cb192-13"><a href="8.2-nfoasiv.html#cb192-13" tabindex="-1"></a><span class="co">#&gt; log(income)      113.3820    87.8837  1.2901    0.1977    </span></span>
<span id="cb192-14"><a href="8.2-nfoasiv.html#cb192-14" tabindex="-1"></a><span class="co">#&gt; I(log(income)^2) -26.9111    31.7457 -0.8477    0.3971    </span></span>
<span id="cb192-15"><a href="8.2-nfoasiv.html#cb192-15" tabindex="-1"></a><span class="co">#&gt; I(log(income)^3)   3.0632     3.7369  0.8197    0.4128    </span></span>
<span id="cb192-16"><a href="8.2-nfoasiv.html#cb192-16" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb192-17"><a href="8.2-nfoasiv.html#cb192-17" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span></code></pre></div>
<p>Comparing by <span class="math inline">\(\bar{R}^2\)</span> we find that, leaving out the log-linear model, all models have a similar adjusted fit. In the class of polynomial models, the cubic specification has the highest <span class="math inline">\(\bar{R}^2\)</span> whereas the linear-log specification is the best of the log-models.</p>
<div class="sourceCode" id="cb193"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb193-1"><a href="8.2-nfoasiv.html#cb193-1" tabindex="-1"></a><span class="co"># compute the adj. R^2 for the nonlinear models</span></span>
<span id="cb193-2"><a href="8.2-nfoasiv.html#cb193-2" tabindex="-1"></a>adj_R2 <span class="ot">&lt;-</span><span class="fu">rbind</span>(<span class="st">&quot;quadratic&quot;</span> <span class="ot">=</span> <span class="fu">summary</span>(quadratic_model)<span class="sc">$</span>adj.r.squared,</span>
<span id="cb193-3"><a href="8.2-nfoasiv.html#cb193-3" tabindex="-1"></a>               <span class="st">&quot;cubic&quot;</span> <span class="ot">=</span> <span class="fu">summary</span>(cubic_model)<span class="sc">$</span>adj.r.squared,</span>
<span id="cb193-4"><a href="8.2-nfoasiv.html#cb193-4" tabindex="-1"></a>               <span class="st">&quot;LinearLog&quot;</span> <span class="ot">=</span> <span class="fu">summary</span>(LinearLog_model)<span class="sc">$</span>adj.r.squared,</span>
<span id="cb193-5"><a href="8.2-nfoasiv.html#cb193-5" tabindex="-1"></a>               <span class="st">&quot;LogLinear&quot;</span> <span class="ot">=</span> <span class="fu">summary</span>(LogLinear_model)<span class="sc">$</span>adj.r.squared,</span>
<span id="cb193-6"><a href="8.2-nfoasiv.html#cb193-6" tabindex="-1"></a>               <span class="st">&quot;LogLog&quot;</span> <span class="ot">=</span> <span class="fu">summary</span>(LogLog_model)<span class="sc">$</span>adj.r.squared,</span>
<span id="cb193-7"><a href="8.2-nfoasiv.html#cb193-7" tabindex="-1"></a>               <span class="st">&quot;polyLog&quot;</span> <span class="ot">=</span> <span class="fu">summary</span>(polyLog_model)<span class="sc">$</span>adj.r.squared)</span>
<span id="cb193-8"><a href="8.2-nfoasiv.html#cb193-8" tabindex="-1"></a></span>
<span id="cb193-9"><a href="8.2-nfoasiv.html#cb193-9" tabindex="-1"></a><span class="co"># assign column names</span></span>
<span id="cb193-10"><a href="8.2-nfoasiv.html#cb193-10" tabindex="-1"></a><span class="fu">colnames</span>(adj_R2) <span class="ot">&lt;-</span> <span class="st">&quot;adj_R2&quot;</span></span>
<span id="cb193-11"><a href="8.2-nfoasiv.html#cb193-11" tabindex="-1"></a></span>
<span id="cb193-12"><a href="8.2-nfoasiv.html#cb193-12" tabindex="-1"></a>adj_R2</span>
<span id="cb193-13"><a href="8.2-nfoasiv.html#cb193-13" tabindex="-1"></a><span class="co">#&gt;              adj_R2</span></span>
<span id="cb193-14"><a href="8.2-nfoasiv.html#cb193-14" tabindex="-1"></a><span class="co">#&gt; quadratic 0.5540444</span></span>
<span id="cb193-15"><a href="8.2-nfoasiv.html#cb193-15" tabindex="-1"></a><span class="co">#&gt; cubic     0.5552279</span></span>
<span id="cb193-16"><a href="8.2-nfoasiv.html#cb193-16" tabindex="-1"></a><span class="co">#&gt; LinearLog 0.5614605</span></span>
<span id="cb193-17"><a href="8.2-nfoasiv.html#cb193-17" tabindex="-1"></a><span class="co">#&gt; LogLinear 0.4970106</span></span>
<span id="cb193-18"><a href="8.2-nfoasiv.html#cb193-18" tabindex="-1"></a><span class="co">#&gt; LogLog    0.5567251</span></span>
<span id="cb193-19"><a href="8.2-nfoasiv.html#cb193-19" tabindex="-1"></a><span class="co">#&gt; polyLog   0.5599944</span></span></code></pre></div>
<p>Let us now compare the cubic and the linear-log model by plotting the corresponding estimated regression functions.</p>
<div class="sourceCode" id="cb194"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb194-1"><a href="8.2-nfoasiv.html#cb194-1" tabindex="-1"></a><span class="co"># generate a scatterplot</span></span>
<span id="cb194-2"><a href="8.2-nfoasiv.html#cb194-2" tabindex="-1"></a><span class="fu">plot</span>(score <span class="sc">~</span> income, </span>
<span id="cb194-3"><a href="8.2-nfoasiv.html#cb194-3" tabindex="-1"></a>     <span class="at">data =</span> CASchools,</span>
<span id="cb194-4"><a href="8.2-nfoasiv.html#cb194-4" tabindex="-1"></a>     <span class="at">col =</span> <span class="st">&quot;steelblue&quot;</span>, </span>
<span id="cb194-5"><a href="8.2-nfoasiv.html#cb194-5" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">20</span>,</span>
<span id="cb194-6"><a href="8.2-nfoasiv.html#cb194-6" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">&quot;Score&quot;</span>,</span>
<span id="cb194-7"><a href="8.2-nfoasiv.html#cb194-7" tabindex="-1"></a>     <span class="at">xlab=</span><span class="st">&quot;Income&quot;</span>,</span>
<span id="cb194-8"><a href="8.2-nfoasiv.html#cb194-8" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;Linear-Log and Cubic Regression Functions&quot;</span>)</span>
<span id="cb194-9"><a href="8.2-nfoasiv.html#cb194-9" tabindex="-1"></a></span>
<span id="cb194-10"><a href="8.2-nfoasiv.html#cb194-10" tabindex="-1"></a><span class="co"># add the linear-log regression line</span></span>
<span id="cb194-11"><a href="8.2-nfoasiv.html#cb194-11" tabindex="-1"></a>order_id  <span class="ot">&lt;-</span> <span class="fu">order</span>(CASchools<span class="sc">$</span>income)</span>
<span id="cb194-12"><a href="8.2-nfoasiv.html#cb194-12" tabindex="-1"></a></span>
<span id="cb194-13"><a href="8.2-nfoasiv.html#cb194-13" tabindex="-1"></a><span class="fu">lines</span>(CASchools<span class="sc">$</span>income[order_id],</span>
<span id="cb194-14"><a href="8.2-nfoasiv.html#cb194-14" tabindex="-1"></a>      <span class="fu">fitted</span>(LinearLog_model)[order_id], </span>
<span id="cb194-15"><a href="8.2-nfoasiv.html#cb194-15" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&quot;darkgreen&quot;</span>, </span>
<span id="cb194-16"><a href="8.2-nfoasiv.html#cb194-16" tabindex="-1"></a>      <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb194-17"><a href="8.2-nfoasiv.html#cb194-17" tabindex="-1"></a></span>
<span id="cb194-18"><a href="8.2-nfoasiv.html#cb194-18" tabindex="-1"></a><span class="co"># add the cubic regression line</span></span>
<span id="cb194-19"><a href="8.2-nfoasiv.html#cb194-19" tabindex="-1"></a><span class="fu">lines</span>(<span class="at">x =</span> CASchools<span class="sc">$</span>income[order_id], </span>
<span id="cb194-20"><a href="8.2-nfoasiv.html#cb194-20" tabindex="-1"></a>      <span class="at">y =</span> <span class="fu">fitted</span>(cubic_model)[order_id],</span>
<span id="cb194-21"><a href="8.2-nfoasiv.html#cb194-21" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, </span>
<span id="cb194-22"><a href="8.2-nfoasiv.html#cb194-22" tabindex="-1"></a>      <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb194-23"><a href="8.2-nfoasiv.html#cb194-23" tabindex="-1"></a><span class="co"># add a legend</span></span>
<span id="cb194-24"><a href="8.2-nfoasiv.html#cb194-24" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;bottomright&quot;</span>,</span>
<span id="cb194-25"><a href="8.2-nfoasiv.html#cb194-25" tabindex="-1"></a>       <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">&quot;Linear-Log model&quot;</span>, <span class="st">&quot;Cubic model&quot;</span>),</span>
<span id="cb194-26"><a href="8.2-nfoasiv.html#cb194-26" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="dv">2</span>,</span>
<span id="cb194-27"><a href="8.2-nfoasiv.html#cb194-27" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;darkgreen&quot;</span>, <span class="st">&quot;red&quot;</span>))</span></code></pre></div>
<p><img src="ITER_files/figure-html/unnamed-chunk-335-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Both regression lines look nearly identical. Altogether the linear-log model may be preferable since it is more parsimonious in terms of regressors: it does not include higher-degree polynomials.</p>
</div>
</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-stock2015" class="csl-entry">
Stock, J. H., and M. W. Watson. 2015. <em><span>I</span>ntroduction to <span>E</span>conometrics, <span>T</span>hird <span>U</span>pdate, <span>G</span>lobal <span>E</span>dition</em>. <span>P</span>earson <span>E</span>ducation <span>L</span>imited.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="8.1-a-general-strategy-for-modelling-nonlinear-regression-functions.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="8.3-interactions-between-independent-variables.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": true,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": {
"link": "https://github.com/mca91/EconometricsWithR/edit/master/08-ch8.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ITER.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
